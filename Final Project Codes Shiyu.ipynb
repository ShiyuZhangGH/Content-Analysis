{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Note. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4 \n",
    "import pandas as pd \n",
    "import docx \n",
    "\n",
    "import re \n",
    "import urllib.parse \n",
    "import io \n",
    "import json\n",
    "import os.path\n",
    "import os \n",
    "import time\n",
    "import nltk \n",
    "import numpy as np\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "import _pickle as cPickle\n",
    "\n",
    "import sklearn\n",
    "import sklearn.feature_extraction.text\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.datasets\n",
    "import sklearn.cluster\n",
    "import sklearn.decomposition\n",
    "import sklearn.metrics\n",
    "\n",
    "import scipy \n",
    "import scipy.cluster.hierarchy\n",
    "import gensim\n",
    "\n",
    "import matplotlib.pyplot as plt #For graphics\n",
    "import matplotlib.cm #Still for graphics\n",
    "import seaborn as sns #Makes the graphics look nicer\n",
    "\n",
    "#This 'magic' command makes the plots work better\n",
    "#in the notebook, don't use it outside of a notebook.\n",
    "#Also you can ignore the warning, it\n",
    "%matplotlib inline\n",
    "\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "import operator\n",
    "from googletrans import Translator\n",
    "import networkx as nx\n",
    "import gensim\n",
    "\n",
    "import sklearn\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "import sklearn.neural_network\n",
    "import sklearn.decomposition\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, \\\n",
    "precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.  Scraping the data from qidian website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Section Overview*** \n",
    "\n",
    "In this section, I scraped data from the web novel website qidian (male: https://www.qidian.com/rank/collect?style=2; female: https://www.qidian.com/mm/rank/collect?style=2)\n",
    "\n",
    "All the operations were run for male and female version of the website separately. \n",
    "\n",
    "**Step 1**: Go the the ranking board (male and female separately) to gather links of the popular books --> A list of all book links\n",
    "\n",
    "**Step 2**: Go to the introduction page of each book, scraped the book demographics (book name, author name, book introduction, total number of bookmark, total number of recommend, total number of clicks, tags assigned to each novel). \n",
    "\n",
    "**Step 3**: On the introduction page, there is a button called (trial reading for free). Clicking this button jumps to the first chapter of this book. I scraped 30 chapters of each books by clicking \"next page\" at the bottom of each chapter.\n",
    "\n",
    "**Iteration**: Scraping the books sometimes gives me errors. But trying for a second or third time may work. I therefore write an iteration that would collect the books that were unsuccessful for the first time and then tried a second, a third, even a fourth time.\n",
    "\n",
    "**Results**: The results of this section is two dataframe, one for 500 males novels and one for 500 female novels. The shape of the novels are \n",
    "\n",
    "    500*12 : \n",
    "    500 books * (1.'author', 2.'click_count', 3.'example_text', 4.'intro', 5.'intro_mentioned_books', 6.'name', 7.'recom_count', 8.'tags', 9.'word_count' (of the book), 10.'num_bookmarked', 11.'book_url', 12.'book_rank')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Gathering book links from the ranking board before processing the books\n",
    "##The ranking board includes 10 pages; each page includes 50 books. \n",
    "##500 books in total on the ranking board. \n",
    "BookList= []\n",
    "for p in range(1,11):\n",
    "    #For the male version of the website\n",
    "    #rank_url= \"https://www.qidian.com/rank/collect?style=2&page={}\".format(p)\n",
    "    \n",
    "    #For the female version of the website \n",
    "    rank_url= \"https://www.qidian.com/mm/rank/collect?style=2&page={}\".format(p)\n",
    "\n",
    "    page_request= requests.get(rank_url)\n",
    "    page_soup= BeautifulSoup(page_request.text, \"lxml\")\n",
    "\n",
    "    url_list= page_soup.body.find(\"div\", attrs= {\"class\": \"rank-view-list\"})\\\n",
    "               .find_all(\"a\", attrs= {\"class\": \"name\"}) #Continuing the previous line!!!\n",
    "    bookmark_list= page_soup.body.find_all(\"td\", attrs= {\"class\": \"month\"})\n",
    "    for i in range(50): #The page is well structured; 50 books a page\n",
    "        a_book= [url_list[i][\"href\"], int(bookmark_list[i].text)]\n",
    "        BookList.append(a_book)\n",
    "\n",
    "#Output of this loop is links of the books on the ranking broad.\n",
    "#Output is list within list\n",
    "#[[book1's url, number of being bookmarked], [book2's url, number of being bookmarked], etc]\n",
    "print(len(BookList))\n",
    "print(BookList[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##I store the book links in a excel file\n",
    "\"\"\"\n",
    "BookList_male= pd.DataFrame(BookList)\n",
    "BookList_male.to_csv(\"bookList_male.csv\")\n",
    "\"\"\"\n",
    "BookList_female= pd.DataFrame(BookList)\n",
    "BookList_female.to_csv(\"bookList_female.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##These functions are for dealing with individual book links\n",
    "##and gathering information of each book\n",
    "\n",
    "def soup_a_book(a_book_url):\n",
    "    ##Extracting book introduction from a webpage+ \n",
    "    ##Using Beautifulsoup to parse a book's web page\n",
    "    a_book_request= requests.get(a_book_url)\n",
    "    a_book_soup= BeautifulSoup(a_book_request.text, 'lxml')\n",
    "    return a_book_soup\n",
    "\n",
    "\n",
    "def get_intro(a_book_soup):\n",
    "    #Following the previous function, get the book's introductio and get rid of \"\\u3000\"\n",
    "    for_intro= a_book_soup.body.find(\"div\", attrs= {\"class\": \"book-intro\"})\n",
    "    intro= re.sub(r\"\\u3000\", \" \", for_intro.text.strip()) #(Regular Expression 1)\n",
    "    return intro\n",
    "\n",
    "def get_book_demo(a_book_soup):\n",
    "    ###Book demographics###\n",
    "    for_info= a_book_soup.body.find(\"div\", attrs= {\"class\": \"book-info\"})\n",
    "\n",
    "    #name, author\n",
    "    name= for_info.text.split()[0]\n",
    "    author= for_info.text.split()[1]\n",
    "    \n",
    "    linked_text= re.findall(r\"\\d+.\\d+.*总推荐\", for_info.text)[0] #(Regular Expression 2)\n",
    "    #The above re.findall() returns a list, I take its element as string.\n",
    "    splited_text= linked_text.split(\"|\")\n",
    "    #print(splited_text)\n",
    "\n",
    "    #word count\n",
    "    word_count= splited_text[0] \n",
    "\n",
    "    #click count\n",
    "    click_count= re.findall(r\"\\d+.\\d+.*总点击\", splited_text[1])[0] #(Regular Expression 3)  \n",
    "    \n",
    "    #recommendation count\n",
    "    recom_count= splited_text[2] #(Regular Expression 3)  \n",
    "\n",
    "    #tags\n",
    "    tags= a_book_soup.body.find_all(\"a\", attrs= {\"class\": \"red\"})\n",
    "    tags= [i.text for i in tags]\n",
    "    tags_string= \"\" \n",
    "    for t in tags:\n",
    "        tags_string+= t+ \";\"\n",
    "\n",
    "    return name, author, word_count, click_count, recom_count, tags_string\n",
    "\n",
    "\n",
    "def get_IntroMentioned_books(intro, name):\n",
    "    #Input of this function:\n",
    "    #uses output of TWO of the above functions get_intro() and get_book_demo()\n",
    "    #Lookinf for other books mentioned in the book introduction\n",
    "    all_mentioned= re.findall(r\"《(.*?)》\", intro) #(Regular Expression 4)\n",
    "    other_books= [i for i in all_mentioned if i!= name]\n",
    "    other_books_string= \"\"\n",
    "    for o in other_books:\n",
    "        other_books_string+= o+ \";\"\n",
    "    return other_books_string\n",
    "\n",
    "\n",
    "def get_text(a_book_soup):\n",
    "    #Input is the soup of the introduction page of the book \n",
    "    #Obtain the first 30 chapters as example writing, 30 chapters are stored in one dictionary\n",
    "    \n",
    "    #Using the introduction page to get the the \"read for free (= first page)\"\n",
    "    def get_content(for_read_url):\n",
    "        read_url= \"https:\"+ for_read_url\n",
    "\n",
    "        ch= requests.get(read_url)\n",
    "        ch_soup= BeautifulSoup(ch.text, 'lxml')\n",
    "        #Attention: \"html.parser\" gives me a TypeError called:\n",
    "        #TypeError: 'NoneType' object is not subscriptable\n",
    "        #This problem is no longer there, if I use \"lxml\" as parser\n",
    "\n",
    "        chP= ch_soup.body.find(\"div\", attrs= {\"class\": \"read-content\"}).find_all(\"p\")\n",
    "        chP_joined= \"\"\n",
    "        for p in chP:\n",
    "            chP_joined+= str(p)   \n",
    "        chP_joined= chP_joined.replace(\"\\u3000\", \"\")\n",
    "  \n",
    "        ch_content= re.sub(r\"(<\\/*p>)(\\1*)\", \"\", chP_joined) #(Regular Expression 5)\n",
    "        ch_content= ch_content.strip()\n",
    "        return ch_content, ch_soup\n",
    "    \n",
    "    content_dic= {}\n",
    "    i= 1 \n",
    "    while i< 31:\n",
    "        if i== 1:\n",
    "            for_read_url= a_book_soup.body.find(\"a\", text= \"免费试读\")[\"href\"] \n",
    "            ch_content, ch_soup = get_content(for_read_url)\n",
    "            content_dic[i]= ch_content\n",
    "            i+= 1\n",
    "        else:\n",
    "            for_read_url= ch_soup.body.find(\"a\", text= \"下一章\")[\"href\"]\n",
    " \n",
    "            ch_content, ch_soup = get_content(for_read_url)\n",
    "            content_dic[i]= ch_content\n",
    "            i+= 1\n",
    "    \n",
    "    return content_dic\n",
    "\n",
    "def deal_with_a_book(a_book_url):\n",
    "    a_book_soup= soup_a_book(a_book_url)\n",
    "    intro= get_intro(a_book_soup)\n",
    "    name, author, word_count, click_count, recom_count, tags_string= get_book_demo(a_book_soup)\n",
    "    other_books_string= get_IntroMentioned_books(intro, name)\n",
    "    content_dic= get_text(a_book_soup)\n",
    "    \n",
    "    a_book_dic= {'name' : name, \"author\": author, \"intro\": intro, \n",
    "                 \"word_count\": word_count, \"click_count\": click_count, \n",
    "                 \"recom_count\": recom_count,\n",
    "                 \"tags\": tags_string, \"intro_mentioned_books\": other_books_string, \n",
    "                 \"example_text\": content_dic}\n",
    "    helper= [a_book_dic]\n",
    "    bookDF= pd.DataFrame(data= helper)\n",
    "    return bookDF, a_book_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Processing the 500 books and output a data frame\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "bookDF_female_200_500= pd.DataFrame({})\n",
    "book_error_recording= \"book_error_recording.txt\"\n",
    "\n",
    "\n",
    "for book in BookList[200:500]:\n",
    "    try:\n",
    "        book_url= \"https:\"+ book[0]\n",
    "        a_bookDF, a_book_soup= deal_with_a_book(book_url)\n",
    "        #The \"number of being bookmarked\" information is not available on the\n",
    "        #book introduction page. This information is available on the book ranking page. \n",
    "        #I add a column for each book about its number of being bookmarked:\n",
    "        a_bookDF[\"num_bookmarked\"]= book[1]\n",
    "        a_bookDF[\"book_url\"]= book_url\n",
    "        a_bookDF[\"book_rank\"]= BookList.index(book)\n",
    "\n",
    "        if a_bookDF.shape[1]== 12:\n",
    "            bookDF_female_200_500= bookDF_female_200_500.append(a_bookDF)\n",
    "            bookDF_female_200_500.to_pickle(\"bookDF_female_200_500.pickle\")\n",
    "            print(bookDF_female_200_500.shape)\n",
    "        else:\n",
    "            print(\"Does not generate 12-column book:\", book_url)\n",
    "    except:\n",
    "        print(\"Error in book:\", book_url)\n",
    "        fw= open(\"book_error_recording.txt\", \"a\")\n",
    "        fw.write(\"\\n Error in book:\"+ book_url)\n",
    "        fw.close()\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##I scraped the 500 books in two times. \n",
    "\n",
    "##For male\n",
    "bookDF_male_0_200= pd.read_pickle(\"bookDF_male_0_200.pickle\")\n",
    "bookDF_male_200_500= pd.read_pickle(\"bookDF_male_200_500.pickle\")\n",
    "bookDF_male= bookDF_male_0_200.append(bookDF_male_200_500)\n",
    "bookDF_male.to_pickle(\"bookDF_male.pickle\")\n",
    "bookDF_male.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##For female\n",
    "bookDF_female_0_200= pd.read_pickle(\"bookDF_female_0_200.pickle\")\n",
    "bookDF_female_200_500= pd.read_pickle(\"bookDF_female_200_500.pickle\")\n",
    "bookDF_female= bookDF_female_0_200.append(bookDF_female_200_500)\n",
    "bookDF_female.to_pickle(\"bookDF_female.pickle\")\n",
    "bookDF_female.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:darkred\"> **The following of this section is to solve technical issues and not substantially important**\n",
    "\n",
    "**Iteration for books that are unsuccessfully scraped for the first time** The above run the code for one time and loop through 500 books on the ranking board for male and female version of the website, respective. However, some webpages were not successfully processed and generate errors. In the following, I re-process the webpages that were not successfully processed for the first time.\n",
    "For the male version, the recursive codes successfully scraped the data of all books.\n",
    "For the female version, the problem is not just random problem of the website, but is actually due to my codes. I have to modify my code to deal with the problem in the \"deal_with_a_book()\" function. I do not make modification above, so avoid messing with the code that works on 995 cases. I copy and past the function above and make the modification just for the 5 books that cannot be procesed (named \"Extra Section\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Re-processing the error books \n",
    "#(The errors occured for unknown reason. Not because the pages are problematic\n",
    "#If I run it for another time, there is no problem at all.\n",
    "\n",
    "#For the male data frame\n",
    "##I store the booklist as a data frame. Read it back to a list. \n",
    "bookpd_male= pd.read_csv(\"bookList_male.csv\")\n",
    "booklist_male= []\n",
    "for i in range(bookpd_male.shape[0]):\n",
    "    booklist_male+= [list(bookpd_male.iloc[i][1:3])]\n",
    "##load the scraped dataframe\n",
    "bookDF_male= pd.read_pickle(\"bookDF_male.pickle\")\n",
    "##Find the ones that were not successfully included in the scraped data\n",
    "error_male= []\n",
    "for u in booklist_male:\n",
    "    if \"https:\"+ u[0] not in list(bookDF_male[\"book_url\"]):\n",
    "        error_male+= [u]\n",
    "\n",
    "##Copy and paste the codes I used above + Modeification!\n",
    "##I write the code recursively. It will only stop until all the errored books are processed. \n",
    "while True:\n",
    "    if len(error_male)== 0:\n",
    "        break\n",
    "    else:\n",
    "        for book in error_male:\n",
    "            try:\n",
    "                book_url= \"https:\"+ book[0]\n",
    "                a_bookDF, a_book_soup= deal_with_a_book(book_url)\n",
    "\n",
    "                a_bookDF[\"num_bookmarked\"]= book[1]\n",
    "                a_bookDF[\"book_url\"]= book_url\n",
    "                a_bookDF[\"book_rank\"]= booklist_male.index(book)\n",
    "\n",
    "                if a_bookDF.shape[1]== 12:\n",
    "                    bookDF_male= bookDF_male.append(a_bookDF)\n",
    "                    bookDF_male.to_pickle(\"bookDF_male.pickle\")\n",
    "                    error_male.remove(book)\n",
    "                    print(bookDF_male.shape)\n",
    "                else:\n",
    "                    print(\"Does not generate 12-column book:\", book_url)\n",
    "            except:\n",
    "                print(\"Error in book:\", book_url)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For the female data frame (Copy and Paste from the previous male code)\n",
    "##I store the booklist as a data frame. Read it back to a list. \n",
    "bookpd_female= pd.read_csv(\"bookList_female.csv\")\n",
    "booklist_female= []\n",
    "for i in range(bookpd_female.shape[0]):\n",
    "    booklist_female+= [list(bookpd_female.iloc[i][1:3])]\n",
    "##load the scraped dataframe\n",
    "bookDF_female= pd.read_pickle(\"bookDF_female.pickle\")\n",
    "##Find the ones that were not successfully included in the scraped data\n",
    "error_female= []\n",
    "for u in booklist_female:\n",
    "    if \"https:\"+ u[0] not in list(bookDF_female[\"book_url\"]):\n",
    "        error_female+= [u]\n",
    "print(len(error_female))\n",
    "\n",
    "##I write the code recursively. It will only stop until all the errored books are processed. \n",
    "##There are five web pages that cannot be processed. So I had to force restart kenel to\n",
    "##break out of the loop\n",
    "while True:\n",
    "    if len(error_female)== 0:\n",
    "        break\n",
    "    else:\n",
    "        for book in error_female:\n",
    "            try:\n",
    "                book_url= \"https:\"+ book[0]\n",
    "                a_bookDF, a_book_soup= deal_with_a_book(book_url)\n",
    "\n",
    "                a_bookDF[\"num_bookmarked\"]= book[1]\n",
    "                a_bookDF[\"book_url\"]= book_url\n",
    "                a_bookDF[\"book_rank\"]= booklist_female.index(book)\n",
    "\n",
    "                if a_bookDF.shape[1]== 12:\n",
    "                    bookDF_female= bookDF_female.append(a_bookDF)\n",
    "                    bookDF_female.to_pickle(\"bookDF_female.pickle\")\n",
    "                    error_female.remove(book)\n",
    "                    print(bookDF_female.shape)\n",
    "                else:\n",
    "                    print(\"Does not generate 12-column book:\", book_url)\n",
    "            except:\n",
    "                print(\"Error in book:\", book_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Error in book: https://book.qidian.com/info/2487306\n",
    "Error in book: https://book.qidian.com/info/1533678\n",
    "Error in book: https://book.qidian.com/info/1692031\n",
    "Error in book: https://book.qidian.com/info/2613980\n",
    "Error in book: https://book.qidian.com/info/3374695\n",
    "\"\"\"\n",
    "#The problem is in get_book_demo() which further problematizes deal_with_a_book()\n",
    "\n",
    "def get_book_demo_modi(a_book_soup):\n",
    "    ###Book demographics###\n",
    "    for_info= a_book_soup.body.find(\"div\", attrs= {\"class\": \"book-info\"})\n",
    "    #print(for_info.text)\n",
    "    #print(type(for_info.text))\n",
    "\n",
    "    #name, author\n",
    "    name= for_info.text.split()[0]\n",
    "    author= for_info.text.split()[1]\n",
    "    \n",
    "    linked_text= re.findall(r\"\\d+.*总推荐\", for_info.text)[0] #(Regular Expression 2)\n",
    "    #The above re.findall() returns a list, I take its element as string.\n",
    "    splited_text= linked_text.split(\"|\")\n",
    "    #print(splited_text)\n",
    "\n",
    "    #word count\n",
    "    word_count= splited_text[0] \n",
    "\n",
    "    #click count\n",
    "    click_count= re.findall(r\"\\d+.\\d+.*总点击\", splited_text[1])[0] #(Regular Expression 3)  \n",
    "    \n",
    "    #recommendation count\n",
    "    recom_count= splited_text[2] #(Regular Expression 3)  \n",
    "\n",
    "    #tags\n",
    "    tags= a_book_soup.body.find_all(\"a\", attrs= {\"class\": \"red\"})\n",
    "    tags= [i.text for i in tags]\n",
    "    tags_string= \"\" \n",
    "    for t in tags:\n",
    "        tags_string+= t+ \";\"\n",
    "\n",
    "    return name, author, word_count, click_count, recom_count, tags_string\n",
    "\n",
    "\n",
    "\n",
    "def deal_with_a_book_modi(a_book_url):\n",
    "    a_book_soup= soup_a_book(a_book_url)\n",
    "    intro= get_intro(a_book_soup)\n",
    "    name, author, word_count, click_count, recom_count, tags_string= get_book_demo_modi(a_book_soup)\n",
    "    other_books_string= get_IntroMentioned_books(intro, name)\n",
    "    content_dic= get_text(a_book_soup)\n",
    "    \n",
    "    a_book_dic= {'name' : name, \"author\": author, \"intro\": intro, \n",
    "                 \"word_count\": word_count, \"click_count\": click_count, \n",
    "                 \"recom_count\": recom_count,\n",
    "                 \"tags\": tags_string, \"intro_mentioned_books\": other_books_string, \n",
    "                 \"example_text\": content_dic}\n",
    "    helper= [a_book_dic]\n",
    "    bookDF= pd.DataFrame(data= helper)\n",
    "    return bookDF, a_book_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Process the last 5 books\n",
    "bookpd_female= pd.read_csv(\"bookList_female.csv\")\n",
    "booklist_female= []\n",
    "for i in range(bookpd_female.shape[0]):\n",
    "    booklist_female+= [list(bookpd_female.iloc[i][1:3])]\n",
    "##load the scraped dataframe\n",
    "bookDF_female= pd.read_pickle(\"bookDF_female.pickle\")\n",
    "##Find the ones that were not successfully included in the scraped data\n",
    "error_female= []\n",
    "for u in booklist_female:\n",
    "    if \"https:\"+ u[0] not in list(bookDF_female[\"book_url\"]):\n",
    "        error_female+= [u]\n",
    "print(len(error_female))\n",
    "\n",
    "while True:\n",
    "    if len(error_female)== 0:\n",
    "        break\n",
    "    for book in error_female:\n",
    "        try:\n",
    "            book_url= \"https:\"+ book[0]\n",
    "            a_bookDF, a_book_soup= deal_with_a_book_modi(book_url)\n",
    "\n",
    "            a_bookDF[\"num_bookmarked\"]= book[1]\n",
    "            a_bookDF[\"book_url\"]= book_url\n",
    "            a_bookDF[\"book_rank\"]= booklist_female.index(book)\n",
    "\n",
    "            if a_bookDF.shape[1]== 12:\n",
    "                bookDF_female= bookDF_female.append(a_bookDF)\n",
    "                bookDF_female.to_pickle(\"bookDF_female.pickle\")\n",
    "                error_female.remove(book)\n",
    "                print(bookDF_female.shape)\n",
    "            else:\n",
    "                print(\"Does not generate 12-column book:\", book_url)\n",
    "        except:\n",
    "            print(\"Error in book:\", book_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookDF_female= pd.read_pickle(\"bookDF_female.pickle\")\n",
    "bookDF_female.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2. Data Preprocessing (tokenizing, POS tagging, stopwords removing)\n",
    "\n",
    "***Section Overview***\n",
    "\n",
    "All the codes were run on male and female dataframe separately. I should have combine the male and female dataframes and just add a column called \"gender\" to distinguish. But somehow, it did not occur to me at the time. Since running the codes separately like this does not influence the results of pre-processing (besides being inefficient) and the codes above takes rather long. I will leave the codes like this. \n",
    "\n",
    "Here are the things that I completed with the codes below. These tasks do not necessarily get completed in different code blocks (e.g., task 1 and task 2 are done in one function).\n",
    "\n",
    "**Task 1**: In the previous section, the 30 chapters of one book is stored within a dictionary in one cell. Here, I expand this 30-item dictionary and make each chapter correspond to one cell.  \n",
    "\n",
    "**Task 2**: I use `jieba` package to tokenize book introduction and the 30 chapters of each book, I stored the results in separate columns (12+ 31 columns).\n",
    "\n",
    "**Task 3**: Parallel to task 2, I use POS tagging function of `jieba` to process the book introduction text and the 30-chapter text so that the novel text is tokenized and tagged. (12+ 31+ 31 columns)\n",
    "\n",
    "**Task 4**: I construct the list of stopwords from three sources:\n",
    "\n",
    "    1) I download a list from the internet, which consisits of 738 words. \n",
    "    2) POS tags tag all the things that `jieba` cannot recognize as \"x\". I look up all the tokens of the book introduction that were tagged as \"x\", and I consider them as stopwords. This step supplements the stopword list I found on the internet especially because the Chinese punctuation is coded differently from English punctuation. For example, in Chinese, comma is \"，\" but in English it is \",\". \n",
    "    3) I manually included a few words that occur very often, but are not related to the content of the novel, including '完本'full book, '书号'book number, '群号'group number, '新书'new book, '书友'bookmate, '小说'novel, '作品'production, '读者群'reader group, '读者'reader, '大家'we, '时候'when, '书'book.\n",
    "\n",
    "**Task 5**: I remove stopwords for tokenized book introduction, for tokenized tagged book introduction, for the 30-column of tokenized chapters, and for the 30-column of tagged chapter, which gives me 62 more columns. This sums up to 12+ 31+ 31+ 62= 136 columns. I store the 500*136 male matrix and 500*136 female matrix separately in pickle files. \n",
    "\n",
    "After this section, the dataset is ready for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 2 ~ Male-part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bookDF_male= pd.read_pickle(\"bookDF_male.pickle\")\n",
    "bookDF_female= pd.read_pickle(\"bookDF_female.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_ch(thirty_ch):\n",
    "    #Take the 30-chapter dictionary as input\n",
    "    #Tokenize the 30 chapters separately and output a list of 30 tokenized word lists (list of list)\n",
    "    thirty_ch_list= []\n",
    "    for ch in thirty_ch.keys():\n",
    "        ch_list= jieba.lcut(thirty_ch[ch], cut_all= False)\n",
    "        thirty_ch_list+= [ch_list]\n",
    "    return thirty_ch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Male\n",
    "##Tokenize the book chapters. For each chapter (of each book), present under the column \"ch?_token\"\n",
    "row_DF_500= pd.DataFrame()\n",
    "for i in range(bookDF_male.shape[0]):\n",
    "    #Using the tokenize_ch() function defined above\n",
    "    book_ch_list= tokenize_ch(bookDF_male[\"example_text\"].iloc[i])\n",
    "    row_DF= pd.DataFrame()\n",
    "    for i in range(30):\n",
    "        row_DF[\"ch\"+str(i+1)+\"_token\"]= [book_ch_list[i]]\n",
    "    row_DF_500= pd.concat([row_DF_500, row_DF], axis= 0)\n",
    "print(row_DF_500.shape)\n",
    "\n",
    "\n",
    "#Creating a new dataframe\n",
    "#So as not save any thing to over-write the original data\n",
    "bookDF_male_tokenized= pd.concat([bookDF_male, row_DF_500], axis= 1)\n",
    "print(bookDF_male_tokenized.shape)\n",
    "\n",
    "##Tokenize the book introduction and add a column called \"intro_token\"\n",
    "bookDF_male_tokenized[\"intro_token\"]= bookDF_male[\"intro\"].apply(lambda x: jieba.lcut(x))\n",
    "#bookDF_male[\"intro_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pos_cut(a_string):\n",
    "    word_tag_list= []\n",
    "    words_poscut= pseg.cut(a_string)\n",
    "    for word, tag in words_poscut:\n",
    "        word_tag_list+= [(word, tag)]\n",
    "    return word_tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Male\n",
    "#This takes really long time... \n",
    "row_tagDF_500= pd.DataFrame()\n",
    "for i in range(bookDF_male_tokenized.shape[0]):\n",
    "    a_book= bookDF_male_tokenized[\"example_text\"].iloc[i]   \n",
    "    row_tagDF= pd.DataFrame()\n",
    "    for j in range(30):\n",
    "        row_tagDF[\"ch\"+str(j+1)+\"_tag\"]= [pos_cut(a_book[j+1])]\n",
    "    row_tagDF_500= pd.concat([row_tagDF_500, row_tagDF], axis= 0)\n",
    "print(row_tagDF_500.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sum the columns all up\n",
    "week2= '/Users/ShiyuZhang/Documents/SourceTree/Content-Analysis/2-Corpus-Linguistics'\n",
    "os.chdir(week2)\n",
    "os.chdir(\"..\")\n",
    "bookDF_male= pd.read_pickle(\"bookDF_male.pickle\")\n",
    "bookDF_female= pd.read_pickle(\"bookDF_female.pickle\")\n",
    "os.chdir(week2)\n",
    "\n",
    "\n",
    "bookDF_male_tokenized= pd.concat([bookDF_male, \n",
    "                                  bookDF_male_tokenized[\"intro_token\"], row_DF_500,\n",
    "                                  bookDF_male_tokenized[\"intro_tag\"], row_tagDF_500], axis= 1)\n",
    "bookDF_male_tokenized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '?', '_', '“', '”', '、', '。', '《', '》', '一', '一些', '一何', '一则', '一方面', '一旦', '一来', '一样', '一般', '万一', '上', '上下', '下', '不', '不仅', '不但', '不光', '不单', '不只', '不外乎', '不如', '不妨', '不尽', '不尽然', '不得', '不怕', '不惟', '不成', '不拘', '不料', '不是', '不比', '不然', '不特', '不独', '不管', '不至于', '不若', '不论', '不过', '不问', '与', '与其', '与其说', '与否', '与此同时', '且', '且不说', '且说', '两者', '个', '个别', '临', '为', '为了', '为什么', '为何', '为止', '为此', '为着', '乃', '乃至', '乃至于', '么', '之', '之一', '之所以', '之类', '乌乎', '乎', '乘', '也', '也好', '也罢', '了', '二来', '于', '于是', '于是乎', '云云', '云尔', '些', '亦', '人', '人们', '人家', '什么', '什么样', '今', '介于', '仍', '仍旧', '从', '从此', '从而', '他人', '以', '以上', '以为', '以便', '以免', '以及', '以故', '以期', '以来', '以至', '以至于', '以致', '们', '任', '任何', '任凭', '似的', '但', '但凡', '但是', '何', '何以', '何况', '何处', '何时', '余外', '作为', '你', '你们', '使', '使得', '例如', '依', '依据', '依照', '便于', '俺', '俺们', '倘', '倘使', '倘或', '倘然', '倘若', '借', '假使', '假如', '假若', '傥然', '像', '儿', '先不先', '光是', '全体', '全部', '兮', '关于', '其', '其一', '其中', '其二', '其他', '其余', '其它', '其次', '具体地说', '具体说来', '兼之', '内', '再', '再其次', '再则', '再有', '再者', '再者说', '再说', '冒', '冲', '况且', '几', '几时', '凡', '凡是', '凭', '凭借', '出于', '出来', '分别', '则', '则甚', '别', '别人', '别处', '别是', '别的', '别管', '别说', '到', '前后', '前此', '前者', '加之', '加以', '即', '即令', '即使', '即便', '即如', '即或', '即若', '却', '去', '又', '又及', '及', '及其', '及至', '反之', '反而', '反过来', '反过来说', '受到', '另', '另一方面', '另外', '另悉', '只', '只当', '只怕', '只是', '只有', '只消', '只要', '只限', '叫', '可', '可以', '可是', '可见', '各', '各个', '各位', '各种', '各自', '同', '同时', '后', '后者', '向', '向使', '向着', '吓', '吗', '否则', '吧', '吧哒', '吱', '呀', '呃', '呕', '呗', '呜', '呜呼', '呢', '呵', '呵呵', '呸', '呼哧', '咋', '和', '咚', '咦', '咧', '咱', '咱们', '咳', '哇', '哈', '哈哈', '哉', '哎', '哎呀', '哎哟', '哗', '哟', '哦', '哩', '哪', '哪个', '哪些', '哪儿', '哪天', '哪年', '哪怕', '哪样', '哪边', '哪里', '哼', '哼唷', '唉', '唯有', '啊', '啐', '啥', '啦', '啪达', '啷当', '喂', '喏', '喔唷', '喽', '嗡', '嗡嗡', '嗬', '嗯', '嗳', '嘎', '嘎登', '嘘', '嘛', '嘻', '嘿', '嘿嘿', '因', '因为', '因了', '因此', '因着', '因而', '固然', '在', '在下', '在于', '地', '基于', '处在', '多', '多么', '多少', '大', '大家', '好', '如', '如上', '如上所述', '如下', '如何', '如其', '如同', '如是', '如果', '如此', '如若', '始而', '孰料', '孰知', '宁', '宁可', '宁愿', '宁肯', '它', '它们', '对', '对于', '对待', '对方', '对比', '将', '小', '尔', '尔后', '尔尔', '尚且', '就', '就是', '就是了', '就是说', '就算', '就要', '尽', '尽管', '尽管如此', '岂但', '己', '已', '已矣', '巴', '巴巴', '并', '并且', '并非', '庶乎', '庶几', '开外', '开始', '归', '归齐', '当', '当地', '当然', '当着', '彼', '彼时', '彼此', '往', '待', '很', '得', '得了', '怎', '怎么', '怎么办', '怎么样', '怎奈', '怎样', '总之', '总的来看', '总的来说', '总的说来', '总而言之', '恰恰相反', '您', '惟其', '慢说', '我', '我们', '或', '或则', '或是', '或曰', '或者', '截至', '所', '所以', '所在', '所幸', '所有', '才', '才能', '打', '打从', '把', '抑或', '拿', '按', '按照', '换句话说', '换言之', '据', '据此', '接着', '故', '故此', '故而', '旁人', '无', '无宁', '无论', '既', '既往', '既是', '既然', '时候', '是', '是以', '是的', '曾', '替', '替代', '有', '有些', '有关', '有及', '有时', '有的', '望', '朝', '朝着', '本', '本人', '本地', '本着', '本身', '来', '来着', '来自', '来说', '极了', '果然', '果真', '某', '某个', '某些', '某某', '根据', '欤', '正值', '正如', '正巧', '正是', '此', '此地', '此处', '此外', '此时', '此次', '此间', '毋宁', '每', '每当', '比', '比及', '比如', '比方', '没奈何', '沿', '沿着', '漫说', '焉', '然则', '然后', '然而', '照', '照着', '犹且', '犹自', '甚且', '甚么', '甚或', '甚而', '甚至', '甚至于', '用', '用来', '由', '由于', '由是', '由此', '由此可见', '的', '的确', '的话', '直到', '相对而言', '省得', '看', '眨眼', '着', '着呢', '矣', '矣乎', '矣哉', '离', '竟而', '第', '等', '等到', '等等', '简言之', '管', '类如', '紧接着', '纵', '纵令', '纵使', '纵然', '经', '经过', '结果', '给', '继之', '继后', '继而', '综上所述', '罢了', '者', '而', '而且', '而况', '而后', '而外', '而已', '而是', '而言', '能', '能否', '腾', '自', '自个儿', '自从', '自各儿', '自后', '自家', '自己', '自打', '自身', '至', '至于', '至今', '至若', '致', '般的', '若', '若夫', '若是', '若果', '若非', '莫不然', '莫如', '莫若', '虽', '虽则', '虽然', '虽说', '被', '要', '要不', '要不是', '要不然', '要么', '要是', '譬喻', '譬如', '让', '许多', '论', '设使', '设或', '设若', '诚如', '诚然', '该', '说来', '诸', '诸位', '诸如', '谁', '谁人', '谁料', '谁知', '贼死', '赖以', '赶', '起', '起见', '趁', '趁着', '越是', '距', '跟', '较', '较之', '边', '过', '还', '还是', '还有', '还要', '这', '这一来', '这个', '这么', '这么些', '这么样', '这么点儿', '这些', '这会儿', '这儿', '这就是说', '这时', '这样', '这次', '这般', '这边', '这里', '进而', '连', '连同', '逐步', '通过', '遵循', '遵照', '那', '那个', '那么', '那么些', '那么样', '那些', '那会儿', '那儿', '那时', '那样', '那般', '那边', '那里', '都', '鄙人', '鉴于', '针对', '阿', '除', '除了', '除外', '除开', '除此之外', '除非', '随', '随后', '随时', '随着', '难道说', '非但', '非徒', '非特', '非独', '靠', '顺', '顺着', '首先', '！', '，', '：', '；', '？']\n",
      "738\n"
     ]
    }
   ],
   "source": [
    "##I found a list of Chinese stop words online and download it.\n",
    "fr= open(\"Chinese_stop_words.txt\", encoding= \"utf-8\")  \n",
    "stopw_ch= fr.read().split()\n",
    "fr.close()\n",
    "print(stopw_ch)\n",
    "print(len(stopw_ch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['，', '。', ' ', '…', '《', '》', '！', '？', '‘', '’', '、', '：', ':', '２', '（', '）', '—', '*', '；', '“', '”', '\\r', '!', '?', ',', '=', '【', '】', '~', 'V', '％', '-', 'ｃ', 'X', 'ｅ', '^', '_', '<', 'a', '\"', '/', '#', '>', 'Ｐ', 'Ｓ', '＜', '＞', '+', '%', '～', '.', '##########', '[', ']', '＝', '·', 'ㄟ', '(', '▔', ')', 'ㄏ', '－', '2', 'ｍ', '@', '８', '６', '０', 'の', '剣', 'を', '喰', 'ら', 'え', '啾', '|', '▍', '1', '╰', '☆', '＋', '∽', '\\xa0', '3', '0', '&#', '�', '╄', '\\\\', 'Ⅱ', 'u', '①', '②', '③', '④', '．', 'Ｙ', '{', '}', '###########################', '4', '6', '7', '8', 'A', 'B', '&', '┃', 'ゞ', '「', '」', '狷', '→', ';', '※', '+++++++++++++++++++++++++++++++++++++++++++++++', '∝', '灞', '＊', 'Ｑ', '+++++++++++++++++++++++++++++++++++++']\n"
     ]
    }
   ],
   "source": [
    "##I rely on the book introductions to find more stop words. \n",
    "##If the POS cannot identify the element and tags it as \"x\", it is my stop word\n",
    "## The ones that are signs:\n",
    "bookDF_male_tokenized= pd.read_pickle(\"bookDF_male_tokenized.pickle\")\n",
    "stopw_x= []\n",
    "for w, t in bookDF_male_tokenized[\"intro_tag\"].sum():\n",
    "    if t== \"x\" and (w not in stopw_x):\n",
    "        stopw_x+= [w]\n",
    "print(stopw_x)\n",
    "print(len(stopw_x))\n",
    "\n",
    "## Manually detect the most common words that are obviously irrelevants:\n",
    "fdist_tag_word = nltk.ConditionalFreqDist((t, w) for w, t in bookDF_male_tokenized['intro_tag'].sum())\n",
    "#print(\"the 50 most common a:\", \"\\n\", fdist_tag_word[\"a\"].most_common(50))\n",
    "#print()\n",
    "#print(\"the 50 most common an:\", \"\\n\", fdist_tag_word[\"an\"].most_common(50))\n",
    "#print()\n",
    "#print(\"the 50 most common ad:\", \"\\n\", fdist_tag_word[\"ad\"].most_common(50))\n",
    "#print()\n",
    "#print(\"the 50 most common ag:\", \"\\n\", fdist_tag_word[\"ag\"].most_common(50))\n",
    "#print()\n",
    "#print(\"the 50 most common n:\", \"\\n\", fdist_tag_word[\"n\"].most_common(50))\n",
    "\n",
    "stopw_manual= ['完本', '书号', '群号', '新书', '书友', '小说', '作品', '读者群', '读者', '大家'\n",
    "              '时候', '书']\n",
    "            #These are the ones that are related to the novel context but not to the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Combining three list of stopwords \n",
    "##download+ xtag+ manually detected a few\n",
    "stopw_total= list(set(stopw_ch+ stopw_x+ stopw_manual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Removing the stop words from the text\n",
    "def remove_stopw(wordlist, stopw):\n",
    "    cleaned_list= []\n",
    "    for w in wordlist:\n",
    "        if w not in stopw:\n",
    "            cleaned_list+= [w]\n",
    "    return cleaned_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bookDF_male_tokenized[\"intro_clean\"]= \\\n",
    "bookDF_male_tokenized[\"intro_token\"].apply(lambda x: remove_stopw(x, stopw_total))\n",
    "#bookDF_male_tokenized[\"intro_clean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    bookDF_male_tokenized[\"ch\"+ str(i+1)+ \"_clean\"]=\\\n",
    "    bookDF_male_tokenized[\"ch\"+ str(i+1)+ \"_token\"].apply(lambda x: remove_stopw(x, stopw_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stop_tag(a_list_word_tag, stopw):\n",
    "    clean_list= []\n",
    "    for w, t in a_list_word_tag:\n",
    "        if w not in stopw:\n",
    "            clean_list+= [(w, t)]\n",
    "    return clean_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bookDF_male_tokenized[\"intro_tag_clean\"]= bookDF_male_tokenized[\"intro_tag\"].apply(lambda x: remove_stop_tag(x, stopw_total))\n",
    "\n",
    "for i in range(30):\n",
    "    bookDF_male_tokenized[\"ch\"+str(i+1)+\"_tag_clean\"]= \\\n",
    "    bookDF_male_tokenized[\"ch\"+str(i+1)+\"_tag\"].apply(lambda x: remove_stop_tag(x, stopw_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bookDF_male_tokenized.to_pickle(\"bookDF_male_tokenized.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 2~ Female-Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/86/kbyspkys411_n8krrz1xl9cc0000gn/T/jieba.cache\n",
      "Loading model cost 1.435 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 30)\n",
      "(500, 42)\n"
     ]
    }
   ],
   "source": [
    "##Female\n",
    "##Tokenize the book chapters. For each chapter (of each book), present under the column \"ch?_token\"\n",
    "row_DF_500= pd.DataFrame()\n",
    "for i in range(bookDF_female.shape[0]):\n",
    "    #Using the tokenize_ch() function defined above\n",
    "    book_ch_list= tokenize_ch(bookDF_female[\"example_text\"].iloc[i])\n",
    "    row_DF= pd.DataFrame()\n",
    "    for i in range(30):\n",
    "        row_DF[\"ch\"+str(i+1)+\"_token\"]= [book_ch_list[i]]\n",
    "    row_DF_500= pd.concat([row_DF_500, row_DF], axis= 0)\n",
    "print(row_DF_500.shape)\n",
    "\n",
    "\n",
    "#Creating a new dataframe\n",
    "#So as not save any thing to over-write the original data\n",
    "bookDF_female_tokenized= pd.concat([bookDF_female, row_DF_500], axis= 1)\n",
    "print(bookDF_female_tokenized.shape)\n",
    "\n",
    "##Tokenize the book introduction and add a column called \"intro_token\"\n",
    "bookDF_female_tokenized[\"intro_token\"]= bookDF_female[\"intro\"].apply(lambda x: jieba.lcut(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bookDF_female_tokenized[\"intro_tag\"]= bookDF_female_tokenized[\"intro\"].apply(lambda x: pos_cut(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 30)\n"
     ]
    }
   ],
   "source": [
    "##Female\n",
    "#This takes really long time... \n",
    "row_tagDF_500= pd.DataFrame()\n",
    "for i in range(bookDF_female_tokenized.shape[0]):\n",
    "    a_book= bookDF_female_tokenized[\"example_text\"].iloc[i]   \n",
    "    row_tagDF= pd.DataFrame()\n",
    "    for j in range(30):\n",
    "        row_tagDF[\"ch\"+str(j+1)+\"_tag\"]= [pos_cut(a_book[j+1])]\n",
    "    row_tagDF_500= pd.concat([row_tagDF_500, row_tagDF], axis= 0)\n",
    "print(row_tagDF_500.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 74)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sum the columns all up\n",
    "bookDF_female= pd.read_pickle(\"bookDF_female.pickle\")\n",
    "\n",
    "\n",
    "bookDF_female_tokenized= pd.concat([bookDF_female, \n",
    "                                  bookDF_female_tokenized[\"intro_token\"], row_DF_500,\n",
    "                                  bookDF_female_tokenized[\"intro_tag\"], row_tagDF_500], axis= 1)\n",
    "bookDF_female_tokenized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookDF_female_tokenized[\"intro_clean\"]= \\\n",
    "bookDF_female_tokenized[\"intro_token\"].apply(lambda x: remove_stopw(x, stopw_total))\n",
    "#bookDF_female_tokenized[\"intro_clean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    bookDF_female_tokenized[\"ch\"+ str(i+1)+ \"_clean\"]=\\\n",
    "    bookDF_female_tokenized[\"ch\"+ str(i+1)+ \"_token\"].apply(lambda x: remove_stopw(x, stopw_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up the tags\n",
    "bookDF_female_tokenized[\"intro_tag_clean\"]= bookDF_female_tokenized[\"intro_tag\"].apply(lambda x: remove_stop_tag(x, stopw_total))\n",
    "\n",
    "for i in range(30):\n",
    "    bookDF_female_tokenized[\"ch\"+str(i+1)+\"_tag_clean\"]= \\\n",
    "    bookDF_female_tokenized[\"ch\"+str(i+1)+\"_tag\"].apply(lambda x: remove_stop_tag(x, stopw_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'click_count', 'example_text', 'intro',\n",
       "       'intro_mentioned_books', 'name', 'recom_count', 'tags', 'word_count',\n",
       "       'num_bookmarked',\n",
       "       ...\n",
       "       'ch21_tag_clean', 'ch22_tag_clean', 'ch23_tag_clean', 'ch24_tag_clean',\n",
       "       'ch25_tag_clean', 'ch26_tag_clean', 'ch27_tag_clean', 'ch28_tag_clean',\n",
       "       'ch29_tag_clean', 'ch30_tag_clean'],\n",
       "      dtype='object', length=136)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookDF_female_tokenized.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bookDF_female_tokenized.to_pickle(\"bookDF_female_tokenized.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3 Describing the novels\n",
    "\n",
    "***Section Overview***\n",
    "\n",
    "In this section, I perform descriptive analysis to introduce the dataset. \n",
    "\n",
    "**Description 1**: Number of bookmarked. The website offers different ways of ranking the novels, such as \"original production board\", \"24 hours popularity board\", and \"completed novel board\". The board I scraped is called \"bookmark board\" which presumably include the novels that have been bookmarked for the most amount of times. I calculate the range and mean of the times these 1000 novels were bookmarked. \n",
    "\n",
    "**Description 2**: Author. Some popular authors contribute more than one novel to this board. I count of the number of authors included in this dataset.\n",
    "\n",
    "**Description 3**: Tags. The website gives tags to the novels. I check the kind of tags given to these novels. \n",
    "\n",
    "**Description 4**: Topics through network graph. Using the most common nouns, verbs and adjectives used in these novels (weighted by tf-idf), I contrust a network that shows the topics and characters common in these novels. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookDF_male_tokenized= pd.read_pickle(\"bookDF_male_tokenized.pickle\")\n",
    "bookDF_female_tokenized= pd.read_pickle(\"bookDF_female_tokenized.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male novels, bookmark average: 262457.6081632653\n",
      "male novels, bookmark SD: 180588.10361499802\n",
      "male novels, bookmark max: 1231847\n",
      "male novels, bookmark min: 112443\n",
      "\n",
      "female novels, bookmark average: 112080.534\n",
      "female novels, bookmark SD: 92330.59444959548\n",
      "female novels, bookmark max: 987034\n",
      "female novels, bookmark min: 48959\n"
     ]
    }
   ],
   "source": [
    "#Descriptive statistics of the male and female novels\n",
    "print(\"male novels, bookmark average:\", bookDF_male_tokenized[\"num_bookmarked\"][10:].mean())\n",
    "print(\"male novels, bookmark SD:\", bookDF_male_tokenized[\"num_bookmarked\"][10:].std())\n",
    "print(\"male novels, bookmark max:\", bookDF_male_tokenized[\"num_bookmarked\"][10:].max())\n",
    "print(\"male novels, bookmark min:\", bookDF_male_tokenized[\"num_bookmarked\"][10:].min())\n",
    "print()\n",
    "\n",
    "print(\"female novels, bookmark average:\", bookDF_female_tokenized[\"num_bookmarked\"].mean())\n",
    "print(\"female novels, bookmark SD:\", bookDF_female_tokenized[\"num_bookmarked\"].std())\n",
    "print(\"female novels, bookmark max:\", bookDF_female_tokenized[\"num_bookmarked\"].max())\n",
    "print(\"female novels, bookmark min:\", bookDF_female_tokenized[\"num_bookmarked\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many authors contribute to the 500 male novels: 311\n",
      "How many authors contribute to the 500 female novels: 284\n"
     ]
    }
   ],
   "source": [
    "##Authors\n",
    "\n",
    "print(\"How many authors contribute to the 500 male novels:\", \n",
    "      len(set(bookDF_male_tokenized[\"author\"])))\n",
    "\n",
    "# author_dic_male is a dictionary that documents the novels written by each author\n",
    "name_author_male= bookDF_male_tokenized[[\"author\", \"name\"]]\n",
    "author_dic_male= {}\n",
    "\n",
    "for index, row in name_author_male.iterrows():\n",
    "    author= row[\"author\"]\n",
    "    name= row[\"name\"]  \n",
    "    if author not in author_dic_male:\n",
    "        author_dic_male[author]= [name]\n",
    "    else: \n",
    "        author_dic_male[author]+= [name]    \n",
    "\n",
    "\n",
    "print(\"How many authors contribute to the 500 female novels:\", \n",
    "      len(set(bookDF_female_tokenized[\"author\"])))\n",
    "\n",
    "name_author_female= bookDF_female_tokenized[[\"author\", \"name\"]]\n",
    "\n",
    "# author_dic_female is a dictionary that documents the novels written by each author\n",
    "name_author_female= bookDF_female_tokenized[[\"author\", \"name\"]]\n",
    "author_dic_female= {}\n",
    "\n",
    "for index, row in name_author_female.iterrows():\n",
    "    author= row[\"author\"]\n",
    "    name= row[\"name\"]  \n",
    "    if author not in author_dic_female:\n",
    "        author_dic_female[author]= [name]\n",
    "    else: \n",
    "        author_dic_female[author]+= [name] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('玄幻', 124), ('都市', 97), ('仙侠', 79), ('历史', 74), ('东方玄幻', 60), ('都市生活', 58), ('二次元', 57), ('异世大陆', 55), ('科幻', 49), ('游戏', 37), ('幻想修仙', 35), ('异术超能', 31), ('虚拟网游', 26), ('两宋元明', 23), ('修真文明', 20), ('时空穿梭', 20), ('现代修真', 18), ('架空历史', 18), ('两晋隋唐', 16), ('奇幻', 12), ('秦汉三国', 12), ('未来世界', 8), ('末世危机', 8), ('游戏异界', 8), ('武侠', 7), ('古武机甲', 7), ('王朝争霸', 7), ('现实', 7), ('灵异', 6), ('衍生同人', 5), ('青春校园', 5), ('现代魔法', 4), ('寻墓探险', 4), ('武侠幻想', 4), ('星际文明', 4), ('现实百态', 4), ('神话修真', 4), ('体育', 4), ('足球运动', 4), ('剑与魔法', 3), ('电子竞技', 3), ('国术无双', 3), ('古典仙侠', 2), ('史诗奇幻', 2), ('黑暗幻想', 2), ('娱乐明星', 2), ('高武世界', 2), ('五代十国', 2), ('进化变异', 2), ('清史民国', 1), ('上古先秦', 1), ('变身入替', 1), ('外国历史', 1), ('灵异鬼怪', 1), ('恐怖惊悚', 1), ('另类幻想', 1), ('军事', 1), ('战争幻想', 1), ('恩怨情仇', 1)]\n",
      "\n",
      "[('古代言情', 329), ('古典架空', 169), ('穿越奇情', 113), ('现代言情', 66), ('豪门世家', 45), ('玄幻言情', 41), ('经商种田', 27), ('仙侠奇缘', 20), ('科幻空间', 20), ('东方玄幻', 19), ('西方奇幻', 18), ('古典仙侠', 18), ('宫闱宅斗', 17), ('都市生活', 11), ('末世危机', 8), ('游戏竞技', 8), ('网游情缘', 8), ('浪漫青春', 7), ('未来世界', 7), ('青春校园', 6), ('悬疑灵异', 5), ('星际恋歌', 5), ('婚恋情缘', 4), ('N次元', 4), ('同人衍生', 4), ('娱乐明星', 3), ('异族恋情', 3), ('都市异能', 3), ('古代情缘', 3), ('恐怖惊悚', 2), ('现代修真', 2), ('异世大陆', 1), ('灵异鬼怪', 1), ('青春纯爱', 1), ('推理侦探', 1), ('悬疑探险', 1)]\n"
     ]
    }
   ],
   "source": [
    "##Tags\n",
    "tag_dic_male= {}\n",
    "for b_tag in bookDF_male_tokenized[\"tags\"]:\n",
    "    tags= b_tag.split(\";\")[:-1]\n",
    "    for tag in tags:\n",
    "        if tag not in tag_dic_male:\n",
    "            tag_dic_male[tag]= 1\n",
    "        else:\n",
    "            tag_dic_male[tag]+= 1\n",
    "tag_dic_male_sorted= sorted(tag_dic_male.items(), key= operator.itemgetter(1), reverse= True)\n",
    "print(tag_dic_male_sorted)\n",
    "print()\n",
    "\n",
    "tag_dic_female= {}\n",
    "for b_tag in bookDF_female_tokenized[\"tags\"]:\n",
    "    tags= b_tag.split(\";\")[:-1]\n",
    "    for tag in tags:\n",
    "        if tag not in tag_dic_female:\n",
    "            tag_dic_female[tag]= 1\n",
    "        else:\n",
    "            tag_dic_female[tag]+= 1\n",
    "tag_dic_female_sorted= sorted(tag_dic_female.items(), key= operator.itemgetter(1), reverse= True)\n",
    "print(tag_dic_female_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浩瀚宇宙某个偏僻星域中，一点朦胧金光以某种固定速度在漆黑星空中徐徐飞行着，并不时从中传出阵阵啼鸣之声，若断若续，若有若无，仿佛泣血之音，又如九幽狞笑。不知过了多少年后，前方蓦然出现一颗蔚蓝色巨大星球。“轰”的一声巨响！金光在星球引力作用下，以惊人速度向巨大星球直冲而去，并在接触星球表面大气的瞬间，化为一团汹汹燃烧流星，向下方一片海域坠落而去。……大齐天元九年，有灵官上禀朝廷，有天外异物落入东海之内，化为滔天巨浪淹没二十余岛屿，越府沿海数县被巨浪波及，毁房屋万间，百姓家畜死伤无数——《东洲记》\n"
     ]
    }
   ],
   "source": [
    "for a in bookDF_male_tokenized[\"example_text\"].iloc[2].values():\n",
    "    print(a)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83448.786\n",
      "76612.942\n"
     ]
    }
   ],
   "source": [
    "def count_length(novel_DF):\n",
    "    text_30_DF= novel_DF[\"example_text\"]\n",
    "    total_word_list= []\n",
    "    for i in range(novel_DF.shape[0]): \n",
    "        total_word= 0\n",
    "        a_book= text_30_DF.iloc[i]\n",
    "        for a_ch in a_book.values():\n",
    "            total_word+= len(a_ch)\n",
    "        total_word_list+= [total_word]\n",
    "    return total_word_list\n",
    "\n",
    "        \n",
    "book_length_male= count_length(bookDF_male_tokenized)\n",
    "book_length_female= count_length(bookDF_female_tokenized)\n",
    "    \n",
    "print(np.mean(book_length_male))\n",
    "print(np.mean(book_length_female))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Network\n",
    "\n",
    "For the semantic network, only adjectives, verbs and some nouns are potentially useful for me. So I build list of words as vocabulary for selecting relevant words. POS tagging does more than detect adj, n and v; it can separate different kinds of adj, n and v. I only include certain kinds:\n",
    "\n",
    "    describing words (I called this category adj in codes for simplicity): \n",
    "    \"a\"-形容词-adjective, \"ag\"-形语素-？, \"ad\"-副词-adverb, \"an\"-名形词-？, \"i\"-成语-idiom, \"z\"-状态词-status word\n",
    "    \n",
    "    noun:\n",
    "    \"n\"-名词-noun, \"ns\"-地名-location name, \"ng\"-名语素-?\n",
    "    But I exclude: \"nr\"-人名-human, \"nt\"-机构团体-organization, \"nz\"-专有名词-specific nouns\n",
    "    \n",
    "    verbs: \"vg\"-动语素-?, \"v\"-动词-verb, \"vd\"-副动词-?, \"vn\"-动名词-?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(DF, keep_tag):\n",
    "    #Input 1: a dataframe that contains 30 columns (30 chapter) of books. \n",
    "    #Each column contains a list of word tag tuple\n",
    "    #Input 2: words with corresponding POS tags that I want to keep \n",
    "    #Output a vocabulary list\n",
    "    voc= set()\n",
    "    tag_column= []\n",
    "    for i in range(30):\n",
    "        tag_column+= [\"ch\"+str(i+1)+\"_tag\"]\n",
    "    for j in range(DF.shape[0]):\n",
    "        for col in tag_column:\n",
    "            word_tag_list= DF.iloc[j][col]\n",
    "            for w, t in word_tag_list:\n",
    "                if t in keep_tag:\n",
    "                    voc.add(w)\n",
    "    return voc\n",
    "            \n",
    "keep_tag_adj= [\"a\", \"ag\", \"ad\", \"an\", \"i\", \"z\"]\n",
    "keep_tag_v= [\"vg\", \"v\", \"vd\", \"vn\"]\n",
    "keep_tag_n= [\"n\", \"ns\", \"ng\"]\n",
    "\n",
    "\n",
    "\n",
    "helper_col= []\n",
    "for i in range(30):\n",
    "    helper_col+= [\"ch\"+str(i+1)+\"_tag\"]\n",
    "\n",
    "\"\"\"Three dataset: male, female, combined\"\"\"\n",
    "bookDF_tag= pd.concat([bookDF_male_tokenized[helper_col], \n",
    "                       bookDF_female_tokenized[helper_col]], \n",
    "                      axis= 0)\n",
    "#bookDF_tag_male= bookDF_male_tokenized[helper_col]\n",
    "#bookDF_tag_female= bookDF_female_tokenized[helper_col]\n",
    "\n",
    "\n",
    "voc_adj= build_vocabulary(bookDF_tag, keep_tag_adj)\n",
    "voc_v= build_vocabulary(bookDF_tag, keep_tag_v)\n",
    "voc_n= build_vocabulary(bookDF_tag, keep_tag_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_col= []\n",
    "for i in range(30):\n",
    "    helper_col+= [\"ch\"+str(i+1)+\"_clean\"]\n",
    "        \n",
    "bookDF_ch= pd.concat([bookDF_male_tokenized[helper_col], \n",
    "                      bookDF_female_tokenized[helper_col]], \n",
    "                     axis= 0)\n",
    "#bookDF_ch_male= bookDF_male_tokenized[helper_col]\n",
    "#bookDF_ch_female= bookDF_female_tokenized[helper_col]\n",
    "\n",
    "\n",
    "def collapse_30_ch_to_string(DF):\n",
    "    #This function collapses the 30 chapters (30 columns) of a book into one cell\n",
    "    #Then sum up the list of each book to a string, (words separated by space)\n",
    "    helper_lis= [] \n",
    "    for i in range(DF.shape[0]):\n",
    "        cell= []\n",
    "        for col in helper_col:\n",
    "            cell+= DF.iloc[i][col]\n",
    "\n",
    "        helper_lis+= [cell]\n",
    "\n",
    "    helper_str= []\n",
    "    for i in range(DF.shape[0]):\n",
    "        helper_str+= [\" \".join(helper_lis[i])]\n",
    "\n",
    "    all_ch_string_DF= pd.DataFrame({\"all_ch_string\": helper_str})\n",
    "    \n",
    "    return all_ch_string_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ch_string_DF= collapse_30_ch_to_string(bookDF_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 149845)\n",
      "(1000, 149845)\n",
      "(1000, 149845)\n"
     ]
    }
   ],
   "source": [
    "def output_distin_words(all_ch_string_DF, voc_list, how_many= 1000):\n",
    "    \"\"\"Input 1: A dataframe with a column named \"all_ch_string\" in which all words are \n",
    "    separated by space and joined to a string\n",
    "    Input 2: a vocabulary list that contains the target words for tf-idf vectorizer\n",
    "    Input 3: optional. For specifying how many distinctive words I want\n",
    "    \n",
    "    The tf-idf matrix will be ranked by (target) words' weighted frequency\"\"\"\n",
    "\n",
    "    my_tf_vectorizer= sklearn.feature_extraction.text.TfidfVectorizer(max_df=0.5, \n",
    "                                                                      min_df=3)\n",
    "    novel_tf_vects= my_tf_vectorizer.fit_transform(all_ch_string_DF[\"all_ch_string\"])\n",
    "    print(novel_tf_vects.shape)  \n",
    "    \n",
    "    #Rank the tf-idf features\n",
    "    terms = my_tf_vectorizer.get_feature_names()\n",
    "    sums = novel_tf_vects.sum(axis=0)\n",
    "\n",
    "    # connecting term to its sums frequency\n",
    "    data = []\n",
    "    for col, term in enumerate(terms):\n",
    "        data.append( (term, sums[0,col] ))\n",
    "\n",
    "    ranking = pd.DataFrame(data, columns=['term','rank'])\n",
    "    ranked= ranking.sort_values('rank', ascending=False)\n",
    "    \n",
    "    target= []\n",
    "    for t in ranked[\"term\"]:\n",
    "        if len(target)>= how_many:\n",
    "            break\n",
    "        if t in set(voc_list): #set() permits faster lookup\n",
    "            target+= [t]\n",
    "    return target\n",
    " \n",
    "#dis stands for distintive\n",
    "dis_adj= output_distin_words(all_ch_string_DF, voc_adj)\n",
    "dis_n= output_distin_words(all_ch_string_DF, voc_n)\n",
    "dis_v= output_distin_words(all_ch_string_DF, voc_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    7\n",
       "2    9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= pd.DataFrame([[1, 2, 3],\n",
    "                 [4, 5, 6]])\n",
    "a.sum(axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(dis_adj))\n",
    "print(len(dis_n))\n",
    "print(len(dis_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\"> The above operation identifies the target words that I want to build networks with (i.e., the nodes). In the following, I will use the windows next to each target word to build network because I am interested in linking words through the local context.\n",
    "\n",
    "<span style=\"color:green\"> I use windows next to these target words as the local context. Since I am interested in connection between words, I take windows by counting 10 words rightword (i.e., forward but not backward). \n",
    "    \n",
    "<span style=\"color:pink\"> Notes. The way I take windows here is different from the way I took windows in the classification task because here I am interested in undirected edge. I won't miss any connection or count repeatedly by going one way. But in the classification task, I am interested in the context that \"he\" and \"she\" are placed, I want both left and right windows of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_text_split= []\n",
    "for i in range(all_ch_string_DF.shape[0]):\n",
    "    text= all_ch_string_DF.iloc[i][\"all_ch_string\"]\n",
    "    text_split= text.split()\n",
    "    list_text_split+= [text_split]\n",
    "bookDF_ch[\"30_ch_list\"]= list_text_split\n",
    "\n",
    "def replace_character_maleN(wordlist):\n",
    "    new_wordlist= []\n",
    "    for w in wordlist:\n",
    "        if w== \"他\":\n",
    "            new_wordlist+= [\"male_he\"]\n",
    "        elif w== \"她\":\n",
    "            new_wordlist+= [\"male_she\"]\n",
    "        else:\n",
    "            new_wordlist+= [w]\n",
    "    return [new_wordlist]\n",
    "        \n",
    "def replace_character_femaleN(wordlist):\n",
    "    new_wordlist= []\n",
    "    for w in wordlist:\n",
    "        if w== \"他\":\n",
    "            new_wordlist+= [\"female_he\"]\n",
    "        elif w== \"她\":\n",
    "            new_wordlist+= [\"female_she\"]\n",
    "        else:\n",
    "            new_wordlist+= [w]\n",
    "    return [new_wordlist]\n",
    "\n",
    "bookDF_ch[\"30_ch_list_replace\"]= pd.concat([bookDF_ch[\"30_ch_list\"].iloc[:500].apply(lambda x: replace_character_maleN(x)),\n",
    "                                        bookDF_ch[\"30_ch_list\"].iloc[500:].apply(lambda x: replace_character_femaleN(x))],\n",
    "                                        axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 1233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "a[1: 1+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_adjacencyM(dataframe, col_name, target):\n",
    "    \n",
    "    target_dic= {target[i]: i for i in range(len(target))}\n",
    "    target_dic_rev= {num: word for word, num in target_dic.items()}\n",
    "\n",
    "    net_np= np.zeros((len(target_dic), len(target_dic)))\n",
    "\n",
    "    for i in range(dataframe.shape[0]):\n",
    "        text= dataframe[col_name].iloc[i][0]\n",
    "\n",
    "        for j in range(len(text)):\n",
    "            if text[j] in target_dic:\n",
    "                right= text[j: j+ 10]\n",
    "                for wr in right[1:]:\n",
    "                    if wr in target_dic:\n",
    "                        #I want to fill only half of the matrix\n",
    "                        if target_dic[text[j]]< target_dic[wr]:\n",
    "                            net_np[target_dic[text[j]], target_dic[wr]]+= 1\n",
    "\n",
    "                        elif target_dic[text[j]]== target_dic[wr]:\n",
    "                            net_np[target_dic[text[j]], target_dic[wr]]+= 0\n",
    "\n",
    "                        else:\n",
    "                            net_np[target_dic[wr], target_dic[text[j]]]+= 1\n",
    "    return net_np, target_dic, target_dic_rev\n",
    "\n",
    "gender_target= [\"male_he\", \"male_she\", \"female_he\", \"female_she\"]\n",
    "\n",
    "adjacencyM_adj, target_dic_adj, target_dic_rev_adj= cal_adjacencyM(bookDF_ch, \n",
    "                                                                   \"30_ch_list_replace\", \n",
    "                                                                   dis_adj+ gender_target)\n",
    "adjacencyM_v, target_dic_v, target_dic_rev_v= cal_adjacencyM(bookDF_ch, \n",
    "                                                             \"30_ch_list_replace\", \n",
    "                                                             dis_v+ gender_target)\n",
    "adjacencyM_n, target_dic_n, target_dic_rev_n= cal_adjacencyM(bookDF_ch, \n",
    "                                                             \"30_ch_list_replace\", \n",
    "                                                             dis_n+ gender_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1004, 1004)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjacencyM_adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_node_w_adj= []\n",
    "for i in range(adjacencyM_adj.shape[0]):\n",
    "    for j in range(i, adjacencyM_adj.shape[0]):\n",
    "        if adjacencyM_adj[i, j]> 0:\n",
    "            node_node_w_adj+= [(target_dic_rev_adj[i], \n",
    "                              target_dic_rev_adj[j], \n",
    "                              adjacencyM_adj[i, j])]\n",
    "\n",
    "node_node_w_v= []\n",
    "for i in range(adjacencyM_v.shape[0]):\n",
    "    for j in range(i, adjacencyM_v.shape[0]):\n",
    "        if adjacencyM_v[i, j]> 0:\n",
    "            node_node_w_v+= [(target_dic_rev_v[i], \n",
    "                              target_dic_rev_v[j], \n",
    "                              adjacencyM_v[i, j])]\n",
    "\n",
    "node_node_w_n= []\n",
    "for i in range(adjacencyM_n.shape[0]):\n",
    "    for j in range(i, adjacencyM_n.shape[0]):\n",
    "        if adjacencyM_n[i, j]> 0:\n",
    "            node_node_w_n+= [(target_dic_rev_n[i], \n",
    "                              target_dic_rev_n[j], \n",
    "                              adjacencyM_n[i, j])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 1004\n",
      "Number of edges: 74237\n",
      "Average degree: 147.8825\n",
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 1004\n",
      "Number of edges: 4702\n",
      "Average degree:   9.3665\n"
     ]
    }
   ],
   "source": [
    "g_adj= nx.Graph()\n",
    "g_adj.add_weighted_edges_from(node_node_w_adj)\n",
    "print(nx.info(g_adj))\n",
    "avg= np.mean([d[\"weight\"] for n1, n2, d in g_adj.edges(data = True)])\n",
    "g_adj.remove_edges_from([(n1, n2) for n1, n2, d in g_adj.edges(data = True) if d['weight'] <= avg])\n",
    "print(nx.info(g_adj))\n",
    "\n",
    "g_v= nx.Graph()\n",
    "g_v.add_weighted_edges_from(node_node_w_v)\n",
    "avg= np.mean([d[\"weight\"] for n1, n2, d in g_v.edges(data = True)])\n",
    "g_v.remove_edges_from([(n1, n2) for n1, n2, d in g_v.edges(data = True) if d['weight'] <= avg])\n",
    "\n",
    "g_n= nx.Graph()\n",
    "g_n.add_weighted_edges_from(node_node_w_n)\n",
    "avg= np.mean([d[\"weight\"] for n1, n2, d in g_n.edges(data = True)])\n",
    "g_n.remove_edges_from([(n1, n2) for n1, n2, d in g_n.edges(data = True) if d['weight'] <= avg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'真气'}\n",
      "{'武道'}\n",
      "{'小白'}\n"
     ]
    }
   ],
   "source": [
    "#Overly relying on tf-idf have the risk of capturing words too idiosyncratic,\n",
    "#which is why here I use degree centrality to balance it a bit. Degree centrality looks for the more central words\n",
    "#I think this would make my target a bit more general and less oriented to specificity of a few novels\n",
    "\n",
    "dcentralities_adj= nx.degree_centrality(g_adj)\n",
    "dcentralities_v= nx.degree_centrality(g_v)\n",
    "dcentralities_n= nx.degree_centrality(g_n)\n",
    "\n",
    "adj= [w for w, v in sorted(dcentralities_adj.items(), key = lambda x: x[1], reverse = True)[:337]][4:]\n",
    "n= [w for w, v in sorted(dcentralities_n.items(), key = lambda x: x[1], reverse = True)[:337]][4:]\n",
    "v= [w for w, v in sorted(dcentralities_v.items(), key = lambda x: x[1], reverse = True)[:337]][4:]\n",
    "\n",
    "#There are overlap between adj, n and v. I decide where they go. \n",
    "#One between adj & n: 真气(n)\n",
    "#One between v and n: 武道(n)\n",
    "#One between adj and v: 小白(adj)\n",
    "\n",
    "print(set(adj)& set(n))\n",
    "print(set(v)& set(n))\n",
    "print(set(adj)& set(v))\n",
    "\n",
    "word_attri_dic= {}\n",
    "for w in adj:\n",
    "    word_attri_dic[w]= \"adj\"\n",
    "for w in n:\n",
    "    word_attri_dic[w]= \"n\"\n",
    "for w in v:\n",
    "    word_attri_dic[w]= \"v\"\n",
    "\n",
    "word_attri_dic[\"真气\"]= \"n\"\n",
    "word_attri_dic[\"武道\"]= \"n\"\n",
    "word_attri_dic[\"小白\"]= \"adj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_3= list(set(adj+ n+ v))\n",
    "adjacencyM_3, target_dic_3, target_dic_rev_3= cal_adjacencyM(bookDF_ch, \"30_ch_list_replace\", target_3)\n",
    "\n",
    "node_node_w_3= []\n",
    "for i in range(adjacencyM_3.shape[0]):\n",
    "    for j in range(i, adjacencyM_3.shape[0]):\n",
    "        if adjacencyM_3[i, j]> 0:\n",
    "            node_node_w_3+= [(target_dic_rev_3[i], \n",
    "                              target_dic_rev_3[j], \n",
    "                              adjacencyM_3[i, j])]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_3= nx.Graph()\n",
    "g_3.add_weighted_edges_from(node_node_w_3)\n",
    "\n",
    "for word, attribute in word_attri_dic.items(): \n",
    "    g_3.nodes[word][\"w_attribute\"]= attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 996\n",
      "Number of edges: 199891\n",
      "Average degree: 401.3876\n",
      "Average weight: 4.299188057491333\n",
      "Median weight: 2.0\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(g_3))\n",
    "\n",
    "#Average weight\n",
    "print(\"Average weight:\", np.mean([d[\"weight\"] for n1, n2, d in g_3.edges(data = True)]))\n",
    "print(\"Median weight:\", np.median([d[\"weight\"] for n1, n2, d in g_3.edges(data = True)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 996\n",
      "Number of edges: 30372\n",
      "Average degree:  60.9880\n",
      "Average weight: 17.837712366653495\n"
     ]
    }
   ],
   "source": [
    "#Remove edges that occur less than average times is not enough --> still 119277 edges..\n",
    "avg= np.mean([d[\"weight\"] for n1, n2, d in g_3.edges(data = True)])\n",
    "#Trim down weight <= 10\n",
    "\n",
    "g_3.remove_edges_from([(n1, n2) for n1, n2, d in g_3.edges(data = True) if d['weight'] <= 5])\n",
    "#Average weight\n",
    "print(nx.info(g_3))\n",
    "print(\"Average weight:\", np.mean([d[\"weight\"] for n1, n2, d in g_3.edges(data = True)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Translate nodes from Chinese to English\n",
    "words= list(nx.nodes(g_3))\n",
    "translator = Translator()\n",
    "\n",
    "chi_eng_dic= {}\n",
    "\n",
    "for chi_w in words:    \n",
    "    try:\n",
    "        eng_w= translator.translate(chi_w).text\n",
    "        chi_eng_dic[chi_w]= eng_w\n",
    "    except:\n",
    "        print(\"something is wrong:\", chi_w)\n",
    "        \n",
    "chi_eng_DF= pd.DataFrame({\"chi\": words, \"eng\": [chi_eng_dic[chi_w] for chi_w in words]})\n",
    "chi_eng_DF.to_csv(\"chi_eng_DF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I manually correct the google translation\n",
    "chi_eng_correct= pd.read_excel(\"chi_eng_correct.xlsx\", encoding= \"latin-1\")\n",
    "eng_words= list(chi_eng_correct[\"eng\"])\n",
    "\n",
    "chi_words= list(nx.nodes(g_3))\n",
    "\n",
    "#I then pair up the Chinese words with the English words\n",
    "pair= [chi+eng.lower() for chi, eng in zip(chi_words, eng_words)]    \n",
    "\n",
    "#Also create a matching dictionary for the block below\n",
    "chi_eng_corrected= {chi: eng.lower() for chi, eng in zip(chi_words, eng_words)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below export two csv file. One is a node table that tags a word attribute for each node; the other is an adjacency matrix that document edges between nodes. I can import the two csv files to Gephi in one project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I call the word column \"id\" because Gephi matches nodes by \"id\".\n",
    "\n",
    "#word_attri_dic match each (Chinese) word with word attribute\n",
    "node_attri_DF= pd.DataFrame({\"id\": [w+ chi_eng_corrected[w] for w, a in word_attri_dic.items()],\n",
    "                             \"w_attribute\": [a for w, a in word_attri_dic.items()]})\n",
    "node_attri_DF.to_csv(\"word_attribute.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Export network matrix to a csv file \n",
    "net= nx.to_numpy_matrix(g_3)\n",
    "netDF= pd.DataFrame(net, columns= pair, index= pair)\n",
    "netDF.to_csv(\"net_f_twoL.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I graph the network in Gephi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4 Gender Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Section Overview***\n",
    "\n",
    "In this section, I examine the image of \"he\" and \"she\" in the male and female novels respectively. \n",
    "\n",
    "**Step 1**: Pre-processing--I combine the 500 male novels and 500 female novels into one dataset. To distinguish \"he\" and \"she\" in the two kinds of novels, I replace the word \"他\" (he) in male novels with \"male_he\" and \"她\" (she) with \"male_she\". Similarily, I replace  \"他\" (he) in female novels with \"female_he\" and \"她\" (she) with \"female_she\". \n",
    "\n",
    "**Step 2**: I did a simple word count, which counts the number of times that \"male_he\", \"male_she\", \"female_he\" and \"female_she\" occur. \n",
    "\n",
    "**Step 3**: Using bootstraping with replacement, I re-sample 20 samples and performed Word2Vec models on these samples. Note that I make the datasets with the structure of 500 male novels + 500 female novels, rather than shuffling the 1000 novels. (There are reasons for this.) I save the 20 models. \n",
    "\n",
    "**Step 4**: Among the 20 models, I identify the one that is in the middle of the range by calculating similarity between the words \"male_he\", \"male_she\", \"female_he\" and \"female_she\". I proceed with this chosen model. \n",
    "\n",
    "**Step 5 (part of Step 4)**: What are the cosine similarities between the pairs of \"male_he\"-\"female_he\", \"male_she\"-\"female_she\", \"male_he\"-\"male_she\", \"female_he\" and \"female_she\"?\n",
    "\n",
    "**Step 6**: I find the words that are most similar to \"male_he\", \"male_she\", \"female_he\" and \"female_she\". I am mainly interested in describing words (adj) and verb, and I am not interested in nouns (especially human names). So I got words by filtering on their POS tags. \n",
    "\n",
    "***Step 7 (intermezzo)**: For testing the way I structure the dataset (500 male + 500 female novels rather than shuffled 1000 novels), I use two other words \"脸庞\" (face) and \"温柔\" (gentle): \"脸庞\" (face) should be a word that has fixed meanings. Its word embeding outcomes shouldn't be influenced much by the order of the novel becasue it should be in similar contexts in both male and female novels. In contrast, \"温柔\" (gentle) might have different contexts in male and female novels. I calculate the cosine similarities between \"male_face\" and \"female_face\", as well as between \"male_gentle\" and \"female_gentle\", in the case of inputing 1) 500 male + 500 female novels and 2) 1000 shuffled novels to understand the order effect. I come to the conclusion that leveraging the order effect of the dataset to aline two word-embedding spaces is reasonable. \n",
    "\n",
    "**Step 8**: Construct a gender dimension and place some target words (adjective) on this gender dimension.\n",
    "\n",
    "**Step 9**: Another way to demonstrate the severe under-representation of \"she\" in male novels and slight under-representation of \"he\" in female novels is network analysis. The descriptive network above does not contain the four gender words. Now I place the four gender words in the network and calculate network statistics. \n",
    "\n",
    "**Step 10**: I make interpretation of the word embedding and network analysis and suggest that gender images different in male and female novels. I use machine learning classification to validate the interpretation I made. I identify a list of gender words as target: \"她\" she, \"他\" he, \"女孩\" girl, \"小女孩\" little, \"男孩\" boy, \"小男孩\" little boy, \"女人\" woman, \"男人\" man, \"女\" female, \"男\" male, \"少年\" teenage boy, \"少女\" teenage girl, \"男子\" man, \"女子\" woman. I take a 11-word window around each target words (5 words on the left+ target word+ 5 words on the right). I use these information to classify novels into male and female novels (see below for more details). The logic is that if gender images are indeed different in male and female novels, then I should be able to correctly a novel into male and female novel sorely based on how it portrays the two gender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookDF_male_tokenized= pd.read_pickle(\"bookDF_male_tokenized.pickle\")\n",
    "bookDF_female_tokenized= pd.read_pickle(\"bookDF_female_tokenized.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data managing, combining the 30 chapters (of each novel) into one cell and clean out unwanted words\n",
    "\n",
    "#The reason why I use the POS tagged columns is because I want a dictionary that tells me the attribute of\n",
    "#each word. This way, I can complete two task in one move. \n",
    "\n",
    "helper_col= []\n",
    "for i in range(30):\n",
    "    helper_col+= [\"ch\"+str(i+1)+\"_tag_clean\"]\n",
    "\n",
    "bookDF_ch_male= bookDF_male_tokenized[helper_col]\n",
    "bookDF_ch_female= bookDF_female_tokenized[helper_col]\n",
    "bookDF_ch= pd.concat([bookDF_ch_male, bookDF_ch_female], axis= 0)\n",
    "bookDF_ch[\"book_gender\"]=  [\"boy\"]* 500+ [\"girl\"]* 500\n",
    "\n",
    "\n",
    "#Collapse 30 chapters (30 columns into one) \n",
    "helper_lis= [] \n",
    "for i in range(bookDF_ch.shape[0]): \n",
    "    cell= []\n",
    "    cell= []\n",
    "    for j in range(30):\n",
    "        cell+= bookDF_ch.iloc[i][\"ch\"+str(j+1)+\"_tag_clean\"]\n",
    "    helper_lis+= [cell]\n",
    "\n",
    "\n",
    "\n",
    "word= []\n",
    "for i in range(bookDF_ch.shape[0]):\n",
    "    cell= []\n",
    "    for w1, t1 in helper_lis[i]:\n",
    "        cell+= [w1]\n",
    "    word+= [cell]\n",
    "\n",
    "bookDF_ch[\"30_ch_list\"]= word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a dictionary that tells me the attribute of each word\n",
    "word_tag_dic= {}\n",
    "for i in range(bookDF_ch.shape[0]):\n",
    "    for w1, t1 in helper_lis[i]:\n",
    "        if w1 not in word_tag_dic:\n",
    "            word_tag_dic[w1]= set([t1])\n",
    "        else:\n",
    "            word_tag_dic[w1].update([t1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace 他 and 她 in the two kinds of novel.\n",
    "#For the male-novels, 他= male_he, 她= male_she\n",
    "#For the female-novels, 他= female_he, 她= female_she\n",
    "\n",
    "def replace_character_maleN(wordlist):\n",
    "    new_wordlist= []\n",
    "    for w in wordlist:\n",
    "        if w== \"他\":\n",
    "            new_wordlist+= [\"male_he\"]\n",
    "        elif w== \"她\":\n",
    "            new_wordlist+= [\"male_she\"]\n",
    "        else:\n",
    "            new_wordlist+= [w]\n",
    "    return [new_wordlist]\n",
    "        \n",
    "def replace_character_femaleN(wordlist):\n",
    "    new_wordlist= []\n",
    "    for w in wordlist:\n",
    "        if w== \"他\":\n",
    "            new_wordlist+= [\"female_he\"]\n",
    "        elif w== \"她\":\n",
    "            new_wordlist+= [\"female_she\"]\n",
    "        else:\n",
    "            new_wordlist+= [w]\n",
    "    return [new_wordlist]\n",
    "\n",
    "bookDF_ch[\"30_ch_list_replace\"]= pd.concat([bookDF_ch[\"30_ch_list\"].iloc[:500].apply(lambda x: replace_character_maleN(x)),\n",
    "                                        bookDF_ch[\"30_ch_list\"].iloc[500:].apply(lambda x: replace_character_femaleN(x))],\n",
    "                                        axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'female_he': 148773,\n",
       " 'female_she': 298651,\n",
       " 'male_he': 250861,\n",
       " 'male_she': 49675}"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many times did the four character occurs? \n",
    "#In male novel, \"she\" occurs 5 times less than \"he\"\n",
    "\n",
    "dic_count= {\"male_he\": 0,\n",
    "            \"male_she\": 0,\n",
    "            \"female_he\": 0,\n",
    "            \"female_she\": 0}\n",
    "\n",
    "for i in range(len(bookDF_ch[\"30_ch_list_replace\"])):\n",
    "    b= bookDF_ch[\"30_ch_list_replace\"].iloc[i]\n",
    "    for w in b[0]:\n",
    "        if w== \"male_he\":\n",
    "            dic_count[\"male_he\"]+= 1\n",
    "        elif w== \"male_she\":\n",
    "            dic_count[\"male_she\"]+= 1\n",
    "        elif w== \"female_he\":\n",
    "            dic_count[\"female_he\"]+= 1\n",
    "        elif w== \"female_she\":\n",
    "            dic_count[\"female_she\"]+= 1\n",
    "\n",
    "dic_count   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304"
      ]
     },
     "execution_count": 932,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampA1= bookDF_ch[\"30_ch_list_replace\"].iloc[:500].sample(frac=1, replace=True).sum()\n",
    "sampA2= bookDF_ch[\"30_ch_list_replace\"].iloc[:500].sample(frac=1, replace=True).sum()\n",
    "\n",
    "overlap= 0\n",
    "for l in sampA1:\n",
    "    if l in sampA2: \n",
    "        overlap+= 1\n",
    "overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Bootstrapping with replacement\n",
    "##Even though I bootstrap resample, I kept the 500 male-500 female structure. \n",
    "##This is like training two models separately but then aline the spaces\n",
    "s_k_1= []\n",
    "s_k_2= []\n",
    "s_k_3= []\n",
    "s_k_4= []\n",
    "model_collection_dic= {}\n",
    "\n",
    "for x in range(20): #A way to repeat the operation 20 times\n",
    "    \n",
    "    bookW2V = gensim.models.word2vec.Word2Vec(size = 200, #dimensions\n",
    "                                               alpha=0.025,\n",
    "                                               window=5,\n",
    "                                               min_count=10,\n",
    "                                               hs=0,  #hierarchical softmax toggle\n",
    "                                               compute_loss = True)\n",
    "    sampA= bookDF_ch[\"30_ch_list_replace\"].iloc[:500].sample(frac=1, replace=True).sum()\n",
    "    sampB= bookDF_ch[\"30_ch_list_replace\"].iloc[500:].sample(frac=1, replace=True).sum()\n",
    "    bookW2V.build_vocab(sampA+ sampB)\n",
    "    bookW2V.train(sampA+ sampB, \n",
    "                  total_examples= 1000, \n",
    "                  epochs=300)\n",
    "    model_collection_dic[\"model\"+str(x)]= bookW2V\n",
    "    \n",
    "    try:\n",
    "        s_k_1.append(cos_similarity(bookW2V, 'male_he', 'female_he')[0,0])\n",
    "        s_k_2.append(cos_similarity(bookW2V, 'male_he', 'male_she')[0,0])\n",
    "        s_k_3.append(cos_similarity(bookW2V, 'female_she', 'female_he')[0,0])\n",
    "        s_k_4.append(cos_similarity(bookW2V, 'male_she', 'female_she')[0,0])\n",
    "    except KeyError:\n",
    "        #Missing one of the words from the vocab\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the 20 models above\n",
    "for name, model in model_collection_dic.items():\n",
    "    model.save(\"{}.model\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yoyo task finished!\n"
     ]
    }
   ],
   "source": [
    "print(\"yoyo task finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model0 0.015039818\n",
      "model1 0.01791046\n",
      "model2 0.013547881\n",
      "model3 0.012802109\n",
      "model4 0.01635749\n",
      "model5 0.02188131\n",
      "model6 0.019612659\n",
      "model7 0.018548556\n",
      "model8 0.016659385\n",
      "model9 0.016074277\n",
      "model10 0.015773902\n",
      "model11 0.020508436\n",
      "model12 0.015443501\n",
      "model13 0.01476565\n",
      "model14 0.013857263\n",
      "model15 0.01884785\n",
      "model16 0.016653597\n",
      "model17 0.016220171\n",
      "model18 0.018271955\n",
      "model19 0.020397145\n"
     ]
    }
   ],
   "source": [
    "##The above bootstrapping calculate 20 models. I need to choose one that is in the middle.\n",
    "##I use the similarity between \"male_he\" vs. \"female_he\", \"male_he\" vs. \"male_she\", \n",
    "##\"female_she\" vs. \"female_he\", and \"male_she\" vs. \"female_she\" to make the selection\n",
    "\n",
    "def model_deviation(a_model):\n",
    "    #This function is highly specific to this context\n",
    "    #No using this function outside this code block\n",
    "    \n",
    "    #This function gives how the four similarity socres of a model deviate from the other 19 models\n",
    "    #The model that have the highest (average) deviation scores is the one that is the most \"off\"\n",
    "    s1= cos_similarity(a_model, 'male_he', 'female_he')[0,0]\n",
    "    s2= cos_similarity(a_model, 'male_he', 'male_she')[0,0]\n",
    "    s3= cos_similarity(a_model, 'female_she', 'female_he')[0,0]\n",
    "    s4= cos_similarity(a_model, 'male_she', 'female_she')[0,0]\n",
    "    \n",
    "    dev1= [abs(s1- s) for s in s_k_1]\n",
    "    dev2= [abs(s2- s) for s in s_k_2]\n",
    "    dev3= [abs(s3- s) for s in s_k_3]\n",
    "    dev4= [abs(s4- s) for s in s_k_4]\n",
    "    #print(np.mean(dev1))\n",
    "    \n",
    "    return np.mean(dev1+ dev2+ dev3+ dev4)\n",
    "\n",
    "for name, model in model_collection_dic.items():\n",
    "    print(name, model_deviation(model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(embedding,word1,word2):\n",
    "    return sklearn.metrics.pairwise.cosine_similarity(embedding.wv[word1].reshape(1,-1),embedding.wv[word2].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1bd8d16588>"
      ]
     },
     "execution_count": 1237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bdaf5e860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s1= []\n",
    "s2= []\n",
    "s3= []\n",
    "s4= []\n",
    "\n",
    "for name, model in model_collection_dic.items():\n",
    "    s1+= [cos_similarity(model, 'male_he', 'female_he')[0,0]]\n",
    "    s2+= [cos_similarity(model, 'male_he', 'male_she')[0,0]]\n",
    "    s3+= [cos_similarity(model, 'female_she', 'female_he')[0,0]]\n",
    "    s4+= [cos_similarity(model, 'male_she', 'female_she')[0,0]]\n",
    "\n",
    "f= plt.figure(figsize= (15, 5))\n",
    "\n",
    "x= [i for i in range(1, 21)]\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(x, s1, 'darkblue', label='\"male_he\" vs. \"female_he\"')\n",
    "plt.plot(x, s4, 'darkred',  label= '\"male_she\" vs. \"female_she\"')\n",
    "plt.axis([1, 20, 0, 1])\n",
    "plt.xticks(np.arange(1, 21, 1))\n",
    "plt.ylabel(\"cosine similarity\")\n",
    "plt.xlabel(\"bootstrap sample\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(x, s2, \"steelblue\", label= '\"male_he\" vs. \"male_she\"')\n",
    "plt.plot(x, s3, 'plum',  label= '\"female_she\" vs. \"female_he\"')\n",
    "plt.axis([1, 20, 0, 1])\n",
    "plt.xticks(np.arange(1, 21, 1))\n",
    "plt.ylabel(\"cosine similarity\")\n",
    "plt.xlabel(\"bootstrap sample\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proceed with model7\n",
    "#bookW2V_20= model_collection_dic[\"model7\"]\n",
    "\n",
    "\"\"\"Already calculated and saved the 20 models. Load one of them\"\"\"\n",
    "bookW2V_20= gensim.models.Word2Vec.load(\"model3.model\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male_he: 177 [('完全', 20), ('根本', 20), ('危险', 20), ('正确', 20), ('显然', 20), ('直接', 20), ('成功', 20), ('容易', 20), ('清楚', 20), ('确实', 20), ('痛苦', 20), ('努力', 20), ('彻底', 20), ('强', 20), ('简单', 20), ('明显', 20), ('重要', 20), ('难', 20), ('轻易', 20), ('困难', 19), ('强大', 19), ('愚蠢', 18), ('认真', 18), ('强烈', 15), ('突然', 15), ('绮丽', 14), ('冷静', 14), ('严重', 14), ('甜甜', 14), ('最好', 14), ('意外', 14), ('糟糕', 13), ('早', 11), ('具体', 11), ('厉害', 10), ('轻松', 10), ('黑脚', 9), ('乐乐', 9), ('怕死', 9), ('幼稚', 9), ('单纯', 9), ('神秘', 9), ('纯粹', 9), ('邪', 8), ('恐惧', 8), ('神秀', 8), ('固执', 8), ('极限', 8), ('不对', 7), ('郁闷', 7)]\n",
      "\n",
      "male_she: 225 [('温柔', 20), ('单纯', 20), ('害羞', 20), ('完全', 20), ('认真', 20), ('漂亮', 20), ('根本', 20), ('不好意思', 19), ('容易', 18), ('努力', 18), ('清纯', 17), ('亲爱', 16), ('善良', 16), ('胆小', 16), ('绮丽', 15), ('倔强', 15), ('愚蠢', 14), ('甜甜', 14), ('年轻', 14), ('坚决', 13), ('婉', 12), ('显然', 12), ('确实', 12), ('柔弱', 12), ('勇敢', 12), ('刁定', 12), ('潇潇', 11), ('冷静', 11), ('固执', 11), ('娟子', 10), ('灵静', 10), ('明显', 10), ('琅玥', 10), ('聪明', 9), ('骄傲', 9), ('缱绻', 9), ('犹豫', 9), ('宁缺', 9), ('平安', 8), ('幼稚', 8), ('困难', 8), ('很好', 8), ('秀', 8), ('真诚', 8), ('娴', 8), ('难', 8), ('失常', 8), ('内疚', 8), ('悠然', 8), ('绯炎', 8)]\n",
      "\n",
      "female_he: 207 [('温柔', 20), ('害羞', 20), ('假', 20), ('聪明', 20), ('不好意思', 19), ('有心', 18), ('平安', 18), ('傻', 18), ('坏', 17), ('根本', 17), ('容易', 17), ('蠢', 16), ('婉', 15), ('糊涂', 15), ('悠然', 15), ('丑', 15), ('早', 15), ('疼', 14), ('冷淡', 14), ('甜甜', 14), ('不对', 13), ('敏华', 13), ('怪', 13), ('绮丽', 12), ('敏容', 12), ('孤煌', 12), ('懒', 12), ('善良', 12), ('难', 12), ('认真', 12), ('愚蠢', 11), ('胆小', 11), ('偏', 10), ('缱绻', 10), ('固执', 10), ('最好', 10), ('娟子', 10), ('秀', 9), ('宁缺', 9), ('内疚', 9), ('清雅', 9), ('明傲', 9), ('单纯', 8), ('不信', 8), ('温婉', 8), ('方劲', 8), ('着急', 8), ('轻易', 8), ('清白', 8), ('麻烦', 8)]\n",
      "\n",
      "female_she: 162 [('疼', 20), ('糊涂', 20), ('根本', 20), ('早', 20), ('心疼', 20), ('容易', 20), ('清楚', 20), ('温柔', 19), ('有心', 19), ('平安', 19), ('单纯', 19), ('努力', 19), ('胆小', 19), ('完全', 18), ('坏', 18), ('累', 18), ('娴', 17), ('婉', 17), ('傻', 17), ('聪明', 17), ('懦弱', 16), ('清雅', 16), ('害羞', 16), ('善良', 16), ('强迫', 15), ('婉宁', 15), ('青巧', 14), ('难', 14), ('甜甜', 14), ('微华', 13), ('久', 13), ('偏', 13), ('内疚', 13), ('敏容', 12), ('懒', 12), ('软弱', 12), ('最好', 12), ('温婉', 11), ('秀', 10), ('舒服', 10), ('缱绻', 10), ('哭哭啼啼', 10), ('假', 10), ('暖', 9), ('婉儿', 9), ('悠然', 9), ('明傲', 9), ('乖巧', 8), ('怪', 8), ('怯懦', 7)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now I want to look for the most similar words of a kind for a target word \n",
    "def most_similar_word(model, target_word, tag_list, howmany= 50, word_tag_dic= word_tag_dic):\n",
    "    #Input 1: the word2vec model \n",
    "    #Input 2: target word that I want to look for similar words for \n",
    "    #Input 3: tag_list. Do I want to see the similar noun, adj, or v or ...?\n",
    "    #Input 4: how many most similar words I want\n",
    "    #Input 5: optional. This is the dictionary that gives each word its attributes\n",
    "    \n",
    "    similar_word_list= model.wv.most_similar(target_word, topn= 5000)\n",
    "    found_most_similar= []\n",
    "    for sim, num in similar_word_list:\n",
    "        try:\n",
    "            \"\"\"Human names are difficult to handle and jieba gives names different tags. \n",
    "            Since I really do not want any names. I add one more filter here to \n",
    "            screen out anything that could be names\"\"\"\n",
    "            if (\"nr\" not in word_tag_dic[sim]) and (\"nrfg\" not in word_tag_dic[sim]):\n",
    "                if set(word_tag_dic[sim])& set(tag_list)!= set():\n",
    "                    found_most_similar+= [sim]\n",
    "        except:\n",
    "            pass\n",
    "    return found_most_similar[:howmany]\n",
    "    \n",
    "    \n",
    "keep_tag_adj= [\"a\", \"ag\", \"ad\", \"an\", \"z\"] # \"i\"\n",
    "keep_tag_v= [\"vg\", \"v\", \"vd\", \"vn\"]\n",
    "keep_tag_n= [\"n\", \"ns\", \"ng\"]\n",
    "keep_tag= keep_tag_adj+ keep_tag_v\n",
    "\n",
    "#print(\"most similar adj:\", most_similar_word(bookW2V_20, \"male_he\", keep_tag_adj, 150))\n",
    "\n",
    "\n",
    "def all_model_similary_word_count(target_word, tag_list, howmany= 50, word_tag_dic= word_tag_dic):\n",
    "    #This function utilizes the most_similar_word function defines above\n",
    "    #The previous function turns the most similar words of a specified kind of one mode\n",
    "    #This function complile the most similar words the the 20 bootstrap models\n",
    "    output_dic= {}\n",
    "    for name, model in model_collection_dic.items():   \n",
    "        most_similar_1= most_similar_word(model, target_word, tag_list, howmany= howmany, word_tag_dic= word_tag_dic)\n",
    "        for sw in most_similar_1:\n",
    "            if sw not in output_dic:\n",
    "                output_dic[sw]= 1\n",
    "            else:\n",
    "                output_dic[sw]+= 1\n",
    "    return output_dic\n",
    "\n",
    "male_he_20= all_model_similary_word_count(\"male_he\", keep_tag_adj, 50)\n",
    "male_he_20_sorted= sorted(male_he_20.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(\"male_he:\", len(male_he_20), male_he_20_sorted[:50])\n",
    "male_he_20_tot= [w for w, n in male_he_20_sorted[:60]]\n",
    "print()\n",
    "\n",
    "male_she_20= all_model_similary_word_count(\"male_she\", keep_tag_adj, 50)\n",
    "male_she_20_sorted= sorted(male_she_20.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(\"male_she:\", len(male_she_20), male_she_20_sorted[:50])\n",
    "male_she_20_tot= [w for w, n in male_she_20_sorted[:60]]\n",
    "print()\n",
    "\n",
    "female_he_20= all_model_similary_word_count(\"female_he\", keep_tag_adj, 50)\n",
    "female_he_20_sorted= sorted(female_he_20.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(\"female_he:\", len(female_he_20), female_he_20_sorted[:50])\n",
    "female_he_20_tot= [w for w, n in female_he_20_sorted[:80]]\n",
    "print()\n",
    "\n",
    "female_she_20= all_model_similary_word_count(\"female_she\", keep_tag_adj, 50)\n",
    "female_she_20_sorted= sorted(female_she_20.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(\"female_she:\", len(female_she_20), female_she_20_sorted[:50])\n",
    "female_she_20_tot= [w for w, n in female_she_20_sorted[:80]]\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_to_eng(wordlist):\n",
    "    translator = Translator()\n",
    "    \n",
    "    chi_eng_dic= {}\n",
    "    \n",
    "    for chi_w in wordlist:\n",
    "        try:\n",
    "            eng_w= translator.translate(chi_w).text\n",
    "            chi_eng_dic[chi_w]= eng_w\n",
    "        except:\n",
    "            print(\"something is wrong:\", chi_w)\n",
    "    return chi_eng_dic\n",
    "\n",
    "male_he_20_eng= chi_to_eng(male_he_20_tot)\n",
    "male_she_20_eng= chi_to_eng(male_she_20_tot)\n",
    "female_he_20_eng= chi_to_eng(female_he_20_tot)\n",
    "female_she_20_eng= chi_to_eng(female_she_20_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['完全-complete', '根本-fundamental', '危险-Danger', '正确-correct', '显然-Obviously', '直接-direct', '成功-success', '容易-easy', '清楚-clear', '确实-indeed', '痛苦-pain', '努力-Work hard', '彻底-thorough', '强-Strong', '简单-simple', '明显-obvious', '重要-important', '难-difficult', '轻易-easily', '困难-difficult', '强大-powerful', '愚蠢-silly', '认真-serious', '强烈-strong', '突然-suddenly', '绮丽-beautiful', '冷静-calm', '严重-serious', '甜甜-Sweet', '最好-the best', '意外-accident', '糟糕-bad', '早-early', '具体-specific', '厉害-Powerful', '轻松-Relaxed', '黑脚-Black feet', '乐乐-Lele', '怕死-fear death', '幼稚-naive', '单纯-simple', '神秘-mysterious', '纯粹-purely', '邪-evil', '恐惧-fear', '神秀-God show', '固执-stubborn', '极限-limit', '不对-wrong', '郁闷-depressed', '宁缺-Ning deficiency', '荒诞-absurd', '不错-Good', '野蛮-brutal', '刁定-刁定', '鬼-ghost', '神奇-magical', '蠢-stupid', '清醒-wide awake', '成真-Accomplishment']\n"
     ]
    }
   ],
   "source": [
    "def print_translate(a_dic):\n",
    "    for_print= []\n",
    "    for chi, eng in a_dic.items():\n",
    "        for_print+= [chi+str(\"-\")+eng]\n",
    "    return for_print\n",
    "\n",
    "print(print_translate(male_he_20_eng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intrinsic_similarity(model, wordlist):\n",
    "    np_2dim= np.empty((len(wordlist), len(wordlist)))\n",
    "    for i in range(np_2dim.shape[0]):\n",
    "        for j in range(np_2dim.shape[1]):\n",
    "            np_2dim[i, j]= cos_similarity(model, wordlist[i], wordlist[j])\n",
    "    return np_2dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model0\n",
      "   male_he 0.1548450701791793\n",
      "   male_she 0.12992561542391778\n",
      "   female_he 0.10953017401471735\n",
      "   female_she 0.10077668541148305\n",
      "model1\n",
      "   male_he 0.14374223508127035\n",
      "   male_she 0.12017817310579121\n",
      "   female_he 0.10996891061477364\n",
      "   female_she 0.11382477054074407\n",
      "model2\n",
      "   male_he 0.1443182529296726\n",
      "   male_she 0.10853603831864893\n",
      "   female_he 0.10536316033266485\n",
      "   female_she 0.10959156139735132\n",
      "model3\n",
      "   male_he 0.14874518097266554\n",
      "   male_she 0.11163372479379177\n",
      "   female_he 0.1068609601251781\n",
      "   female_she 0.11981877289693803\n",
      "model4\n",
      "   male_he 0.1448295814961195\n",
      "   male_she 0.11787524384260177\n",
      "   female_he 0.1024559476049617\n",
      "   female_she 0.11241424000300466\n",
      "model5\n",
      "   male_he 0.14995199616737664\n",
      "   male_she 0.1234085296086967\n",
      "   female_he 0.12142848567590117\n",
      "   female_she 0.10945057034678757\n",
      "model6\n",
      "   male_he 0.1521659443117678\n",
      "   male_she 0.11723349701836705\n",
      "   female_he 0.11351330898925661\n",
      "   female_she 0.10703292510583996\n",
      "model7\n",
      "   male_he 0.14191939700841905\n",
      "   male_she 0.09750832073874771\n",
      "   female_he 0.09572979369200767\n",
      "   female_she 0.10624299394004047\n",
      "model8\n",
      "   male_he 0.14962958093415946\n",
      "   male_she 0.10651626954004169\n",
      "   female_he 0.10821331141032278\n",
      "   female_she 0.11516678308863193\n",
      "model9\n",
      "   male_he 0.14822948586270213\n",
      "   male_she 0.10773295206390321\n",
      "   female_he 0.11587813620381057\n",
      "   female_she 0.10727465013712645\n",
      "model10\n",
      "   male_he 0.14753774906918407\n",
      "   male_she 0.10831502752229571\n",
      "   female_he 0.1064848401736468\n",
      "   female_she 0.10921814199239016\n",
      "model11\n",
      "   male_he 0.14814231214262544\n",
      "   male_she 0.11521387133672834\n",
      "   female_he 0.0970320825278759\n",
      "   female_she 0.10049746571816504\n",
      "model12\n",
      "   male_he 0.14569394008517264\n",
      "   male_she 0.09908296642266214\n",
      "   female_he 0.10911183485500514\n",
      "   female_she 0.11017348826788366\n",
      "model13\n",
      "   male_he 0.13851793997995557\n",
      "   male_she 0.10629311693571508\n",
      "   female_he 0.10184155930560082\n",
      "   female_she 0.10227606255561113\n",
      "model14\n",
      "   male_he 0.15449191613569857\n",
      "   male_she 0.10750762053243816\n",
      "   female_he 0.11084082440845669\n",
      "   female_she 0.1124091833282262\n",
      "model15\n",
      "   male_he 0.15124860938712956\n",
      "   male_she 0.11297168678529561\n",
      "   female_he 0.10341642113365233\n",
      "   female_she 0.11056464822106063\n",
      "model16\n",
      "   male_he 0.13214153031986206\n",
      "   male_she 0.11154923591315746\n",
      "   female_he 0.09333715873211622\n",
      "   female_she 0.10663556631430983\n",
      "model17\n",
      "   male_he 0.13809454062879087\n",
      "   male_she 0.10956621991284192\n",
      "   female_he 0.11987071244306863\n",
      "   female_she 0.11258640457578004\n",
      "model18\n",
      "   male_he 0.15056734500825406\n",
      "   male_she 0.127001484875381\n",
      "   female_he 0.11206895559243858\n",
      "   female_she 0.11739065926112234\n",
      "model19\n",
      "   male_he 0.14100893806815148\n",
      "   male_she 0.10593832573108375\n",
      "   female_he 0.10959990098513663\n",
      "   female_she 0.10959559790529311\n"
     ]
    }
   ],
   "source": [
    "for name, model in model_collection_dic.items():\n",
    "    print(name)\n",
    "    male_he_adj= most_similar_word(model, \"male_he\", keep_tag_adj, 50)\n",
    "    male_she_adj= most_similar_word(model, \"male_she\", keep_tag_adj, 50)\n",
    "    female_he_adj= most_similar_word(model, \"female_he\", keep_tag_adj, 50)\n",
    "    female_she_adj= most_similar_word(model, \"female_she\", keep_tag_adj, 50)\n",
    "\n",
    "    print(\"   male_he\", intrinsic_similarity(model, male_he_adj).mean())\n",
    "\n",
    "    print(\"   male_she\", intrinsic_similarity(model, male_she_adj).mean())\n",
    "\n",
    "    print(\"   female_he\",intrinsic_similarity(model, female_he_adj).mean())\n",
    "\n",
    "    print(\"   female_she\", intrinsic_similarity(model, female_she_adj).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "89\n"
     ]
    }
   ],
   "source": [
    "#Overlap between the similar words\n",
    "male_he_10= most_similar_word(bookW2V_20, \"male_he\", keep_tag, 150)\n",
    "male_she_10= most_similar_word(bookW2V_20, \"male_she\", keep_tag, 150)\n",
    "female_he_10= most_similar_word(bookW2V_20, \"female_he\", keep_tag, 150)\n",
    "female_she_10= most_similar_word(bookW2V_20, \"female_she\", keep_tag, 150)\n",
    "\n",
    "print(len(set(male_he_10)& set(male_she_10)))\n",
    "print(len(set(female_he_10)& set(female_she_10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intermezzo: to test the order effect of the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.90458983]]\n",
      "[[0.7773516]]\n",
      "\n",
      "[[0.86085105]]\n",
      "[[0.6992688]]\n"
     ]
    }
   ],
   "source": [
    "#What if I use other words ranther than \"他\" and \"她\"?\n",
    "#For the word \"脸庞\", it the order of the novels doesn't really matter. \n",
    "#For the word \"温柔\", the order has some effect. But not as much for \"她\" and \"他\"\n",
    "\n",
    "def replace_testing_maleN(wordlist):\n",
    "    new_wordlist= []\n",
    "    for w in wordlist:\n",
    "        if w== \"脸庞\":\n",
    "            new_wordlist+= [\"male_脸\"]\n",
    "        elif w== \"温柔\":\n",
    "            new_wordlist+= [\"male_温\"]\n",
    "        else:\n",
    "            new_wordlist+= [w]\n",
    "    return [new_wordlist]\n",
    "        \n",
    "def replace_testing_femaleN(wordlist):\n",
    "    new_wordlist= []\n",
    "    for w in wordlist:\n",
    "        if w== \"脸庞\":\n",
    "            new_wordlist+= [\"female_脸\"]\n",
    "        elif w== \"温柔\":\n",
    "            new_wordlist+= [\"female_温\"]\n",
    "        else:\n",
    "            new_wordlist+= [w]\n",
    "    return [new_wordlist]\n",
    "\n",
    "bookDF_ch[\"testing_replace\"]= pd.concat([bookDF_ch[\"30_ch_list\"].iloc[:500].apply(lambda x: replace_testing_maleN(x)),\n",
    "                                        bookDF_ch[\"30_ch_list\"].iloc[500:].apply(lambda x: replace_testing_femaleN(x))],\n",
    "                                        axis= 0)\n",
    "\n",
    "#=============\n",
    "bookW2V_testing= gensim.models.word2vec.Word2Vec(size = 200, #dimensions\n",
    "                                           alpha=0.025,\n",
    "                                           window=5,\n",
    "                                           min_count=10,\n",
    "                                           hs=0,  #hierarchical softmax toggle\n",
    "                                           compute_loss = True)\n",
    "#sampA= bookDF_ch[\"testing_replace\"].iloc[:500].sample(frac=1, replace=False).sum()\n",
    "#sampB= bookDF_ch[\"testing_replace\"].iloc[500:].sample(frac=1, replace=False).sum()\n",
    "bookW2V_testing.build_vocab(bookDF_ch[\"testing_replace\"].sum())\n",
    "bookW2V_testing.train(bookDF_ch[\"testing_replace\"].sum(), \n",
    "              total_examples= bookW2V_testing.corpus_count, \n",
    "              epochs=10)\n",
    "\n",
    "print(cos_similarity(bookW2V_testing, 'male_脸', 'female_脸'))\n",
    "print(cos_similarity(bookW2V_testing, 'male_温', 'female_温'))\n",
    "print()\n",
    "#=============\n",
    "\n",
    "bookW2V_Sotesting= gensim.models.word2vec.Word2Vec(size = 200, #dimensions\n",
    "                                           alpha=0.025,\n",
    "                                           window=5,\n",
    "                                           min_count=10,\n",
    "                                           hs=0,  #hierarchical softmax toggle\n",
    "                                           compute_loss = True)\n",
    "#sampA= bookDF_ch[\"testing_replace\"].iloc[:500].sample(frac=1, replace=False).sum()\n",
    "#sampB= bookDF_ch[\"testing_replace\"].iloc[500:].sample(frac=1, replace=False).sum()\n",
    "bookW2V_Sotesting.build_vocab(bookDF_ch[\"testing_replace\"].sum())\n",
    "bookW2V_Sotesting.train(sorted(bookDF_ch[\"testing_replace\"].sum()), \n",
    "              total_examples= bookW2V_Sotesting.corpus_count, \n",
    "              epochs=10)\n",
    "\n",
    "print(cos_similarity(bookW2V_Sotesting, 'male_脸', 'female_脸'))\n",
    "print(cos_similarity(bookW2V_Sotesting, 'male_温', 'female_温'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An alternative way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookDF_ch[\"30_ch_list_not_replace\"]= pd.concat([bookDF_ch[\"30_ch_list\"].iloc[:500].apply(lambda x: [x]),\n",
    "                                        bookDF_ch[\"30_ch_list\"].iloc[500:].apply(lambda x: [x])],\n",
    "                                        axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_tar= [\"他\", \"她\"]\n",
    "two_tar_dicofDF= {tar: pd.DataFrame({}) for tar in two_tar}\n",
    "\n",
    "\n",
    "bookW2V_altern = gensim.models.word2vec.Word2Vec(size = 200, #dimensions\n",
    "                                              alpha=0.025,\n",
    "                                              window=5,\n",
    "                                              min_count=10,\n",
    "                                              hs=0,  #hierarchical softmax toggle\n",
    "                                            compute_loss = True)\n",
    "\n",
    "#sampA and sampB are the original dataset (not bootstrapped); \n",
    "#I .sample() to randomize the 500 novels so that they are not ordered by popularity\n",
    "sampA= bookDF_ch[\"30_ch_list_not_replace\"].iloc[:500].sample(frac=1, replace=False).sum()\n",
    "sampB= bookDF_ch[\"30_ch_list_not_replace\"].iloc[500:].sample(frac=1, replace=False).sum()\n",
    "bookW2V_altern.build_vocab(sampA+ sampB)\n",
    "for e in range(300):\n",
    "    bookW2V_altern.train(sampA, total_examples= 500, start_alpha=0.025, epochs=1)\n",
    "    for tar in two_tar:\n",
    "        tar_vector= pd.DataFrame(bookW2V_altern.wv[tar]).T #Transpose a column to a row\n",
    "        two_tar_dicofDF[tar]= two_tar_dicofDF[tar].append(tar_vector)\n",
    "        \n",
    "    bookW2V_altern.train(sampB, total_examples= 500, start_alpha=0.025, epochs=1)\n",
    "    for tar in two_tar:\n",
    "        tar_vector= pd.DataFrame(bookW2V_altern.wv[tar]).T #Transpose a column to a row\n",
    "        two_tar_dicofDF[tar]= two_tar_dicofDF[tar].append(tar_vector)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_tar_dicofDF[\"他\"].to_csv(\"bookW2V_altern他.csv\")\n",
    "two_tar_dicofDF[\"她\"].to_csv(\"bookW2V_altern她.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102393, 200)"
      ]
     },
     "execution_count": 1235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookW2V_altern.wv.syn0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "500 male novels (epoch 1), then 500 female novels (epoch 2), then 500 male novels (epoch 3), then 500 female (epoch 4) and so on for 600 epochs in total. \n",
    "\n",
    "The blue line is similarity between \"he\" verctor of one epoch and \"he\" verctor of the previous epoch; the red line is similarity between \"she\" verctor of one epoch and \"she\" verctor of the previous epoch. The lower the similarity socre between consecutive epochs, the more surprised the model is. As shown in the graph below, the entire \"he\" line is below the \"she\" line. This means that the model more surprised about the context of \"he\" when the model alternates between male and female novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1bd8051f98>"
      ]
     },
     "execution_count": 1272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1be2134780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fluctuation_from_previous(a_DF):\n",
    "    #Input is an epoch * dimension dataframe\n",
    "    re_DF= a_DF.reset_index()\n",
    "    output_sim_list= []\n",
    "    for ind in range(re_DF.shape[0]):\n",
    "        if ind == 0:\n",
    "            previous= re_DF.iloc[0]\n",
    "            \n",
    "        else:\n",
    "            current= re_DF.iloc[ind]\n",
    "           \n",
    "            output_sim_list+= \\\n",
    "            [sklearn.metrics.pairwise.cosine_similarity(previous.reshape(1,-1), current.reshape(1,-1))[0][0]]\n",
    "            previous= current\n",
    "    return output_sim_list\n",
    "\n",
    "he_fluctuation= fluctuation_from_previous(two_tar_dicofDF[\"他\"])\n",
    "she_fluctuation= fluctuation_from_previous(two_tar_dicofDF[\"她\"])\n",
    "\n",
    "\n",
    "x= [i for i in range(1, 600)]    \n",
    "\n",
    "\n",
    "plt.plot(x, he_fluctuation, 'darkblue', label='\"he\" fluctuation')\n",
    "plt.plot(x, she_fluctuation, \"darkred\", label= '\"she\" fluctuation')\n",
    "plt.axis([0, 601, 0, 1])\n",
    "plt.xticks(np.arange(0, 601, 50))\n",
    "plt.ylabel(\"cosine similarity\")\n",
    "plt.xlabel(\"half-epoch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploting words on a gender dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18460079,  0.49904427,  1.5926014 , ...,  0.7852894 ,\n",
       "         2.9510896 ,  0.84896743],\n",
       "       [ 0.20671488, -0.18960692,  2.363801  , ...,  0.6791583 ,\n",
       "         1.6088402 , -0.33376583],\n",
       "       [ 1.1217331 , -0.3688375 , -0.07849975, ...,  1.3457477 ,\n",
       "         1.5685208 , -1.375219  ],\n",
       "       ...,\n",
       "       [ 2.1345487 ,  1.1804278 , -0.94299996, ...,  1.421387  ,\n",
       "         5.657922  , -0.0867824 ],\n",
       "       [ 3.37601   , -2.411012  , -0.61300266, ..., -1.0828315 ,\n",
       "         3.057328  ,  1.4912338 ],\n",
       "       [-1.1188415 , -4.4074726 , -1.8513417 , ..., -1.2511324 ,\n",
       "         5.2649016 ,  0.84828186]], dtype=float32)"
      ]
     },
     "execution_count": 1290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#words to create dimensions\n",
    "tnytTargetWords = [\"female_he\", \"female_she\" , 'male_he', \"male_she\"]\n",
    "#\n",
    "\n",
    "#words we will be mapping\n",
    "tnytTargetWords += [\"善良\", \"冷酷\", \n",
    "                    \"温柔\", \"粗暴\",  \n",
    "                    \"强大\", \n",
    "                    \"残暴\",\n",
    "                    \"柔软\", \"坚硬\", \n",
    "                    \"纯净\",  \n",
    "                    \"心软\", \"强硬\",\n",
    "                    \"痛苦\", \"欢乐\", \n",
    "                    \"悲惨\", \"幸福\", \n",
    "                    \"嫉妒\", \"妒忌\", \n",
    "                    \"宽恕\", \"豁达\", \n",
    "                    \"贪婪\", \n",
    "                    \"惧怕\", \n",
    "                    \"支撑\", \n",
    "                    \"轻松\", \"沉重\", \n",
    "                    \"忧伤\", \"从容\", \n",
    "                    \"喜欢\", \n",
    "                    \"柔弱\", \"强壮\", \n",
    "                    \"清纯\", \"老道\"]\n",
    "target_dic= {\"male_he\": \"male_he\", \"male_she\": \"male_she\", \"female_he\": \"female_he\", \"female_she\": \"female_she\", \n",
    "             \"善良\": \"kind\", \"冷酷\": \"cold-blooded\", \n",
    "             \"温柔\": \"gentle\", \n",
    "             \"粗暴\": \"rude\", \n",
    "             \"强大\": \"strong\", \"柔软\": \"soft\", \"坚硬\": \"hard\", \"纯净\": \"pure\", \n",
    "             \"残暴\": \"brutal\", \"心软\": \"soft-hearted\", \"强硬\": \"tough\",\n",
    "             \"开心\": \"happy\", \"难过\": \"sad\", \"痛苦\": \"painful\", \"欢乐\": \"joy\", \n",
    "             \"悲惨\": \"miserable\", \"幸福\": \"hapiness\", \"嫉妒\": \"jealous\", \"妒忌\": \"envious\", \n",
    "             \"宽恕\": \"forgive\", \"豁达\": \"generous\", \"贪婪\": \"greedy\", \"惧怕\": \"fear\", \n",
    "             \"支撑\": \"support\", \"轻松\": \"relaxing\", \"沉重\": \"heavy\", \"忧伤\": \"sorrow\", \n",
    "             \"从容\": \"unhurried\", \"喜欢\": \"like\", \"动\": \"moving\", \"静\": \"still\", \n",
    "             \"柔弱\": \"delicate\", \"强壮\": \"robust\", \"清纯\": \"innocent\", \"老道\": \"seasoned\",\n",
    "             \"成熟\": \"mature\", \"幼稚\": \"immature\", \"哭\": \"cry\", \"笑\": \"smile\",\n",
    "             \"高手\": \"master\", \"新手\": \"newbie\"}\n",
    "\n",
    "\n",
    "wordsSubMatrix = []\n",
    "for word in tnytTargetWords:\n",
    "    wordsSubMatrix.append(bookW2V_20.wv[word])\n",
    "wordsSubMatrix = np.array(wordsSubMatrix)\n",
    "wordsSubMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female_he', 'female_she', 'male_he', 'male_she', 'kind', 'cold-blooded', 'gentle', 'rude', 'strong', 'brutal', 'soft', 'hard', 'pure', 'soft-hearted', 'tough', 'painful', 'joy', 'miserable', 'hapiness', 'jealous', 'envious', 'forgive', 'generous', 'greedy', 'fear', 'support', 'relaxing', 'heavy', 'sorrow', 'unhurried', 'like', 'delicate', 'robust', 'innocent', 'seasoned']\n"
     ]
    }
   ],
   "source": [
    "target_english= [target_dic[w] for w in tnytTargetWords]\n",
    "print(target_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1292,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaWordsNYT = sklearn.decomposition.PCA(n_components = 50).fit(wordsSubMatrix)\n",
    "reducedPCA_dataNYT = pcaWordsNYT.transform(wordsSubMatrix)\n",
    "#T-SNE is theoretically better, but you should experiment\n",
    "tsneWordsNYT = sklearn.manifold.TSNE(n_components = 2).fit_transform(reducedPCA_dataNYT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(vector):\n",
    "    normalized_vector = vector / np.linalg.norm(vector)\n",
    "    return normalized_vector\n",
    "\n",
    "def dimension(model, positives, negatives):\n",
    "    diff = sum([normalize(model[x]) for x in positives]) - sum([normalize(model[y]) for y in negatives])\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24989639]], dtype=float32)"
      ]
     },
     "execution_count": 1294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_similarity(bookW2V_20, \"female_he\", \"男\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#If I just want a gender dimension and do not care whether the gender words in male or female novel\n",
    "#I can just add them here\n",
    "gender = dimension(bookW2V_20, \n",
    "                   [\"male_he\", \"female_he\", \"男\", \"男人\", \"男孩\", \"少年\", \"小男孩\"], \n",
    "                   [\"male_she\", \"female_she\", \"女\", \"女人\", \"女孩\", \"少女\", \"小女孩\"])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDF(model, word_list):\n",
    "    g = []\n",
    "    \n",
    "    for word in word_list:\n",
    "        g.append(sklearn.metrics.pairwise.cosine_similarity(bookW2V_20[word].reshape(1,-1), gender.reshape(1,-1))[0][0])\n",
    "    \n",
    "    df = pd.DataFrame({'gender': g}, index = target_english)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "adjectiveDF = makeDF(bookW2V_20, tnytTargetWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Coloring(Series):\n",
    "    x = Series.values\n",
    "    y = x-x.min()\n",
    "    z = y/y.max()\n",
    "    c = list(plt.cm.flag(z))\n",
    "    return c\n",
    "\n",
    "def PlotDimension(ax,df, dim):\n",
    "    ax.set_frame_on(False)\n",
    "    #ax.set_title(dim, fontsize = 20)\n",
    "    colors = Coloring(df[dim])\n",
    "    for i, word in enumerate(df.index):\n",
    "        ax.annotate(word, (0, df[dim][i]), color = colors[i], alpha = 0.6, fontsize = 12)\n",
    "    MaxY = df[dim].max()\n",
    "    MinY = df[dim].min()\n",
    "    plt.ylim(MinY,MaxY)\n",
    "    plt.yticks(())\n",
    "    plt.xticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1af6efb6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (12,8))\n",
    "ax1 = fig.add_subplot(131)\n",
    "PlotDimension(ax1, adjectiveDF, 'gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, I graph network (in Gephi) to describe the novels. I could not graph with the four gender words in the network because they are associated with almost every other words and separate the nework into clear clusters centering around them. However, I can examine the network statistics of the four gender words, the result of which confirm the findings of the word embedding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following the code above\n",
    "target_4= list(target_3+ gender_target)\n",
    "adjacencyM_4, target_dic_4, target_dic_rev_4= cal_adjacencyM(bookDF_ch, \"30_ch_list_replace\", target_4)\n",
    "\n",
    "node_node_w_4= []\n",
    "for i in range(adjacencyM_4.shape[0]):\n",
    "    for j in range(i, adjacencyM_4.shape[0]):\n",
    "        if adjacencyM_4[i, j]> 0:\n",
    "            node_node_w_4+= [(target_dic_rev_4[i], \n",
    "                              target_dic_rev_4[j], \n",
    "                              adjacencyM_4[i, j])]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 1000\n",
      "Number of edges: 197922\n",
      "Average degree: 395.8440\n",
      "Average weight: 7.652282212184598\n",
      "Median weight: 2.0\n"
     ]
    }
   ],
   "source": [
    "g_4= nx.Graph()\n",
    "g_4.add_weighted_edges_from(node_node_w_4)\n",
    "\n",
    "print(nx.info(g_4))\n",
    "\n",
    "#Average weight\n",
    "print(\"Average weight:\", np.mean([d[\"weight\"] for n1, n2, d in g_4.edges(data = True)]))\n",
    "print(\"Median weight:\", np.median([d[\"weight\"] for n1, n2, d in g_4.edges(data = True)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I plot a graph that shows how the centrality value of the 4 gender words change as I trim the network based on centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ee8b6f908>"
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e5ca0cbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "male_he_trim= []\n",
    "male_she_trim= []\n",
    "female_he_trim= []\n",
    "female_she_trim= []\n",
    "\n",
    "trim_weight= [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]\n",
    "\n",
    "\n",
    "\n",
    "for w in trim_weight:\n",
    "    g_4.remove_edges_from([(n1, n2) for n1, n2, d in g_4.edges(data = True) if d['weight'] <= w])\n",
    "    \n",
    "    dcentralities = nx.degree_centrality(g_4)\n",
    "    male_he_trim+= [dcentralities['male_he']]\n",
    "    male_she_trim+= [dcentralities['male_she']]\n",
    "    female_he_trim+= [dcentralities['female_he']]\n",
    "    female_she_trim+= [dcentralities['female_she']]\n",
    "\n",
    "\n",
    "sns.set()\n",
    "plt.plot(trim_weight, male_he_trim, 'darkblue', label='\"he\" in male novel')\n",
    "plt.plot(trim_weight, male_she_trim, 'darkred', label='\"she\" in male novel')\n",
    "plt.plot(trim_weight, female_he_trim, 'steelblue',  label='\"he\" in female novel')\n",
    "plt.plot(trim_weight, female_she_trim, 'plum',  label='\"she\" in female novel')\n",
    "plt.axis([0, 60, 0, 1])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 10. Classification**\n",
    "\n",
    "*Classification.1*: I use only the gender words to do the classification, which means 14 features: \"她\" she, \"他\" he, \"女孩\" girl, \"小女孩\" little, \"男孩\" boy, \"小男孩\" little boy, \"女人\" woman, \"男人\" man, \"女\" female, \"男\" male, \"少年\" teenage boy, \"少女\" teenage girl, \"男子\" man, \"女子\" woman. This should have a higher-than-chance accuracy because the occurence of these characters are different in male and female novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "col= [\"ch\"+str(i)+\"_clean\" for i in range(1,31)]\n",
    "\n",
    "bookDF_both= pd.concat([bookDF_male_tokenized[col], bookDF_female_tokenized[col]], axis= 0)\n",
    "bookDF_both[\"gender\"]= [1]*500+ [0]*500\n",
    "#bookDF_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collapse the 30 chapters\n",
    "collapsed_ch_1000= []\n",
    "for i in range(bookDF_both.shape[0]):\n",
    "    a_book= bookDF_both.iloc[i]\n",
    "    collapsed_ch= []\n",
    "    for c in col:\n",
    "        collapsed_ch+= a_book[c]\n",
    "    collapsed_ch_1000+= [collapsed_ch]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "target= [\"她\", \"他\", \"女孩\", \"小女孩\", \"男孩\", \"小男孩\", \n",
    "         \"女人\", \"男人\", \"女\", \"男\", \"少年\", \"少女\", \"男子\", \"女子\"]\n",
    "\n",
    "#target= [\"她\", \"女孩\", \"小女孩\",\n",
    "#         \"女人\", \"女\", \"少女\"]\n",
    "\n",
    "#target= [\"他\" \"男孩\", \"小男孩\", \n",
    "#         \"男人\", \"男\", \"少年\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the 5-word windows next to the target words. \n",
    "#This is NOT ideal! There are repetitions! \n",
    "#For example, if 她 and 他 occur close to each other, the code below  \n",
    "#would get a window for 她 and another window for 他, which results in repetition.\n",
    "def get_target_window(target):\n",
    "    #Input: target is a list of target words\n",
    "    w= 5\n",
    "    windows_1000= []\n",
    "    for book in collapsed_ch_1000:\n",
    "        windows= []\n",
    "        for i in range(len(book)):\n",
    "            if book[i] in target:\n",
    "                if i< w: #This is for the first 5 (window) words\n",
    "                    window= book[0: i+w+1]\n",
    "                    windows+= window\n",
    "                else:\n",
    "                    window= book[i-w:i+w+1]\n",
    "                    windows+= window\n",
    "        windows_1000+= [windows]\n",
    "    len(windows_1000)\n",
    "\n",
    "    clf_DF= pd.DataFrame({\"gender_words\": windows_1000})\n",
    "    clf_DF[\"gender\"]= [1]*500+ [0]*500\n",
    "    clf_DF[\"gender_string\"]= clf_DF[\"gender_words\"].apply(lambda x: \" \".join(x))\n",
    "    return clf_DF\n",
    "\n",
    "clf_DF= get_target_window(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.752294</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.687778</td>\n",
       "      <td>0.709411</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.763920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.704444</td>\n",
       "      <td>0.730223</td>\n",
       "      <td>0.675422</td>\n",
       "      <td>0.794702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.691111</td>\n",
       "      <td>0.715746</td>\n",
       "      <td>0.661626</td>\n",
       "      <td>0.779510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.704444</td>\n",
       "      <td>0.726899</td>\n",
       "      <td>0.671727</td>\n",
       "      <td>0.791946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.525424</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.697778</td>\n",
       "      <td>0.726358</td>\n",
       "      <td>0.672253</td>\n",
       "      <td>0.789934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.715789</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.687778</td>\n",
       "      <td>0.715299</td>\n",
       "      <td>0.661049</td>\n",
       "      <td>0.779249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.703333</td>\n",
       "      <td>0.721585</td>\n",
       "      <td>0.673152</td>\n",
       "      <td>0.777528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.705556</td>\n",
       "      <td>0.724818</td>\n",
       "      <td>0.675048</td>\n",
       "      <td>0.782511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.669794</td>\n",
       "      <td>0.786344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.704444</td>\n",
       "      <td>0.722917</td>\n",
       "      <td>0.676413</td>\n",
       "      <td>0.776286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_accuracy   test_f1  test_precision  test_recall  train_accuracy  \\\n",
       "0           0.73  0.752294        0.706897     0.803922        0.687778   \n",
       "1           0.64  0.672727        0.587302     0.787234        0.704444   \n",
       "2           0.80  0.803922        0.803922     0.803922        0.691111   \n",
       "3           0.70  0.732143        0.694915     0.773585        0.704444   \n",
       "4           0.60  0.607843        0.525424     0.720930        0.697778   \n",
       "5           0.73  0.715789        0.708333     0.723404        0.687778   \n",
       "6           0.67  0.702703        0.696429     0.709091        0.703333   \n",
       "7           0.65  0.695652        0.655738     0.740741        0.705556   \n",
       "8           0.64  0.660377        0.583333     0.760870        0.696667   \n",
       "9           0.66  0.711864        0.646154     0.792453        0.704444   \n",
       "\n",
       "   train_f1  train_precision  train_recall  \n",
       "0  0.709411         0.662162      0.763920  \n",
       "1  0.730223         0.675422      0.794702  \n",
       "2  0.715746         0.661626      0.779510  \n",
       "3  0.726899         0.671727      0.791946  \n",
       "4  0.726358         0.672253      0.789934  \n",
       "5  0.715299         0.661049      0.779249  \n",
       "6  0.721585         0.673152      0.777528  \n",
       "7  0.724818         0.675048      0.782511  \n",
       "8  0.723404         0.669794      0.786344  \n",
       "9  0.722917         0.676413      0.776286  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10-fold cross validation--classification based on the occurence of the 14 gender words\n",
    "def cross_val_target(X, y, clf):\n",
    "    train_accuracy= []\n",
    "    test_accuracy= []\n",
    "    \n",
    "    train_precision= []\n",
    "    test_precision= []\n",
    "    \n",
    "    train_recall= []\n",
    "    test_recall= []\n",
    "    \n",
    "    train_f1= []\n",
    "    test_f1= []\n",
    "    \n",
    "    kf = KFold(n_splits=10, shuffle= True)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train_string, X_test_string = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "        vectorizer= sklearn.feature_extraction.text.CountVectorizer(vocabulary= [\"她\", \"他\", \n",
    "                                                                                 \"女孩\", \"小女孩\", \n",
    "                                                                                 \"男孩\", \"小男孩\", \n",
    "                                                                                 \"女人\", \"男人\", \n",
    "                                                                                 \"女\", \"男\", \n",
    "                                                                                 \"少年\", \"少女\",\n",
    "                                                                                 \"男子\", \"女子\"])\n",
    "        X_train_wordfeq= vectorizer.fit_transform(X_train_string)\n",
    "        X_test_wordfeq= vectorizer.transform(X_test_string)\n",
    "    \n",
    "        #Fitting the classifier, clf is defined outside of this function\n",
    "        clf.fit(X_train_wordfeq, y_train)\n",
    "        \n",
    "        y_train_pred= clf.predict(X_train_wordfeq)\n",
    "        y_test_pred= clf.predict(X_test_wordfeq)\n",
    "        \n",
    "        ##Accuracy score of training and test set\n",
    "        \n",
    "        train_accuracy+= [accuracy_score(y_train, y_train_pred)]\n",
    "        test_accuracy+= [accuracy_score(y_test, y_test_pred)]\n",
    "        \n",
    "        ##Precision score of training and test set\n",
    "        train_precision+= [precision_score(y_train, y_train_pred)]\n",
    "        test_precision+= [precision_score(y_test, y_test_pred)]\n",
    "        \n",
    "        ##Recall score of training and test set\n",
    "        train_recall+= [recall_score(y_train, y_train_pred)]\n",
    "        test_recall+= [recall_score(y_test, y_test_pred)]\n",
    "        \n",
    "        ##F1 score of training and test set\n",
    "        train_f1+= [f1_score(y_train, y_train_pred)]\n",
    "        test_f1+= [f1_score(y_test, y_test_pred)]\n",
    "        \n",
    "    summaryDF= pd.DataFrame({\"train_accuracy\": train_accuracy,\n",
    "                             \"test_accuracy\": test_accuracy,\n",
    "                             \"train_precision\": train_precision,\n",
    "                             \"test_precision\": test_precision,\n",
    "                             \"train_recall\": train_recall,\n",
    "                             \"test_recall\": test_recall,\n",
    "                             \"train_f1\": train_f1,\n",
    "                             \"test_f1\": test_f1})\n",
    "    \n",
    "    \n",
    "    return summaryDF\n",
    "\n",
    "X= clf_DF[\"gender_string\"]\n",
    "y= clf_DF[\"gender\"]\n",
    "\n",
    "clf_lr = sklearn.linear_model.LogisticRegression()\n",
    "outcome_use_target= cross_val_target(X, y, clf_lr)\n",
    "outcome_use_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.682"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_use_target[\"test_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Classification.2*: Utilize the windows next to the gender words (the local context of the gender words). I perform the simple CountVectorizer to calculat the frequency of each words, then use PCA to extract features out of the plain word-frequency count. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Testing phase with one split: \"\"\"\n",
    "#Which classifier works the best?\n",
    "#How many PCA factors?\n",
    "\n",
    "X_train_string, X_test_string, y_train, y_test= \\\n",
    "train_test_split(clf_DF[\"gender_string\"], clf_DF[\"gender\"], test_size= 0.1)\n",
    "\n",
    "vectorizer= sklearn.feature_extraction.text.CountVectorizer()\n",
    "X_train_wordfeq= vectorizer.fit_transform(X_train_string)\n",
    "X_test_wordfeq= vectorizer.transform(X_test_string)\n",
    "\n",
    "pca = sklearn.decomposition.PCA(n_components = 200)\n",
    "X_train = pca.fit_transform(X_train_wordfeq.toarray())\n",
    "X_test= pca.transform(X_test_wordfeq.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier: clf_naive\n",
      "50\n",
      "training's accuracy:  0.6088888888888889\n",
      "testing's accuracy:  0.5\n",
      "100\n",
      "training's accuracy:  0.6122222222222222\n",
      "testing's accuracy:  0.48\n",
      "150\n",
      "training's accuracy:  0.6166666666666667\n",
      "testing's accuracy:  0.48\n",
      "200\n",
      "training's accuracy:  0.6166666666666667\n",
      "testing's accuracy:  0.47\n",
      "\n",
      "classifier: clf_lr\n",
      "50\n",
      "training's accuracy:  0.9122222222222223\n",
      "testing's accuracy:  0.87\n",
      "100\n",
      "training's accuracy:  0.9555555555555556\n",
      "testing's accuracy:  0.93\n",
      "150\n",
      "training's accuracy:  0.98\n",
      "testing's accuracy:  0.92\n",
      "200\n",
      "training's accuracy:  0.9966666666666667\n",
      "testing's accuracy:  0.9\n",
      "\n",
      "classifier: clf_SVClinear\n",
      "50\n",
      "training's accuracy:  0.9188888888888889\n",
      "testing's accuracy:  0.86\n",
      "100\n",
      "training's accuracy:  0.9577777777777777\n",
      "testing's accuracy:  0.94\n",
      "150\n",
      "training's accuracy:  0.9888888888888889\n",
      "testing's accuracy:  0.94\n",
      "200\n",
      "training's accuracy:  1.0\n",
      "testing's accuracy:  0.88\n",
      "\n",
      "classifier: clf_SVCrbf\n",
      "50\n",
      "training's accuracy:  1.0\n",
      "testing's accuracy:  0.43\n",
      "100\n",
      "training's accuracy:  1.0\n",
      "testing's accuracy:  0.43\n",
      "150\n",
      "training's accuracy:  1.0\n",
      "testing's accuracy:  0.43\n",
      "200\n",
      "training's accuracy:  1.0\n",
      "testing's accuracy:  0.43\n",
      "\n",
      "classifier: clf_KNN\n",
      "50\n",
      "training's accuracy:  1.0\n",
      "testing's accuracy:  0.81\n",
      "100\n",
      "training's accuracy:  1.0\n",
      "testing's accuracy:  0.79\n",
      "150\n",
      "training's accuracy:  1.0\n",
      "testing's accuracy:  0.78\n",
      "200\n",
      "training's accuracy:  1.0\n",
      "testing's accuracy:  0.76\n",
      "\n",
      "classifier: clf_tree\n",
      "50\n",
      "training's accuracy:  1.0\n",
      "testing's accuracy:  0.78\n",
      "100\n",
      "training's accuracy:  1.0\n",
      "testing's accuracy:  0.76\n",
      "150\n",
      "training's accuracy:  1.0\n",
      "testing's accuracy:  0.81\n",
      "200\n",
      "training's accuracy:  1.0\n",
      "testing's accuracy:  0.84\n",
      "\n",
      "classifier: clf_forest\n",
      "50\n",
      "training's accuracy:  0.9944444444444445\n",
      "testing's accuracy:  0.85\n",
      "100\n",
      "training's accuracy:  0.9922222222222222\n",
      "testing's accuracy:  0.86\n",
      "150\n",
      "training's accuracy:  0.9877777777777778\n",
      "testing's accuracy:  0.77\n",
      "200\n",
      "training's accuracy:  0.9922222222222222\n",
      "testing's accuracy:  0.78\n",
      "\n",
      "classifier: clf_neural\n",
      "50\n",
      "training's accuracy:  0.9966666666666667\n",
      "testing's accuracy:  0.88\n",
      "100\n",
      "training's accuracy:  0.9988888888888889\n",
      "testing's accuracy:  0.88\n",
      "150\n",
      "training's accuracy:  0.9988888888888889\n",
      "testing's accuracy:  0.89\n",
      "200\n",
      "training's accuracy:  0.9988888888888889\n",
      "testing's accuracy:  0.92\n",
      "\n",
      "classifier: clf_ensemble\n",
      "50\n",
      "training's accuracy:  0.9944444444444445\n",
      "testing's accuracy:  0.85\n",
      "100\n",
      "training's accuracy:  0.9977777777777778\n",
      "testing's accuracy:  0.84\n",
      "150\n",
      "training's accuracy:  0.9988888888888889\n",
      "testing's accuracy:  0.84\n",
      "200\n",
      "training's accuracy:  1.0\n",
      "testing's accuracy:  0.84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Testing phase with one split: \"\"\"\n",
    "\n",
    "clf_naive = sklearn.naive_bayes.GaussianNB()\n",
    "clf_SVClinear = sklearn.svm.SVC(kernel = 'linear', probability = True) \n",
    "clf_SVCrbf = sklearn.svm.SVC(kernel = 'rbf', degree = 3, probability = True) \n",
    "clf_KNN = sklearn.neighbors.KNeighborsClassifier(6, weights='distance')\n",
    "clf_lr = sklearn.linear_model.LogisticRegression()\n",
    "clf_tree = sklearn.tree.DecisionTreeClassifier()\n",
    "clf_forest = sklearn.ensemble.RandomForestClassifier()\n",
    "clf_neural = sklearn.neural_network.MLPClassifier()\n",
    "clf_ensemble = sklearn.ensemble.GradientBoostingClassifier()\n",
    "\n",
    "clf_collection= {\"clf_naive\": clf_naive, \"clf_lr\": clf_lr,\n",
    "                 \"clf_SVClinear\": clf_SVClinear,\n",
    "                 \"clf_SVCrbf\": clf_SVCrbf, \"clf_KNN\": clf_KNN, \"clf_tree\": clf_tree,\n",
    "                 \"clf_forest\": clf_forest, \"clf_neural\": clf_neural, \n",
    "                 \"clf_ensemble\": clf_ensemble}\n",
    "\n",
    "for name, clf in clf_collection.items():      \n",
    "        print(\"classifier:\", name)     \n",
    "        for i in [50, 100, 150, 200]:\n",
    "            print(i)      \n",
    "            clf.fit(X_train[:, :i], y_train)\n",
    "\n",
    "            y_train_pred= clf.predict(X_train[:, :i])\n",
    "            print(\"training's accuracy: \", accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "            y_test_pred= clf.predict(X_test[:, :i])\n",
    "            print(\"testing's accuracy: \", accuracy_score(y_test, y_test_pred))\n",
    "        print()  \n",
    "#Decide to choose linear regression classify using 150 PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.985556</td>\n",
       "      <td>0.985604</td>\n",
       "      <td>0.982340</td>\n",
       "      <td>0.988889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981111</td>\n",
       "      <td>0.981215</td>\n",
       "      <td>0.980132</td>\n",
       "      <td>0.982301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.986726</td>\n",
       "      <td>0.984547</td>\n",
       "      <td>0.988914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.978889</td>\n",
       "      <td>0.979052</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.984479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.986517</td>\n",
       "      <td>0.977728</td>\n",
       "      <td>0.995465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.989201</td>\n",
       "      <td>0.984946</td>\n",
       "      <td>0.993492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.989989</td>\n",
       "      <td>0.986696</td>\n",
       "      <td>0.993304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.900901</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.985556</td>\n",
       "      <td>0.985377</td>\n",
       "      <td>0.979866</td>\n",
       "      <td>0.990950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.990011</td>\n",
       "      <td>0.986726</td>\n",
       "      <td>0.993318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.884211</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.990121</td>\n",
       "      <td>0.989035</td>\n",
       "      <td>0.991209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_accuracy   test_f1  test_precision  test_recall  train_accuracy  \\\n",
       "0           0.94  0.938776        0.958333     0.920000        0.985556   \n",
       "1           0.98  0.979592        0.960000     1.000000        0.981111   \n",
       "2           0.92  0.916667        0.936170     0.897959        0.986667   \n",
       "3           0.94  0.941176        0.905660     0.979592        0.978889   \n",
       "4           0.94  0.948276        0.964912     0.932203        0.986667   \n",
       "5           0.90  0.883721        0.808511     0.974359        0.988889   \n",
       "6           0.91  0.914286        0.905660     0.923077        0.990000   \n",
       "7           0.89  0.900901        0.943396     0.862069        0.985556   \n",
       "8           0.91  0.912621        0.903846     0.921569        0.990000   \n",
       "9           0.89  0.884211        0.840000     0.933333        0.990000   \n",
       "\n",
       "   train_f1  train_precision  train_recall  \n",
       "0  0.985604         0.982340      0.988889  \n",
       "1  0.981215         0.980132      0.982301  \n",
       "2  0.986726         0.984547      0.988914  \n",
       "3  0.979052         0.973684      0.984479  \n",
       "4  0.986517         0.977728      0.995465  \n",
       "5  0.989201         0.984946      0.993492  \n",
       "6  0.989989         0.986696      0.993304  \n",
       "7  0.985377         0.979866      0.990950  \n",
       "8  0.990011         0.986726      0.993318  \n",
       "9  0.990121         0.989035      0.991209  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_val_pca(X, y, clf):\n",
    "    train_accuracy= []\n",
    "    test_accuracy= []\n",
    "    \n",
    "    train_precision= []\n",
    "    test_precision= []\n",
    "\n",
    "    train_recall= []\n",
    "    test_recall= []\n",
    "    \n",
    "    train_f1= []\n",
    "    test_f1= []\n",
    "    \n",
    "    kf = KFold(n_splits=10, shuffle= True)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train_string, X_test_string = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "        vectorizer= sklearn.feature_extraction.text.CountVectorizer()\n",
    "        X_train_wordfeq= vectorizer.fit_transform(X_train_string)\n",
    "        X_test_wordfeq= vectorizer.transform(X_test_string)\n",
    "\n",
    "        pca = sklearn.decomposition.PCA(n_components = 150)\n",
    "        X_train = pca.fit_transform(X_train_wordfeq.toarray())\n",
    "        X_test= pca.transform(X_test_wordfeq.toarray())\n",
    "        \n",
    "    \n",
    "        #Fitting the classifier, clf is defined outside of this function\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred= clf.predict(X_train)\n",
    "        y_test_pred= clf.predict(X_test)\n",
    "        \n",
    "        ##Accuracy score of training and test set\n",
    "        \n",
    "        train_accuracy+= [accuracy_score(y_train, y_train_pred)]\n",
    "        test_accuracy+= [accuracy_score(y_test, y_test_pred)]\n",
    "        \n",
    "        ##Precision score of training and test set\n",
    "        train_precision+= [precision_score(y_train, y_train_pred)]\n",
    "        test_precision+= [precision_score(y_test, y_test_pred)]\n",
    "        \n",
    "        ##Recall score of training and test set\n",
    "        train_recall+= [recall_score(y_train, y_train_pred)]\n",
    "        test_recall+= [recall_score(y_test, y_test_pred)]\n",
    "        \n",
    "        ##F1 score of training and test set\n",
    "        train_f1+= [f1_score(y_train, y_train_pred)]\n",
    "        test_f1+= [f1_score(y_test, y_test_pred)]\n",
    "        \n",
    "    summaryDF= pd.DataFrame({\"train_accuracy\": train_accuracy,\n",
    "                             \"test_accuracy\": test_accuracy,\n",
    "                             \"train_precision\": train_precision,\n",
    "                             \"test_precision\": test_precision,\n",
    "                             \"train_recall\": train_recall,\n",
    "                             \"test_recall\": test_recall,\n",
    "                             \"train_f1\": train_f1,\n",
    "                             \"test_f1\": test_f1})\n",
    "    \n",
    "    \n",
    "    return summaryDF\n",
    "\n",
    "X= clf_DF[\"gender_string\"]\n",
    "y= clf_DF[\"gender\"]\n",
    "\n",
    "outcome_use_pca= cross_val_pca(X, y, clf_lr)\n",
    "outcome_use_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.922"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_use_pca[\"test_accuracy\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5 Emotion\n",
    "\n",
    "***Section Overview***\n",
    "\n",
    "I utilize a Chinese sentiment dictionary called dalian sentiment word list (http://ir.dlut.edu.cn/EmotionOntologyDownload). It contains 27466 Chinese words and categories them into one of 21 sentiment categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bookDF_male_tokenized= pd.read_pickle(\"bookDF_male_tokenized.pickle\")\n",
    "bookDF_female_tokenized= pd.read_pickle(\"bookDF_female_tokenized.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Collapse 30 chapters\\nhelper_lis= [] \\nfor i in range(bookDF_ch.shape[0]):\\n    cell= []\\n    for j in range(30):\\n        cell+= bookDF_ch.iloc[i][\"ch\"+str(j+1)+\"_clean\"]\\n    helper_lis+= [cell]\\n\\nchDF_list= pd.DataFrame({\"ch_list\": helper_lis})\\n'"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper_col= []\n",
    "for i in range(30):\n",
    "    helper_col+= [\"ch\"+str(i+1)+\"_clean\"]\n",
    "bookDF_ch= pd.concat([bookDF_male_tokenized[helper_col], bookDF_female_tokenized[helper_col]], axis= 0)\n",
    "bookDF_ch[\"book_gender\"]= pd.DataFrame([\"boy\"]* 500+ [\"girl\"]*500)\n",
    "\n",
    "\"\"\"\n",
    "#Collapse 30 chapters\n",
    "helper_lis= [] \n",
    "for i in range(bookDF_ch.shape[0]):\n",
    "    cell= []\n",
    "    for j in range(30):\n",
    "        cell+= bookDF_ch.iloc[i][\"ch\"+str(j+1)+\"_clean\"]\n",
    "    helper_lis+= [cell]\n",
    "\n",
    "chDF_list= pd.DataFrame({\"ch_list\": helper_lis})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['词语', '词性种类', '词义数', '词义序号', '情感分类', '强度', '极性', '辅助情感分类', '强度.1',\n",
      "       '极性.1', 'Unnamed: 10', 'Unnamed: 11'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "dalian= pd.read_excel(\"dalian_sentiment_word.xlsx\", encoding=\"latin-1\")\n",
    "print(dalian.columns)\n",
    "\n",
    "dalian_dic= {}\n",
    "for i in range(dalian.shape[0]):\n",
    "    dalian_dic[dalian[\"词语\"].iloc[i]]= \\\n",
    "    [dalian[\"极性\"].iloc[i], dalian[\"强度\"].iloc[i], dalian[\"情感分类\"].iloc[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_tag_list= [\"PA\", \"PE\", \"PD\", \"PH\", \"PG\", \"PB\", \"PK\",\n",
    "               \"NR\", \"NB\", \"NJ\", \"NH\", \"PF\", \"NI\", \"NC\",\n",
    "               \"NG\", \"NE\", \"ND\", \"NN\", \"NK\", \"NL\", \"PC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Testing\"\"\"\n",
    "tag= dalian_dic[\"愤怒\"][2]\n",
    "intense= dalian_dic[\"愤怒\"][1]\n",
    "ch_emo_dic= {\"PA\": 0, \"PE\": 0, \"PD\": 0, \"PH\": 0, \n",
    "             \"PG\": 0, \"PB\": 0, \"PK\": 0, \"NR\": 0, \n",
    "             \"NB\": 0, \"NJ\": 0, \"NH\": 0, \"PF\": 0, \n",
    "             \"NI\": 0, \"NC\": 0, \"NG\": 0, \"NE\": 0, \n",
    "             \"ND\": 0, \"NN\": 0, \"NK\": 0, \"NL\": 0, \n",
    "             \"PC\": 0}\n",
    "ch_emo_dic[tag]+= intense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_ch_emotion_DF= pd.DataFrame({})\n",
    "for ind in range(bookDF_ch.shape[0]):\n",
    "    book= bookDF_ch.iloc[ind]\n",
    "    ch_emo_DF= pd.DataFrame({})\n",
    "    for i in range(30):\n",
    "        ch= book[\"ch\"+ str(i+1)+ \"_clean\"]\n",
    "        ch_emo_dic= {\"chapter\": i+1,\n",
    "                     \"PA\": [0], \"PE\": [0], \"PD\": [0], \"PH\": [0], \n",
    "                     \"PG\": [0], \"PB\": [0], \"PK\": [0], \"NR\": [0], \n",
    "                     \"NB\": [0], \"NJ\": [0], \"NH\": [0], \"PF\": [0], \n",
    "                     \"NI\": [0], \"NC\": [0], \"NG\": [0], \"NE\": [0], \n",
    "                     \"ND\": [0], \"NN\": [0], \"NK\": [0], \"NL\": [0], \n",
    "                     \"PC\": [0]}\n",
    "        for w in ch:\n",
    "            if w in dalian_dic:\n",
    "                tag= dalian_dic[w][2]\n",
    "                intense= dalian_dic[w][1]\n",
    "                \n",
    "                \"\"\"I normalize the emotion score by the length of the chapter\"\"\"\n",
    "                ch_emo_dic[tag][0]+= intense/len(ch)\n",
    "\n",
    "                     \n",
    "        ch_emo_DF= ch_emo_DF.append(pd.DataFrame(ch_emo_dic))\n",
    "        \n",
    "    ch_emo_DF[\"book\"]= [\"book\"+ str(ind)]*30\n",
    "    #if ind== 0:\n",
    "    #    print(ch_emo_DF)\n",
    "    book_ch_emotion_DF= book_ch_emotion_DF.append(ch_emo_DF)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NB', 'NC', 'ND', 'NE', 'NG', 'NH', 'NI', 'NJ', 'NK', 'NL', 'NN', 'NR', 'PA', 'PB', 'PC', 'PD', 'PE', 'PF', 'PG', 'PH', 'PK', 'chapter', 'book']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_emo_raw</th>\n",
       "      <th>male_emo_raw</th>\n",
       "      <th>female_emo_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>648.083354</td>\n",
       "      <td>305.120963</td>\n",
       "      <td>342.962391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NC</th>\n",
       "      <td>389.955204</td>\n",
       "      <td>233.170473</td>\n",
       "      <td>156.784731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ND</th>\n",
       "      <td>792.788023</td>\n",
       "      <td>429.005383</td>\n",
       "      <td>363.782640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NE</th>\n",
       "      <td>631.661377</td>\n",
       "      <td>287.470684</td>\n",
       "      <td>344.190693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NG</th>\n",
       "      <td>56.479196</td>\n",
       "      <td>24.871759</td>\n",
       "      <td>31.607437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NH</th>\n",
       "      <td>128.565918</td>\n",
       "      <td>54.089794</td>\n",
       "      <td>74.476125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NI</th>\n",
       "      <td>197.518157</td>\n",
       "      <td>94.286953</td>\n",
       "      <td>103.231204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJ</th>\n",
       "      <td>198.439793</td>\n",
       "      <td>102.744623</td>\n",
       "      <td>95.695171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NK</th>\n",
       "      <td>16.708254</td>\n",
       "      <td>7.215954</td>\n",
       "      <td>9.492300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NL</th>\n",
       "      <td>206.666612</td>\n",
       "      <td>102.504677</td>\n",
       "      <td>104.161935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>2216.803139</td>\n",
       "      <td>1128.228789</td>\n",
       "      <td>1088.574351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>261.951135</td>\n",
       "      <td>142.284108</td>\n",
       "      <td>119.667027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA</th>\n",
       "      <td>1674.575008</td>\n",
       "      <td>821.956449</td>\n",
       "      <td>852.618559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PB</th>\n",
       "      <td>861.371815</td>\n",
       "      <td>388.268837</td>\n",
       "      <td>473.102978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC</th>\n",
       "      <td>427.305940</td>\n",
       "      <td>241.202871</td>\n",
       "      <td>186.103068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PD</th>\n",
       "      <td>679.770414</td>\n",
       "      <td>361.619914</td>\n",
       "      <td>318.150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PE</th>\n",
       "      <td>400.084990</td>\n",
       "      <td>188.252998</td>\n",
       "      <td>211.831992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PF</th>\n",
       "      <td>105.739829</td>\n",
       "      <td>40.332544</td>\n",
       "      <td>65.407286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PG</th>\n",
       "      <td>735.407770</td>\n",
       "      <td>385.703338</td>\n",
       "      <td>349.704432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PH</th>\n",
       "      <td>3740.852485</td>\n",
       "      <td>2044.178311</td>\n",
       "      <td>1696.674173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PK</th>\n",
       "      <td>364.647985</td>\n",
       "      <td>197.939315</td>\n",
       "      <td>166.708670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    total_emo_raw  male_emo_raw  female_emo_raw\n",
       "NB     648.083354    305.120963      342.962391\n",
       "NC     389.955204    233.170473      156.784731\n",
       "ND     792.788023    429.005383      363.782640\n",
       "NE     631.661377    287.470684      344.190693\n",
       "NG      56.479196     24.871759       31.607437\n",
       "NH     128.565918     54.089794       74.476125\n",
       "NI     197.518157     94.286953      103.231204\n",
       "NJ     198.439793    102.744623       95.695171\n",
       "NK      16.708254      7.215954        9.492300\n",
       "NL     206.666612    102.504677      104.161935\n",
       "NN    2216.803139   1128.228789     1088.574351\n",
       "NR     261.951135    142.284108      119.667027\n",
       "PA    1674.575008    821.956449      852.618559\n",
       "PB     861.371815    388.268837      473.102978\n",
       "PC     427.305940    241.202871      186.103068\n",
       "PD     679.770414    361.619914      318.150500\n",
       "PE     400.084990    188.252998      211.831992\n",
       "PF     105.739829     40.332544       65.407286\n",
       "PG     735.407770    385.703338      349.704432\n",
       "PH    3740.852485   2044.178311     1696.674173\n",
       "PK     364.647985    197.939315      166.708670"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(book_ch_emotion_DF.columns))\n",
    "\n",
    "emotion_mean_total_raw= book_ch_emotion_DF.iloc[:, :21].sum(axis= 0)\n",
    "emotion_mean_male_raw= book_ch_emotion_DF.iloc[:15000, :21].sum(axis= 0)\n",
    "emotion_mean_female_raw= book_ch_emotion_DF.iloc[15000:, :21].sum(axis= 0)\n",
    "\n",
    "emotion_mean_DF= pd.DataFrame({})\n",
    "emotion_mean_DF[\"total_emo_raw\"]= emotion_mean_total_raw\n",
    "emotion_mean_DF[\"male_emo_raw\"]= emotion_mean_male_raw\n",
    "emotion_mean_DF[\"female_emo_raw\"]= emotion_mean_female_raw\n",
    "emotion_mean_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.94211671, -1.5       , -1.11803399, -0.85895569],\n",
       "       [-0.12288479, -0.5       , -0.2236068 , -0.07808688],\n",
       "       [ 0.69634713,  0.5       ,  0.67082039,  0.70278193],\n",
       "       [ 1.51557905,  1.5       ,  1.56524758,  1.48365074],\n",
       "       [-1.14692469,  0.        , -0.89442719, -1.2493901 ]])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Testing\"\"\"\n",
    "a= np.array([[1, 2, 3, 4], \n",
    "             [5, 6, 7, 8],\n",
    "             [9, 10, 11, 12],\n",
    "             [13, 14, 15, 16],\n",
    "             [0, 8, 4, 2]])\n",
    "(a- a.mean(axis= 0))/a.std(axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-11.267303054692732]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test= scipy.stats.ttest_ind(book_ch_emotion_np_norm[:15000, 0], \n",
    "                                  book_ch_emotion_np_norm[15000:, 0])\n",
    "[t_test.statistic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NB', 'NC', 'ND', 'NE', 'NG', 'NH', 'NI', 'NJ', 'NK', 'NL', 'NN', 'NR', 'PA', 'PB', 'PC', 'PD', 'PE', 'PF', 'PG', 'PH', 'PK']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_emo_raw</th>\n",
       "      <th>male_emo_raw</th>\n",
       "      <th>female_emo_raw</th>\n",
       "      <th>male_norm</th>\n",
       "      <th>female_norm</th>\n",
       "      <th>t_statistic</th>\n",
       "      <th>t_pvalue</th>\n",
       "      <th>chi_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>648.083</td>\n",
       "      <td>305.121</td>\n",
       "      <td>342.962</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>-11.267</td>\n",
       "      <td>0.000</td>\n",
       "      <td>悲伤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NC</th>\n",
       "      <td>389.955</td>\n",
       "      <td>233.170</td>\n",
       "      <td>156.785</td>\n",
       "      <td>0.159</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>27.855</td>\n",
       "      <td>0.000</td>\n",
       "      <td>恐惧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ND</th>\n",
       "      <td>792.788</td>\n",
       "      <td>429.005</td>\n",
       "      <td>363.783</td>\n",
       "      <td>0.077</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>13.299</td>\n",
       "      <td>0.000</td>\n",
       "      <td>憎恶</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NE</th>\n",
       "      <td>631.661</td>\n",
       "      <td>287.471</td>\n",
       "      <td>344.191</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.114</td>\n",
       "      <td>-19.794</td>\n",
       "      <td>0.000</td>\n",
       "      <td>烦闷</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NG</th>\n",
       "      <td>56.479</td>\n",
       "      <td>24.872</td>\n",
       "      <td>31.607</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-9.428</td>\n",
       "      <td>0.000</td>\n",
       "      <td>羞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NH</th>\n",
       "      <td>128.566</td>\n",
       "      <td>54.090</td>\n",
       "      <td>74.476</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>0.086</td>\n",
       "      <td>-14.934</td>\n",
       "      <td>0.000</td>\n",
       "      <td>疚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NI</th>\n",
       "      <td>197.518</td>\n",
       "      <td>94.287</td>\n",
       "      <td>103.231</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-5.773</td>\n",
       "      <td>0.000</td>\n",
       "      <td>慌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJ</th>\n",
       "      <td>198.440</td>\n",
       "      <td>102.745</td>\n",
       "      <td>95.695</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>4.324</td>\n",
       "      <td>0.000</td>\n",
       "      <td>失望</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NK</th>\n",
       "      <td>16.708</td>\n",
       "      <td>7.216</td>\n",
       "      <td>9.492</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-4.276</td>\n",
       "      <td>0.000</td>\n",
       "      <td>妒忌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NL</th>\n",
       "      <td>206.667</td>\n",
       "      <td>102.505</td>\n",
       "      <td>104.162</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-1.047</td>\n",
       "      <td>0.295</td>\n",
       "      <td>怀疑</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>2216.803</td>\n",
       "      <td>1128.229</td>\n",
       "      <td>1088.574</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>5.554</td>\n",
       "      <td>0.000</td>\n",
       "      <td>贬责</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>261.951</td>\n",
       "      <td>142.284</td>\n",
       "      <td>119.667</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>10.870</td>\n",
       "      <td>0.000</td>\n",
       "      <td>愤怒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA</th>\n",
       "      <td>1674.575</td>\n",
       "      <td>821.956</td>\n",
       "      <td>852.619</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-5.173</td>\n",
       "      <td>0.000</td>\n",
       "      <td>快乐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PB</th>\n",
       "      <td>861.372</td>\n",
       "      <td>388.269</td>\n",
       "      <td>473.103</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-16.668</td>\n",
       "      <td>0.000</td>\n",
       "      <td>喜爱</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC</th>\n",
       "      <td>427.306</td>\n",
       "      <td>241.203</td>\n",
       "      <td>186.103</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>21.868</td>\n",
       "      <td>0.000</td>\n",
       "      <td>惊奇</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PD</th>\n",
       "      <td>679.770</td>\n",
       "      <td>361.620</td>\n",
       "      <td>318.150</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>8.699</td>\n",
       "      <td>0.000</td>\n",
       "      <td>尊敬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PE</th>\n",
       "      <td>400.085</td>\n",
       "      <td>188.253</td>\n",
       "      <td>211.832</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-7.717</td>\n",
       "      <td>0.000</td>\n",
       "      <td>安心</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PF</th>\n",
       "      <td>105.740</td>\n",
       "      <td>40.333</td>\n",
       "      <td>65.407</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-18.900</td>\n",
       "      <td>0.000</td>\n",
       "      <td>思</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PG</th>\n",
       "      <td>735.408</td>\n",
       "      <td>385.703</td>\n",
       "      <td>349.704</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>6.989</td>\n",
       "      <td>0.000</td>\n",
       "      <td>相信</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PH</th>\n",
       "      <td>3740.852</td>\n",
       "      <td>2044.178</td>\n",
       "      <td>1696.674</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>30.498</td>\n",
       "      <td>0.000</td>\n",
       "      <td>赞扬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PK</th>\n",
       "      <td>364.648</td>\n",
       "      <td>197.939</td>\n",
       "      <td>166.709</td>\n",
       "      <td>0.074</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>12.933</td>\n",
       "      <td>0.000</td>\n",
       "      <td>祝愿</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    total_emo_raw  male_emo_raw  female_emo_raw  male_norm  female_norm  \\\n",
       "NB        648.083       305.121         342.962     -0.065        0.065   \n",
       "NC        389.955       233.170         156.785      0.159       -0.159   \n",
       "ND        792.788       429.005         363.783      0.077       -0.077   \n",
       "NE        631.661       287.471         344.191     -0.114        0.114   \n",
       "NG         56.479        24.872          31.607     -0.054        0.054   \n",
       "NH        128.566        54.090          74.476     -0.086        0.086   \n",
       "NI        197.518        94.287         103.231     -0.033        0.033   \n",
       "NJ        198.440       102.745          95.695      0.025       -0.025   \n",
       "NK         16.708         7.216           9.492     -0.025        0.025   \n",
       "NL        206.667       102.505         104.162     -0.006        0.006   \n",
       "NN       2216.803      1128.229        1088.574      0.032       -0.032   \n",
       "NR        261.951       142.284         119.667      0.063       -0.063   \n",
       "PA       1674.575       821.956         852.619     -0.030        0.030   \n",
       "PB        861.372       388.269         473.103     -0.096        0.096   \n",
       "PC        427.306       241.203         186.103      0.125       -0.125   \n",
       "PD        679.770       361.620         318.150      0.050       -0.050   \n",
       "PE        400.085       188.253         211.832     -0.045        0.045   \n",
       "PF        105.740        40.333          65.407     -0.108        0.108   \n",
       "PG        735.408       385.703         349.704      0.040       -0.040   \n",
       "PH       3740.852      2044.178        1696.674      0.173       -0.173   \n",
       "PK        364.648       197.939         166.709      0.074       -0.074   \n",
       "\n",
       "    t_statistic  t_pvalue chi_label  \n",
       "NB      -11.267     0.000        悲伤  \n",
       "NC       27.855     0.000        恐惧  \n",
       "ND       13.299     0.000        憎恶  \n",
       "NE      -19.794     0.000        烦闷  \n",
       "NG       -9.428     0.000         羞  \n",
       "NH      -14.934     0.000         疚  \n",
       "NI       -5.773     0.000         慌  \n",
       "NJ        4.324     0.000        失望  \n",
       "NK       -4.276     0.000        妒忌  \n",
       "NL       -1.047     0.295        怀疑  \n",
       "NN        5.554     0.000        贬责  \n",
       "NR       10.870     0.000        愤怒  \n",
       "PA       -5.173     0.000        快乐  \n",
       "PB      -16.668     0.000        喜爱  \n",
       "PC       21.868     0.000        惊奇  \n",
       "PD        8.699     0.000        尊敬  \n",
       "PE       -7.717     0.000        安心  \n",
       "PF      -18.900     0.000         思  \n",
       "PG        6.989     0.000        相信  \n",
       "PH       30.498     0.000        赞扬  \n",
       "PK       12.933     0.000        祝愿  "
      ]
     },
     "execution_count": 1276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I first standardize each emotion by its column\n",
    "#For each column, the 30000 cells sum up to 0\n",
    "#Now the \"important\" emotions no longer overshadow the \"unimportant\" ones\n",
    "\n",
    "emotion_col= list(book_ch_emotion_DF.columns)[:21]\n",
    "print(emotion_col)\n",
    "\n",
    "book_ch_emotion_np= np.array(book_ch_emotion_DF.iloc[:, :21])\n",
    "\n",
    "book_ch_emotion_np_norm= \\\n",
    "(book_ch_emotion_np- book_ch_emotion_np.mean(axis= 0))/book_ch_emotion_np.std(axis= 0)\n",
    "\n",
    "#T-test\n",
    "emotion_key_dic= {\"PA\": \"快乐\", \"PE\": \"安心\", \"PD\": \"尊敬\", \"PH\": \"赞扬\",\n",
    "                  \"PG\": \"相信\", \"PB\": \"喜爱\", \"PK\": \"祝愿\", \"NR\": \"愤怒\",\n",
    "                  \"NB\": \"悲伤\", \"NJ\": \"失望\", \"NH\": \"疚\", \"PF\": \"思\",\n",
    "                  \"NI\": \"慌\", \"NC\": \"恐惧\", \"NG\": \"羞\", \"NE\": \"烦闷\",\n",
    "                  \"ND\": \"憎恶\", \"NN\": \"贬责\", \"NK\": \"妒忌\", \"NL\": \"怀疑\",\n",
    "                  \"PC\": \"惊奇\"}\n",
    "\n",
    "emotion_mean_male_norm= []\n",
    "emotion_mean_female_norm= []\n",
    "t_statistic_list= []\n",
    "t_pvalue_list= []\n",
    "chi_label= []\n",
    "\n",
    "for i in range(len(emotion_col)):\n",
    "    chi_label+= [emotion_key_dic[emotion_col[i]]]\n",
    "    emotion_mean_male_norm+= [book_ch_emotion_np_norm[:15000, i].mean()]\n",
    "    emotion_mean_female_norm+= [book_ch_emotion_np_norm[15000:, i].mean()]\n",
    "    t_test= scipy.stats.ttest_ind(book_ch_emotion_np_norm[:15000, i], \n",
    "                                  book_ch_emotion_np_norm[15000:, i])\n",
    "    t_statistic_list+= [t_test.statistic]\n",
    "    t_pvalue_list+= [t_test.pvalue]\n",
    "\n",
    "\n",
    "    \n",
    "emotion_mean_DF[\"male_norm\"]= emotion_mean_male_norm\n",
    "emotion_mean_DF[\"female_norm\"]= emotion_mean_female_norm\n",
    "emotion_mean_DF[\"t_statistic\"]= t_statistic_list\n",
    "emotion_mean_DF[\"t_pvalue\"]= t_pvalue_list\n",
    "emotion_mean_DF[\"chi_label\"]= chi_label\n",
    "    \n",
    "emotion_mean_DF.round(3).to_csv(\"emotion.csv\")\n",
    "emotion_mean_DF.round(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the table above to test positivity bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive emotion sum\n",
      "total_emo_raw     8989.756236\n",
      "male_emo_raw      4669.454577\n",
      "female_emo_raw    4320.301658\n",
      "dtype: float64\n",
      "\n",
      "negative emotion sum\n",
      "total_emo_raw     5745.620163\n",
      "male_emo_raw      2910.994160\n",
      "female_emo_raw    2834.626003\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pos_emo= ['PA', 'PB', 'PC', 'PD', 'PE', 'PF', 'PG', 'PH', 'PK']\n",
    "neg_emo= ['NB', 'NC', 'ND', 'NE', 'NG', 'NH', 'NI', 'NJ', 'NK', 'NL', 'NN', 'NR']\n",
    "\n",
    "pos_emotion_mean_DF= emotion_mean_DF.loc[pos_emo, :]\n",
    "neg_emotion_mean_DF= emotion_mean_DF.loc[neg_emo, :]\n",
    "\n",
    "print(\"positive emotion sum\")\n",
    "print(pos_emotion_mean_DF.iloc[:, :3].sum(axis= 0))\n",
    "print()\n",
    "\n",
    "print(\"negative emotion sum\")\n",
    "print(neg_emotion_mean_DF.iloc[:, :3].sum(axis= 0))\n",
    "\n",
    "#indeed positive emotion occurs more than negative emotion in both male and female novels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emotions that he and she associated with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27351"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dalian_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "col= [\"ch\"+str(i)+\"_clean\" for i in range(1,31)]\n",
    "\n",
    "bookDF_both_forEmo= pd.concat([bookDF_male_tokenized[col], bookDF_female_tokenized[col]], axis= 0)\n",
    "bookDF_both_forEmo[\"gender\"]= [1]*500+ [0]*500\n",
    "#bookDF_both_forEmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch1_clean\n"
     ]
    }
   ],
   "source": [
    "for book in bookDF_both_forEmo:\n",
    "    print(book)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Collapse the 30 chapters\n",
    "collapsed_ch_1000= []\n",
    "for i in range(bookDF_both.shape[0]):\n",
    "    a_book= bookDF_both.iloc[i]\n",
    "    collapsed_ch= []\n",
    "    for c in col:\n",
    "        collapsed_ch+= a_book[c]\n",
    "    collapsed_ch_1000+= [collapsed_ch]  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_window_dalian(target_male, target_female):\n",
    "    #Input: target is a list of target words\n",
    "    w= 5\n",
    "    windows_1000_male= []\n",
    "    windows_1000_female= []\n",
    "    for book in collapsed_ch_1000:\n",
    "        windows_male= []\n",
    "        windows_female= []\n",
    "        for i in range(len(book)):\n",
    "            if book[i] in target_male:\n",
    "                if i< w: #This is for the first 5 (window) words\n",
    "                    window= book[0: i+w+1]\n",
    "                    windows_male+= window\n",
    "                else:\n",
    "                    window= book[i-w:i+w+1]\n",
    "                    windows_male+= window\n",
    "            elif book[i] in target_female:\n",
    "                if i< w: #This is for the first 5 (window) words\n",
    "                    window= book[0: i+w+1]\n",
    "                    windows_female+= window\n",
    "                else:\n",
    "                    window= book[i-w:i+w+1]\n",
    "                    windows_female+= window\n",
    "                \n",
    "                \n",
    "        windows_1000_male+= [windows_male]\n",
    "        windows_1000_female+= [windows_female]\n",
    "    \n",
    "    \n",
    "    around_heshe_DF= pd.DataFrame({\"he_words\": windows_1000_male, \n",
    "                                   \"she_words\": windows_1000_female})\n",
    "    around_heshe_DF[\"gender\"]= [1]*500+ [0]*500\n",
    "    \n",
    "    return around_heshe_DF\n",
    "\n",
    "around_heshe_DF= get_target_window_dalian([\"他\"], [\"她\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_heshe_emotion_ch(input_DF, column_name):\n",
    "    output_ch_DF= pd.DataFrame({})\n",
    "    for ind in range(input_DF.shape[0]): \n",
    "        heshe_emo_dic= {\"PA\": [0], \"PE\": [0], \"PD\": [0], \"PH\": [0], \n",
    "                        \"PG\": [0], \"PB\": [0], \"PK\": [0], \"NR\": [0], \n",
    "                        \"NB\": [0], \"NJ\": [0], \"NH\": [0], \"PF\": [0], \n",
    "                        \"NI\": [0], \"NC\": [0], \"NG\": [0], \"NE\": [0], \n",
    "                        \"ND\": [0], \"NN\": [0], \"NK\": [0], \"NL\": [0], \n",
    "                        \"PC\": [0]}\n",
    "        \n",
    "        gender_words= input_DF[column_name].iloc[ind]\n",
    "        #print(len(gender_words))\n",
    "        for w in gender_words: \n",
    "            if w in dalian_dic:\n",
    "                #print(w)\n",
    "                tag= dalian_dic[w][2]\n",
    "                intense= dalian_dic[w][1]\n",
    "                \n",
    "                \"\"\"I normalize the emotion score by the length of selected words (sum of windows)\"\"\"\n",
    "                heshe_emo_dic[tag][0]+= intense/len(gender_words)\n",
    "        \n",
    "        ch_DF= pd.DataFrame(heshe_emo_dic)\n",
    "        \n",
    "        output_ch_DF= output_ch_DF.append(ch_DF)\n",
    "\n",
    "    return output_ch_DF\n",
    "\n",
    "male_he_emo_ch= count_heshe_emotion_ch(around_heshe_DF.iloc[:500, :], \"he_words\")\n",
    "male_she_emo_ch= count_heshe_emotion_ch(around_heshe_DF.iloc[:500, :], \"she_words\")\n",
    "\n",
    "\n",
    "female_he_emo_ch= count_heshe_emotion_ch(around_heshe_DF.iloc[500:, :], \"he_words\")\n",
    "female_she_emo_ch= count_heshe_emotion_ch(around_heshe_DF.iloc[500:, :], \"she_words\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive emotion:\n",
      "male_he_words       145.121097\n",
      "male_she_words      152.725948\n",
      "female_he_words     140.755896\n",
      "female_she_words    135.069811\n",
      "dtype: float64\n",
      "\n",
      "negative emotion:\n",
      "male_he_words       101.454096\n",
      "male_she_words      100.149305\n",
      "female_he_words     102.183678\n",
      "female_she_words    101.404935\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pos_emo= ['PA', 'PB', 'PC', 'PD', 'PE', 'PF', 'PG', 'PH', 'PK']\n",
    "neg_emo= ['NB', 'NC', 'ND', 'NE', 'NG', 'NH', 'NI', 'NJ', 'NK', 'NL', 'NN', 'NR']\n",
    "\n",
    "print(\"positive emotion:\")\n",
    "heshe_pos_emotion_DF= heshe_emotion_DF.loc[pos_emo, :]\n",
    "print(heshe_pos_emotion_DF.sum(axis= 0))\n",
    "print()\n",
    "\n",
    "print(\"negative emotion:\")\n",
    "heshe_neg_emotion_DF= heshe_emotion_DF.loc[neg_emo, :]\n",
    "print(heshe_neg_emotion_DF.sum(axis= 0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "#At book level. For the positive and negative emotions, T-test between four pairs: \n",
    "\n",
    "##1. \"male_he\" and \"female_he\"\n",
    "##2. \"male_she\" and \"female_she\"\n",
    "\n",
    "##3. \"male_he\" and \"male_she\"\n",
    "##4. \"female_he\" and \"female_she\"\n",
    "\n",
    "pos_emo= ['PA', 'PB', 'PC', 'PD', 'PE', 'PF', 'PG', 'PH', 'PK']\n",
    "male_he_pos= male_he_emo_ch.loc[:, pos_emo].sum(axis= 0)\n",
    "male_she_pos= male_she_emo_ch.loc[:, pos_emo].sum(axis= 0)\n",
    "female_he_pos= female_he_emo_ch.loc[:, pos_emo].sum(axis= 0)\n",
    "female_she_pos= female_she_emo_ch.loc[:, pos_emo].sum(axis= 0)\n",
    "\n",
    "t_Mhe_Fhe_pos= scipy.stats.ttest_ind(male_he_pos, female_he_pos)\n",
    "t_Mshe_Fshe_pos= scipy.stats.ttest_ind(male_she_pos, female_she_pos)\n",
    "t_Mhe_Mshe_pos= scipy.stats.ttest_ind(male_he_pos, male_she_pos)\n",
    "t_Fhe_Fshe_pos= scipy.stats.ttest_ind(female_he_pos, female_she_pos)\n",
    "\n",
    "t_pos_dic= {\"male_he_sum\": male_he_pos.sum(),\n",
    "            \"male_she_sum\": male_she_pos.sum(),\n",
    "            \"female_he_sum\": female_he_pos.sum(),\n",
    "            \"female_she_sum\": female_she_pos.sum(),\n",
    "                    \n",
    "            \"Mhe_vs_Fhe_ST\": [t_Mhe_Fhe_pos.statistic],\n",
    "            \"Mshe_vs_Fshe_ST\": [t_Mshe_Fshe_pos.statistic],\n",
    "            \"Mhe_vs_Mshe_ST\": [t_Mhe_Mshe_pos.statistic],\n",
    "            \"Fhe_vs_Fshe_ST\": [t_Fhe_Fshe_pos.statistic],\n",
    "            \n",
    "            \"Mhe_vs_Fhe_P\": [t_Mhe_Fhe_pos.pvalue],\n",
    "            \"Mshe_vs_Fshe_P\": [t_Mshe_Fshe_pos.pvalue],\n",
    "            \"Mhe_vs_Mshe_P\": [t_Mhe_Mshe_pos.pvalue],\n",
    "            \"Fhe_vs_Fshe_P\": [t_Fhe_Fshe_pos.pvalue]}\n",
    "\n",
    "heshe_pos_comparison_DF= pd.DataFrame(t_pos_dic, index= [\"positive\"]).round(3)\n",
    "\n",
    "\n",
    "neg_emo= ['NB', 'NC', 'ND', 'NE', 'NG', 'NH', 'NI', 'NJ', 'NK', 'NL', 'NN', 'NR']\n",
    "male_he_neg= male_he_emo_ch.loc[:, neg_emo].sum(axis= 0)\n",
    "male_she_neg= male_she_emo_ch.loc[:, neg_emo].sum(axis= 0)\n",
    "female_he_neg= female_he_emo_ch.loc[:, neg_emo].sum(axis= 0)\n",
    "female_she_neg= female_she_emo_ch.loc[:, neg_emo].sum(axis= 0)\n",
    "\n",
    "\n",
    "\n",
    "t_Mhe_Fhe_neg= scipy.stats.ttest_ind(male_he_neg, female_he_neg)\n",
    "t_Mshe_Fshe_neg= scipy.stats.ttest_ind(male_she_neg, female_she_neg)\n",
    "t_Mhe_Mshe_neg= scipy.stats.ttest_ind(male_he_neg, male_she_neg)\n",
    "t_Fhe_Fshe_neg= scipy.stats.ttest_ind(female_he_neg, female_she_neg)\n",
    "\n",
    "t_neg_dic= {\"male_he_sum\": male_he_neg.sum(),\n",
    "            \"male_she_sum\": male_she_neg.sum(),\n",
    "            \"female_he_sum\": female_he_neg.sum(),\n",
    "            \"female_she_sum\": female_she_neg.sum(),\n",
    "                    \n",
    "            \"Mhe_vs_Fhe_ST\": [t_Mhe_Fhe_neg.statistic],\n",
    "            \"Mshe_vs_Fshe_ST\": [t_Mshe_Fshe_neg.statistic],\n",
    "            \"Mhe_vs_Mshe_ST\": [t_Mhe_Mshe_neg.statistic],\n",
    "            \"Fhe_vs_Fshe_ST\": [t_Fhe_Fshe_neg.statistic],\n",
    "            \n",
    "            \"Mhe_vs_Fhe_P\": [t_Mhe_Fhe_neg.pvalue],\n",
    "            \"Mshe_vs_Fshe_P\": [t_Mshe_Fshe_neg.pvalue],\n",
    "            \"Mhe_vs_Mshe_P\": [t_Mhe_Mshe_neg.pvalue],\n",
    "            \"Fhe_vs_Fshe_P\": [t_Fhe_Fshe_neg.pvalue]}\n",
    "\n",
    "heshe_neg_comparison_DF= pd.DataFrame(t_neg_dic, index= [\"negative\"]).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fhe_vs_Fshe_P</th>\n",
       "      <th>Fhe_vs_Fshe_ST</th>\n",
       "      <th>Mhe_vs_Fhe_P</th>\n",
       "      <th>Mhe_vs_Fhe_ST</th>\n",
       "      <th>Mhe_vs_Mshe_P</th>\n",
       "      <th>Mhe_vs_Mshe_ST</th>\n",
       "      <th>Mshe_vs_Fshe_P</th>\n",
       "      <th>Mshe_vs_Fshe_ST</th>\n",
       "      <th>female_he_sum</th>\n",
       "      <th>female_she_sum</th>\n",
       "      <th>male_he_sum</th>\n",
       "      <th>male_she_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.931</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.924</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.241</td>\n",
       "      <td>140.756</td>\n",
       "      <td>135.070</td>\n",
       "      <td>145.121</td>\n",
       "      <td>152.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.989</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.980</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>102.184</td>\n",
       "      <td>101.405</td>\n",
       "      <td>101.454</td>\n",
       "      <td>100.149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Fhe_vs_Fshe_P  Fhe_vs_Fshe_ST  Mhe_vs_Fhe_P  Mhe_vs_Fhe_ST  \\\n",
       "positive          0.931           0.089         0.951          0.062   \n",
       "negative          0.988           0.015         0.989         -0.014   \n",
       "\n",
       "          Mhe_vs_Mshe_P  Mhe_vs_Mshe_ST  Mshe_vs_Fshe_P  Mshe_vs_Fshe_ST  \\\n",
       "positive          0.924          -0.097           0.813            0.241   \n",
       "negative          0.979           0.027           0.980           -0.026   \n",
       "\n",
       "          female_he_sum  female_she_sum  male_he_sum  male_she_sum  \n",
       "positive        140.756         135.070      145.121       152.726  \n",
       "negative        102.184         101.405      101.454       100.149  "
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Not at all significant difference between \n",
    "#how \"he\" and \"she\" is portrayed in male and female novels\n",
    "\n",
    "pd.concat([heshe_pos_comparison_DF, heshe_neg_comparison_DF],\n",
    "          axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "#At book level. For the 21 emotions separately, T-test between four pairs: \n",
    "##1. \"male_he\" and \"female_he\"\n",
    "##2. \"male_she\" and \"female_she\"\n",
    "\n",
    "##3. \"male_he\" and \"male_she\"\n",
    "##4. \"female_he\" and \"female_she\"\n",
    "#Each comparison pair gives me a 21*1 column, the four comparisons give me a 21*4 table\n",
    "\n",
    "emo_col= list(male_he_emo_ch.columns)\n",
    "heshe_emo_ttest_DF= pd.DataFrame({})\n",
    "\n",
    "for e in emo_col:\n",
    "    male_he_emo_500= male_he_emo_ch[e]\n",
    "    male_she_emo_500= male_she_emo_ch[e]\n",
    "    female_he_emo_500= female_he_emo_ch[e]\n",
    "    female_she_emo_500= female_she_emo_ch[e]\n",
    "    \n",
    "    t_Mhe_Fhe= scipy.stats.ttest_ind(male_he_emo_500, female_he_emo_500)\n",
    "    t_Mshe_Fshe= scipy.stats.ttest_ind(male_she_emo_500, female_she_emo_500)\n",
    "    t_Mhe_Mshe= scipy.stats.ttest_ind(male_he_emo_500, male_she_emo_500)\n",
    "    t_Fhe_Fshe= scipy.stats.ttest_ind(female_he_emo_500, female_she_emo_500)\n",
    "    \n",
    "    t_dic= {\"Mhe_vs_Fhe_ST\": [t_Mhe_Fhe.statistic],\n",
    "            \"Mhe_vs_Fhe_P\": [t_Mhe_Fhe.pvalue],\n",
    "            \n",
    "            \"Mshe_vs_Fshe_ST\": [t_Mshe_Fshe.statistic],\n",
    "            \"Mshe_vs_Fshe_P\": [t_Mshe_Fshe.pvalue],\n",
    "            \n",
    "            \"Mhe_vs_Mshe_ST\": [t_Mhe_Mshe.statistic], \n",
    "            \"Mhe_vs_Mshe_P\": [t_Mhe_Mshe.pvalue], \n",
    "            \n",
    "            \"Fhe_vs_Fshe_ST\": [t_Fhe_Fshe.statistic],\n",
    "            \"Fhe_vs_Fshe_P\": [t_Fhe_Fshe.pvalue]}\n",
    "    \n",
    "    one_emo_comparison_DF= pd.DataFrame(t_dic, index= [e])\n",
    "    heshe_emo_ttest_DF= heshe_emo_ttest_DF.append(one_emo_comparison_DF)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fhe_vs_Fshe_P</th>\n",
       "      <th>Fhe_vs_Fshe_ST</th>\n",
       "      <th>Mhe_vs_Fhe_P</th>\n",
       "      <th>Mhe_vs_Fhe_ST</th>\n",
       "      <th>Mhe_vs_Mshe_P</th>\n",
       "      <th>Mhe_vs_Mshe_ST</th>\n",
       "      <th>Mshe_vs_Fshe_P</th>\n",
       "      <th>Mshe_vs_Fshe_ST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>7.982558e-04</td>\n",
       "      <td>-3.363714</td>\n",
       "      <td>1.016788e-02</td>\n",
       "      <td>-2.574972</td>\n",
       "      <td>1.754621e-04</td>\n",
       "      <td>-3.766172</td>\n",
       "      <td>1.646520e-01</td>\n",
       "      <td>1.390616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NC</th>\n",
       "      <td>9.928260e-04</td>\n",
       "      <td>-3.302344</td>\n",
       "      <td>2.432736e-27</td>\n",
       "      <td>11.161046</td>\n",
       "      <td>5.102838e-01</td>\n",
       "      <td>-0.658632</td>\n",
       "      <td>7.715648e-04</td>\n",
       "      <td>3.373197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ND</th>\n",
       "      <td>1.848663e-01</td>\n",
       "      <td>1.326836</td>\n",
       "      <td>5.356629e-02</td>\n",
       "      <td>1.932615</td>\n",
       "      <td>3.144082e-03</td>\n",
       "      <td>2.960497</td>\n",
       "      <td>3.595259e-01</td>\n",
       "      <td>-0.916691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NE</th>\n",
       "      <td>8.564674e-01</td>\n",
       "      <td>-0.180920</td>\n",
       "      <td>2.685475e-13</td>\n",
       "      <td>-7.410114</td>\n",
       "      <td>3.694493e-02</td>\n",
       "      <td>-2.089173</td>\n",
       "      <td>5.399335e-02</td>\n",
       "      <td>-1.929167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NG</th>\n",
       "      <td>6.056868e-01</td>\n",
       "      <td>-0.516404</td>\n",
       "      <td>1.133121e-04</td>\n",
       "      <td>-3.875592</td>\n",
       "      <td>4.502157e-03</td>\n",
       "      <td>-2.847118</td>\n",
       "      <td>4.717752e-01</td>\n",
       "      <td>0.719867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NH</th>\n",
       "      <td>1.837555e-01</td>\n",
       "      <td>1.330202</td>\n",
       "      <td>3.455081e-15</td>\n",
       "      <td>-7.999173</td>\n",
       "      <td>2.690524e-02</td>\n",
       "      <td>-2.216163</td>\n",
       "      <td>2.138504e-02</td>\n",
       "      <td>-2.304751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NI</th>\n",
       "      <td>1.593186e-03</td>\n",
       "      <td>-3.165847</td>\n",
       "      <td>2.412894e-01</td>\n",
       "      <td>1.172467</td>\n",
       "      <td>1.403335e-01</td>\n",
       "      <td>-1.475724</td>\n",
       "      <td>4.829834e-01</td>\n",
       "      <td>0.701775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJ</th>\n",
       "      <td>4.697573e-01</td>\n",
       "      <td>-0.723150</td>\n",
       "      <td>2.880382e-01</td>\n",
       "      <td>1.063002</td>\n",
       "      <td>4.692222e-01</td>\n",
       "      <td>-0.724022</td>\n",
       "      <td>3.923837e-01</td>\n",
       "      <td>0.855674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NK</th>\n",
       "      <td>7.291349e-05</td>\n",
       "      <td>-3.983262</td>\n",
       "      <td>7.501757e-01</td>\n",
       "      <td>0.318496</td>\n",
       "      <td>8.188910e-01</td>\n",
       "      <td>-0.229032</td>\n",
       "      <td>8.691194e-03</td>\n",
       "      <td>-2.629161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NL</th>\n",
       "      <td>9.964483e-01</td>\n",
       "      <td>0.004453</td>\n",
       "      <td>5.518063e-01</td>\n",
       "      <td>0.595257</td>\n",
       "      <td>5.339821e-02</td>\n",
       "      <td>1.933979</td>\n",
       "      <td>1.106565e-01</td>\n",
       "      <td>-1.596667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>3.828418e-02</td>\n",
       "      <td>2.074549</td>\n",
       "      <td>4.411092e-01</td>\n",
       "      <td>-0.770629</td>\n",
       "      <td>1.418007e-03</td>\n",
       "      <td>3.199922</td>\n",
       "      <td>1.517676e-02</td>\n",
       "      <td>-2.432335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>1.112049e-06</td>\n",
       "      <td>4.901027</td>\n",
       "      <td>3.070293e-01</td>\n",
       "      <td>1.021998</td>\n",
       "      <td>4.531330e-02</td>\n",
       "      <td>2.004248</td>\n",
       "      <td>1.344123e-01</td>\n",
       "      <td>1.498143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA</th>\n",
       "      <td>8.958489e-02</td>\n",
       "      <td>-1.699244</td>\n",
       "      <td>7.590165e-01</td>\n",
       "      <td>0.306857</td>\n",
       "      <td>5.780527e-01</td>\n",
       "      <td>0.556414</td>\n",
       "      <td>1.478594e-01</td>\n",
       "      <td>-1.448257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PB</th>\n",
       "      <td>1.454975e-01</td>\n",
       "      <td>1.456759</td>\n",
       "      <td>4.412109e-12</td>\n",
       "      <td>-7.009067</td>\n",
       "      <td>3.295278e-07</td>\n",
       "      <td>-5.140550</td>\n",
       "      <td>5.503338e-02</td>\n",
       "      <td>1.920865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC</th>\n",
       "      <td>5.346745e-01</td>\n",
       "      <td>-0.621102</td>\n",
       "      <td>9.903162e-15</td>\n",
       "      <td>7.860154</td>\n",
       "      <td>7.732665e-01</td>\n",
       "      <td>-0.288183</td>\n",
       "      <td>5.812290e-05</td>\n",
       "      <td>4.037655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PD</th>\n",
       "      <td>1.436160e-09</td>\n",
       "      <td>6.108864</td>\n",
       "      <td>7.420706e-01</td>\n",
       "      <td>-0.329204</td>\n",
       "      <td>1.146724e-02</td>\n",
       "      <td>2.532817</td>\n",
       "      <td>4.904690e-01</td>\n",
       "      <td>0.689818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PE</th>\n",
       "      <td>4.871385e-01</td>\n",
       "      <td>0.695125</td>\n",
       "      <td>1.509732e-02</td>\n",
       "      <td>-2.434246</td>\n",
       "      <td>8.997011e-01</td>\n",
       "      <td>-0.126071</td>\n",
       "      <td>1.529492e-01</td>\n",
       "      <td>-1.430282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PF</th>\n",
       "      <td>6.394350e-02</td>\n",
       "      <td>-1.854633</td>\n",
       "      <td>2.795122e-06</td>\n",
       "      <td>-4.712402</td>\n",
       "      <td>3.647368e-01</td>\n",
       "      <td>-0.906790</td>\n",
       "      <td>1.878878e-04</td>\n",
       "      <td>-3.748801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PG</th>\n",
       "      <td>4.074910e-01</td>\n",
       "      <td>0.828667</td>\n",
       "      <td>7.393166e-02</td>\n",
       "      <td>1.788915</td>\n",
       "      <td>9.226097e-03</td>\n",
       "      <td>2.608643</td>\n",
       "      <td>3.969992e-01</td>\n",
       "      <td>-0.847357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PH</th>\n",
       "      <td>2.129740e-03</td>\n",
       "      <td>3.079565</td>\n",
       "      <td>1.254375e-07</td>\n",
       "      <td>5.323941</td>\n",
       "      <td>6.773740e-04</td>\n",
       "      <td>-3.409292</td>\n",
       "      <td>9.111972e-17</td>\n",
       "      <td>8.464157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PK</th>\n",
       "      <td>2.519494e-01</td>\n",
       "      <td>-1.146291</td>\n",
       "      <td>1.322889e-08</td>\n",
       "      <td>5.730827</td>\n",
       "      <td>9.289374e-02</td>\n",
       "      <td>1.681938</td>\n",
       "      <td>2.015877e-01</td>\n",
       "      <td>1.277883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Fhe_vs_Fshe_P  Fhe_vs_Fshe_ST  Mhe_vs_Fhe_P  Mhe_vs_Fhe_ST  Mhe_vs_Mshe_P  \\\n",
       "NB   7.982558e-04       -3.363714  1.016788e-02      -2.574972   1.754621e-04   \n",
       "NC   9.928260e-04       -3.302344  2.432736e-27      11.161046   5.102838e-01   \n",
       "ND   1.848663e-01        1.326836  5.356629e-02       1.932615   3.144082e-03   \n",
       "NE   8.564674e-01       -0.180920  2.685475e-13      -7.410114   3.694493e-02   \n",
       "NG   6.056868e-01       -0.516404  1.133121e-04      -3.875592   4.502157e-03   \n",
       "NH   1.837555e-01        1.330202  3.455081e-15      -7.999173   2.690524e-02   \n",
       "NI   1.593186e-03       -3.165847  2.412894e-01       1.172467   1.403335e-01   \n",
       "NJ   4.697573e-01       -0.723150  2.880382e-01       1.063002   4.692222e-01   \n",
       "NK   7.291349e-05       -3.983262  7.501757e-01       0.318496   8.188910e-01   \n",
       "NL   9.964483e-01        0.004453  5.518063e-01       0.595257   5.339821e-02   \n",
       "NN   3.828418e-02        2.074549  4.411092e-01      -0.770629   1.418007e-03   \n",
       "NR   1.112049e-06        4.901027  3.070293e-01       1.021998   4.531330e-02   \n",
       "PA   8.958489e-02       -1.699244  7.590165e-01       0.306857   5.780527e-01   \n",
       "PB   1.454975e-01        1.456759  4.412109e-12      -7.009067   3.295278e-07   \n",
       "PC   5.346745e-01       -0.621102  9.903162e-15       7.860154   7.732665e-01   \n",
       "PD   1.436160e-09        6.108864  7.420706e-01      -0.329204   1.146724e-02   \n",
       "PE   4.871385e-01        0.695125  1.509732e-02      -2.434246   8.997011e-01   \n",
       "PF   6.394350e-02       -1.854633  2.795122e-06      -4.712402   3.647368e-01   \n",
       "PG   4.074910e-01        0.828667  7.393166e-02       1.788915   9.226097e-03   \n",
       "PH   2.129740e-03        3.079565  1.254375e-07       5.323941   6.773740e-04   \n",
       "PK   2.519494e-01       -1.146291  1.322889e-08       5.730827   9.289374e-02   \n",
       "\n",
       "    Mhe_vs_Mshe_ST  Mshe_vs_Fshe_P  Mshe_vs_Fshe_ST  \n",
       "NB       -3.766172    1.646520e-01         1.390616  \n",
       "NC       -0.658632    7.715648e-04         3.373197  \n",
       "ND        2.960497    3.595259e-01        -0.916691  \n",
       "NE       -2.089173    5.399335e-02        -1.929167  \n",
       "NG       -2.847118    4.717752e-01         0.719867  \n",
       "NH       -2.216163    2.138504e-02        -2.304751  \n",
       "NI       -1.475724    4.829834e-01         0.701775  \n",
       "NJ       -0.724022    3.923837e-01         0.855674  \n",
       "NK       -0.229032    8.691194e-03        -2.629161  \n",
       "NL        1.933979    1.106565e-01        -1.596667  \n",
       "NN        3.199922    1.517676e-02        -2.432335  \n",
       "NR        2.004248    1.344123e-01         1.498143  \n",
       "PA        0.556414    1.478594e-01        -1.448257  \n",
       "PB       -5.140550    5.503338e-02         1.920865  \n",
       "PC       -0.288183    5.812290e-05         4.037655  \n",
       "PD        2.532817    4.904690e-01         0.689818  \n",
       "PE       -0.126071    1.529492e-01        -1.430282  \n",
       "PF       -0.906790    1.878878e-04        -3.748801  \n",
       "PG        2.608643    3.969992e-01        -0.847357  \n",
       "PH       -3.409292    9.111972e-17         8.464157  \n",
       "PK        1.681938    2.015877e-01         1.277883  "
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heshe_emo_ttest_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male_he_words</th>\n",
       "      <th>male_she_words</th>\n",
       "      <th>female_he_words</th>\n",
       "      <th>female_she_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>10.915381</td>\n",
       "      <td>14.129660</td>\n",
       "      <td>11.796576</td>\n",
       "      <td>12.943516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NC</th>\n",
       "      <td>7.566865</td>\n",
       "      <td>8.068953</td>\n",
       "      <td>4.791461</td>\n",
       "      <td>5.525230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ND</th>\n",
       "      <td>14.883492</td>\n",
       "      <td>12.697619</td>\n",
       "      <td>13.950116</td>\n",
       "      <td>13.354470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NE</th>\n",
       "      <td>10.013201</td>\n",
       "      <td>11.206589</td>\n",
       "      <td>12.262971</td>\n",
       "      <td>12.319867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NG</th>\n",
       "      <td>0.852685</td>\n",
       "      <td>1.323655</td>\n",
       "      <td>1.156636</td>\n",
       "      <td>1.201542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NH</th>\n",
       "      <td>1.867643</td>\n",
       "      <td>2.283073</td>\n",
       "      <td>2.920115</td>\n",
       "      <td>2.731702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NI</th>\n",
       "      <td>3.261554</td>\n",
       "      <td>3.834889</td>\n",
       "      <td>3.074894</td>\n",
       "      <td>3.563613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJ</th>\n",
       "      <td>3.415116</td>\n",
       "      <td>3.664557</td>\n",
       "      <td>3.238536</td>\n",
       "      <td>3.365671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NK</th>\n",
       "      <td>0.255158</td>\n",
       "      <td>0.268484</td>\n",
       "      <td>0.242239</td>\n",
       "      <td>0.437928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NL</th>\n",
       "      <td>4.218122</td>\n",
       "      <td>3.616704</td>\n",
       "      <td>4.106857</td>\n",
       "      <td>4.106059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>38.923963</td>\n",
       "      <td>34.504520</td>\n",
       "      <td>39.598355</td>\n",
       "      <td>37.829485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>5.280915</td>\n",
       "      <td>4.550602</td>\n",
       "      <td>5.044920</td>\n",
       "      <td>4.025852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA</th>\n",
       "      <td>24.748595</td>\n",
       "      <td>24.179319</td>\n",
       "      <td>24.551255</td>\n",
       "      <td>25.681116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PB</th>\n",
       "      <td>14.026045</td>\n",
       "      <td>19.504922</td>\n",
       "      <td>18.356944</td>\n",
       "      <td>17.460287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC</th>\n",
       "      <td>7.956272</td>\n",
       "      <td>8.100014</td>\n",
       "      <td>6.011934</td>\n",
       "      <td>6.146017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PD</th>\n",
       "      <td>10.733510</td>\n",
       "      <td>8.817971</td>\n",
       "      <td>10.890044</td>\n",
       "      <td>8.319105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PE</th>\n",
       "      <td>6.172743</td>\n",
       "      <td>6.224251</td>\n",
       "      <td>7.161252</td>\n",
       "      <td>6.855875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PF</th>\n",
       "      <td>1.449873</td>\n",
       "      <td>1.613737</td>\n",
       "      <td>2.127515</td>\n",
       "      <td>2.536339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PG</th>\n",
       "      <td>13.612498</td>\n",
       "      <td>11.966524</td>\n",
       "      <td>12.836941</td>\n",
       "      <td>12.491544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PH</th>\n",
       "      <td>58.992738</td>\n",
       "      <td>65.561613</td>\n",
       "      <td>52.839601</td>\n",
       "      <td>49.322670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PK</th>\n",
       "      <td>7.428822</td>\n",
       "      <td>6.757596</td>\n",
       "      <td>5.980409</td>\n",
       "      <td>6.256856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    male_he_words  male_she_words  female_he_words  female_she_words\n",
       "NB      10.915381       14.129660        11.796576         12.943516\n",
       "NC       7.566865        8.068953         4.791461          5.525230\n",
       "ND      14.883492       12.697619        13.950116         13.354470\n",
       "NE      10.013201       11.206589        12.262971         12.319867\n",
       "NG       0.852685        1.323655         1.156636          1.201542\n",
       "NH       1.867643        2.283073         2.920115          2.731702\n",
       "NI       3.261554        3.834889         3.074894          3.563613\n",
       "NJ       3.415116        3.664557         3.238536          3.365671\n",
       "NK       0.255158        0.268484         0.242239          0.437928\n",
       "NL       4.218122        3.616704         4.106857          4.106059\n",
       "NN      38.923963       34.504520        39.598355         37.829485\n",
       "NR       5.280915        4.550602         5.044920          4.025852\n",
       "PA      24.748595       24.179319        24.551255         25.681116\n",
       "PB      14.026045       19.504922        18.356944         17.460287\n",
       "PC       7.956272        8.100014         6.011934          6.146017\n",
       "PD      10.733510        8.817971        10.890044          8.319105\n",
       "PE       6.172743        6.224251         7.161252          6.855875\n",
       "PF       1.449873        1.613737         2.127515          2.536339\n",
       "PG      13.612498       11.966524        12.836941         12.491544\n",
       "PH      58.992738       65.561613        52.839601         49.322670\n",
       "PK       7.428822        6.757596         5.980409          6.256856"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sum_heshe_emotion(input_DF, column_name, which_novel):\n",
    "    output_DF= pd.DataFrame({})\n",
    "    heshe_emo_dic= {\"PA\": [0], \"PE\": [0], \"PD\": [0], \"PH\": [0], \n",
    "                    \"PG\": [0], \"PB\": [0], \"PK\": [0], \"NR\": [0], \n",
    "                    \"NB\": [0], \"NJ\": [0], \"NH\": [0], \"PF\": [0], \n",
    "                    \"NI\": [0], \"NC\": [0], \"NG\": [0], \"NE\": [0], \n",
    "                    \"ND\": [0], \"NN\": [0], \"NK\": [0], \"NL\": [0], \n",
    "                    \"PC\": [0]}\n",
    "    for ind in range(input_DF.shape[0]): #\n",
    "        gender_words= input_DF[column_name].iloc[ind]\n",
    "        #print(len(gender_words))\n",
    "        for w in gender_words: \n",
    "            if w in dalian_dic:\n",
    "                #print(w)\n",
    "                tag= dalian_dic[w][2]\n",
    "                intense= dalian_dic[w][1]\n",
    "                \n",
    "                \"\"\"I normalize the emotion score by the length of selected words (sum of windows)\"\"\"\n",
    "                heshe_emo_dic[tag][0]+= intense/len(gender_words)\n",
    "                \n",
    "    output_DF= pd.DataFrame(heshe_emo_dic, index= [str(which_novel)+\"_\"+str(column_name)])\n",
    "\n",
    "    return output_DF\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "male_he_emotion_DF= sum_heshe_emotion(around_heshe_DF.iloc[:500, :], \"he_words\", \"male\")\n",
    "male_she_emotion_DF= sum_heshe_emotion(around_heshe_DF.iloc[:500, :], \"she_words\", \"male\")\n",
    "\n",
    "female_he_emotion_DF= sum_heshe_emotion(around_heshe_DF.iloc[500:, :], \"he_words\", \"female\")\n",
    "female_she_emotion_DF= sum_heshe_emotion(around_heshe_DF.iloc[500:, :], \"she_words\", \"female\")\n",
    "\n",
    "heshe_emotion_DF= pd.concat([male_he_emotion_DF, \n",
    "                             male_she_emotion_DF, \n",
    "                             female_he_emotion_DF, \n",
    "                             female_she_emotion_DF], axis= 0).transpose()\n",
    "heshe_emotion_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male_he_words</th>\n",
       "      <th>male_she_words</th>\n",
       "      <th>female_he_words</th>\n",
       "      <th>female_she_words</th>\n",
       "      <th>Fhe_vs_Fshe_P</th>\n",
       "      <th>Fhe_vs_Fshe_ST</th>\n",
       "      <th>Mhe_vs_Fhe_P</th>\n",
       "      <th>Mhe_vs_Fhe_ST</th>\n",
       "      <th>Mhe_vs_Mshe_P</th>\n",
       "      <th>Mhe_vs_Mshe_ST</th>\n",
       "      <th>Mshe_vs_Fshe_P</th>\n",
       "      <th>Mshe_vs_Fshe_ST</th>\n",
       "      <th>chi_emo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>10.915</td>\n",
       "      <td>14.130</td>\n",
       "      <td>11.797</td>\n",
       "      <td>12.944</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-3.364</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-2.575</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-3.766</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.391</td>\n",
       "      <td>悲伤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NC</th>\n",
       "      <td>7.567</td>\n",
       "      <td>8.069</td>\n",
       "      <td>4.791</td>\n",
       "      <td>5.525</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-3.302</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.161</td>\n",
       "      <td>0.510</td>\n",
       "      <td>-0.659</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3.373</td>\n",
       "      <td>恐惧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ND</th>\n",
       "      <td>14.883</td>\n",
       "      <td>12.698</td>\n",
       "      <td>13.950</td>\n",
       "      <td>13.354</td>\n",
       "      <td>0.185</td>\n",
       "      <td>1.327</td>\n",
       "      <td>0.054</td>\n",
       "      <td>1.933</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2.960</td>\n",
       "      <td>0.360</td>\n",
       "      <td>-0.917</td>\n",
       "      <td>憎恶</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NE</th>\n",
       "      <td>10.013</td>\n",
       "      <td>11.207</td>\n",
       "      <td>12.263</td>\n",
       "      <td>12.320</td>\n",
       "      <td>0.856</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-7.410</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-2.089</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-1.929</td>\n",
       "      <td>烦闷</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NG</th>\n",
       "      <td>0.853</td>\n",
       "      <td>1.324</td>\n",
       "      <td>1.157</td>\n",
       "      <td>1.202</td>\n",
       "      <td>0.606</td>\n",
       "      <td>-0.516</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-3.876</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-2.847</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.720</td>\n",
       "      <td>羞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NH</th>\n",
       "      <td>1.868</td>\n",
       "      <td>2.283</td>\n",
       "      <td>2.920</td>\n",
       "      <td>2.732</td>\n",
       "      <td>0.184</td>\n",
       "      <td>1.330</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-7.999</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-2.216</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-2.305</td>\n",
       "      <td>疚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NI</th>\n",
       "      <td>3.262</td>\n",
       "      <td>3.835</td>\n",
       "      <td>3.075</td>\n",
       "      <td>3.564</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-3.166</td>\n",
       "      <td>0.241</td>\n",
       "      <td>1.172</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-1.476</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.702</td>\n",
       "      <td>慌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJ</th>\n",
       "      <td>3.415</td>\n",
       "      <td>3.665</td>\n",
       "      <td>3.239</td>\n",
       "      <td>3.366</td>\n",
       "      <td>0.470</td>\n",
       "      <td>-0.723</td>\n",
       "      <td>0.288</td>\n",
       "      <td>1.063</td>\n",
       "      <td>0.469</td>\n",
       "      <td>-0.724</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.856</td>\n",
       "      <td>失望</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NK</th>\n",
       "      <td>0.255</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-3.983</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.819</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-2.629</td>\n",
       "      <td>妒忌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NL</th>\n",
       "      <td>4.218</td>\n",
       "      <td>3.617</td>\n",
       "      <td>4.107</td>\n",
       "      <td>4.106</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.053</td>\n",
       "      <td>1.934</td>\n",
       "      <td>0.111</td>\n",
       "      <td>-1.597</td>\n",
       "      <td>怀疑</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>38.924</td>\n",
       "      <td>34.505</td>\n",
       "      <td>39.598</td>\n",
       "      <td>37.829</td>\n",
       "      <td>0.038</td>\n",
       "      <td>2.075</td>\n",
       "      <td>0.441</td>\n",
       "      <td>-0.771</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3.200</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-2.432</td>\n",
       "      <td>贬责</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>5.281</td>\n",
       "      <td>4.551</td>\n",
       "      <td>5.045</td>\n",
       "      <td>4.026</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.901</td>\n",
       "      <td>0.307</td>\n",
       "      <td>1.022</td>\n",
       "      <td>0.045</td>\n",
       "      <td>2.004</td>\n",
       "      <td>0.134</td>\n",
       "      <td>1.498</td>\n",
       "      <td>愤怒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA</th>\n",
       "      <td>24.749</td>\n",
       "      <td>24.179</td>\n",
       "      <td>24.551</td>\n",
       "      <td>25.681</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-1.699</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-1.448</td>\n",
       "      <td>快乐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PB</th>\n",
       "      <td>14.026</td>\n",
       "      <td>19.505</td>\n",
       "      <td>18.357</td>\n",
       "      <td>17.460</td>\n",
       "      <td>0.145</td>\n",
       "      <td>1.457</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-7.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-5.141</td>\n",
       "      <td>0.055</td>\n",
       "      <td>1.921</td>\n",
       "      <td>喜爱</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC</th>\n",
       "      <td>7.956</td>\n",
       "      <td>8.100</td>\n",
       "      <td>6.012</td>\n",
       "      <td>6.146</td>\n",
       "      <td>0.535</td>\n",
       "      <td>-0.621</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.860</td>\n",
       "      <td>0.773</td>\n",
       "      <td>-0.288</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.038</td>\n",
       "      <td>惊奇</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PD</th>\n",
       "      <td>10.734</td>\n",
       "      <td>8.818</td>\n",
       "      <td>10.890</td>\n",
       "      <td>8.319</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.109</td>\n",
       "      <td>0.742</td>\n",
       "      <td>-0.329</td>\n",
       "      <td>0.011</td>\n",
       "      <td>2.533</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.690</td>\n",
       "      <td>尊敬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PE</th>\n",
       "      <td>6.173</td>\n",
       "      <td>6.224</td>\n",
       "      <td>7.161</td>\n",
       "      <td>6.856</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-2.434</td>\n",
       "      <td>0.900</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.153</td>\n",
       "      <td>-1.430</td>\n",
       "      <td>安心</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PF</th>\n",
       "      <td>1.450</td>\n",
       "      <td>1.614</td>\n",
       "      <td>2.128</td>\n",
       "      <td>2.536</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-1.855</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-4.712</td>\n",
       "      <td>0.365</td>\n",
       "      <td>-0.907</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-3.749</td>\n",
       "      <td>思</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PG</th>\n",
       "      <td>13.612</td>\n",
       "      <td>11.967</td>\n",
       "      <td>12.837</td>\n",
       "      <td>12.492</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.074</td>\n",
       "      <td>1.789</td>\n",
       "      <td>0.009</td>\n",
       "      <td>2.609</td>\n",
       "      <td>0.397</td>\n",
       "      <td>-0.847</td>\n",
       "      <td>相信</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PH</th>\n",
       "      <td>58.993</td>\n",
       "      <td>65.562</td>\n",
       "      <td>52.840</td>\n",
       "      <td>49.323</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3.080</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.324</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-3.409</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.464</td>\n",
       "      <td>赞扬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PK</th>\n",
       "      <td>7.429</td>\n",
       "      <td>6.758</td>\n",
       "      <td>5.980</td>\n",
       "      <td>6.257</td>\n",
       "      <td>0.252</td>\n",
       "      <td>-1.146</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.731</td>\n",
       "      <td>0.093</td>\n",
       "      <td>1.682</td>\n",
       "      <td>0.202</td>\n",
       "      <td>1.278</td>\n",
       "      <td>祝愿</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    male_he_words  male_she_words  female_he_words  female_she_words  \\\n",
       "NB         10.915          14.130           11.797            12.944   \n",
       "NC          7.567           8.069            4.791             5.525   \n",
       "ND         14.883          12.698           13.950            13.354   \n",
       "NE         10.013          11.207           12.263            12.320   \n",
       "NG          0.853           1.324            1.157             1.202   \n",
       "NH          1.868           2.283            2.920             2.732   \n",
       "NI          3.262           3.835            3.075             3.564   \n",
       "NJ          3.415           3.665            3.239             3.366   \n",
       "NK          0.255           0.268            0.242             0.438   \n",
       "NL          4.218           3.617            4.107             4.106   \n",
       "NN         38.924          34.505           39.598            37.829   \n",
       "NR          5.281           4.551            5.045             4.026   \n",
       "PA         24.749          24.179           24.551            25.681   \n",
       "PB         14.026          19.505           18.357            17.460   \n",
       "PC          7.956           8.100            6.012             6.146   \n",
       "PD         10.734           8.818           10.890             8.319   \n",
       "PE          6.173           6.224            7.161             6.856   \n",
       "PF          1.450           1.614            2.128             2.536   \n",
       "PG         13.612          11.967           12.837            12.492   \n",
       "PH         58.993          65.562           52.840            49.323   \n",
       "PK          7.429           6.758            5.980             6.257   \n",
       "\n",
       "    Fhe_vs_Fshe_P  Fhe_vs_Fshe_ST  Mhe_vs_Fhe_P  Mhe_vs_Fhe_ST  Mhe_vs_Mshe_P  \\\n",
       "NB          0.001          -3.364         0.010         -2.575          0.000   \n",
       "NC          0.001          -3.302         0.000         11.161          0.510   \n",
       "ND          0.185           1.327         0.054          1.933          0.003   \n",
       "NE          0.856          -0.181         0.000         -7.410          0.037   \n",
       "NG          0.606          -0.516         0.000         -3.876          0.005   \n",
       "NH          0.184           1.330         0.000         -7.999          0.027   \n",
       "NI          0.002          -3.166         0.241          1.172          0.140   \n",
       "NJ          0.470          -0.723         0.288          1.063          0.469   \n",
       "NK          0.000          -3.983         0.750          0.318          0.819   \n",
       "NL          0.996           0.004         0.552          0.595          0.053   \n",
       "NN          0.038           2.075         0.441         -0.771          0.001   \n",
       "NR          0.000           4.901         0.307          1.022          0.045   \n",
       "PA          0.090          -1.699         0.759          0.307          0.578   \n",
       "PB          0.145           1.457         0.000         -7.009          0.000   \n",
       "PC          0.535          -0.621         0.000          7.860          0.773   \n",
       "PD          0.000           6.109         0.742         -0.329          0.011   \n",
       "PE          0.487           0.695         0.015         -2.434          0.900   \n",
       "PF          0.064          -1.855         0.000         -4.712          0.365   \n",
       "PG          0.407           0.829         0.074          1.789          0.009   \n",
       "PH          0.002           3.080         0.000          5.324          0.001   \n",
       "PK          0.252          -1.146         0.000          5.731          0.093   \n",
       "\n",
       "    Mhe_vs_Mshe_ST  Mshe_vs_Fshe_P  Mshe_vs_Fshe_ST chi_emo  \n",
       "NB          -3.766           0.165            1.391      悲伤  \n",
       "NC          -0.659           0.001            3.373      恐惧  \n",
       "ND           2.960           0.360           -0.917      憎恶  \n",
       "NE          -2.089           0.054           -1.929      烦闷  \n",
       "NG          -2.847           0.472            0.720       羞  \n",
       "NH          -2.216           0.021           -2.305       疚  \n",
       "NI          -1.476           0.483            0.702       慌  \n",
       "NJ          -0.724           0.392            0.856      失望  \n",
       "NK          -0.229           0.009           -2.629      妒忌  \n",
       "NL           1.934           0.111           -1.597      怀疑  \n",
       "NN           3.200           0.015           -2.432      贬责  \n",
       "NR           2.004           0.134            1.498      愤怒  \n",
       "PA           0.556           0.148           -1.448      快乐  \n",
       "PB          -5.141           0.055            1.921      喜爱  \n",
       "PC          -0.288           0.000            4.038      惊奇  \n",
       "PD           2.533           0.490            0.690      尊敬  \n",
       "PE          -0.126           0.153           -1.430      安心  \n",
       "PF          -0.907           0.000           -3.749       思  \n",
       "PG           2.609           0.397           -0.847      相信  \n",
       "PH          -3.409           0.000            8.464      赞扬  \n",
       "PK           1.682           0.202            1.278      祝愿  "
      ]
     },
     "execution_count": 927,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heshe_emo_comparison= pd.concat([heshe_emotion_DF, heshe_emo_ttest_DF], axis= 1)\n",
    "heshe_emo_comparison[\"chi_emo\"]= [emotion_key_dic[eng_emo] for eng_emo in heshe_emo_comparison.index]\n",
    "heshe_emo_comparison.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification based on emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_col= []\n",
    "for i in range(30):\n",
    "    helper_col+= [\"ch\"+str(i+1)+\"_clean\"]\n",
    "bookDF_ch= pd.concat([bookDF_male_tokenized[helper_col], \n",
    "                      bookDF_female_tokenized[helper_col]], axis= 0)\n",
    "bookDF_ch[\"book_gender\"]= pd.DataFrame([\"boy\"]* 500+ [\"girl\"]*500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_emotion_DF= pd.DataFrame({})\n",
    "for b_i in range(1000):\n",
    "    a_book_ch= book_ch_emotion_DF.iloc[30*b_i: 30*(b_i+1)]\n",
    "    \n",
    "    a_book_emo= a_book_ch.iloc[:, :21].sum(axis= 0)\n",
    "   \n",
    "    book_emotion_DF= book_emotion_DF.append(a_book_emo, ignore_index= True)\n",
    "\n",
    "book_emotion_DF[\"gender\"]= [1]*500+ [0]*500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_emotion(X, y, clf):\n",
    "    train_accuracy= []\n",
    "    test_accuracy= []\n",
    "    kf = KFold(n_splits=10, shuffle= True)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        #print(train_index)\n",
    "\n",
    "        #Fitting the classifier, clf is defined outside of this function\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred= clf.predict(X_train)\n",
    "        #print(accuracy_score(y_train, y_train_pred))\n",
    "        train_accuracy+= [accuracy_score(y_train, y_train_pred)]\n",
    "\n",
    "        y_test_pred= clf.predict(X_test)\n",
    "        #print(accuracy_score(y_test, y_test_pred))\n",
    "        test_accuracy+= [accuracy_score(y_test, y_test_pred)]\n",
    "    return train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_naive = sklearn.naive_bayes.GaussianNB()\n",
    "clf_SVClinear = sklearn.svm.SVC(kernel = 'linear', probability = True) \n",
    "clf_SVCrbf = sklearn.svm.SVC(kernel = 'rbf', degree = 3, probability = True) \n",
    "clf_KNN = sklearn.neighbors.KNeighborsClassifier(5, weights='distance')\n",
    "clf_lr = sklearn.linear_model.LogisticRegression()\n",
    "clf_tree = sklearn.tree.DecisionTreeClassifier()\n",
    "clf_forest = sklearn.ensemble.RandomForestClassifier()\n",
    "clf_neural = sklearn.neural_network.MLPClassifier()\n",
    "clf_ensemble = sklearn.ensemble.GradientBoostingClassifier()\n",
    "\n",
    "clf_collection= {\"clf_naive\": clf_naive, \"clf_lr\": clf_lr,\n",
    "                \"clf_SVClinear\": clf_SVClinear,\n",
    "                \"clf_SVCrbf\": clf_SVCrbf, \"clf_KNN\": clf_KNN, \"clf_tree\": clf_tree,\n",
    "                \"clf_forest\": clf_forest, \"clf_neural\": clf_neural, \"clf_ensemble\": clf_ensemble}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf_naive\n",
      "average train accuracy:  0.7593333333333333\n",
      "average test accuracy:  0.74\n",
      "clf_lr\n",
      "average train accuracy:  0.8207777777777776\n",
      "average test accuracy:  0.817\n",
      "clf_SVClinear\n",
      "average train accuracy:  0.8267777777777778\n",
      "average test accuracy:  0.817\n",
      "clf_SVCrbf\n",
      "average train accuracy:  0.8046666666666666\n",
      "average test accuracy:  0.783\n",
      "clf_KNN\n",
      "average train accuracy:  1.0\n",
      "average test accuracy:  0.727\n",
      "clf_tree\n",
      "average train accuracy:  1.0\n",
      "average test accuracy:  0.726\n",
      "clf_forest\n",
      "average train accuracy:  0.9913333333333334\n",
      "average test accuracy:  0.783\n",
      "clf_neural\n",
      "average train accuracy:  0.8333333333333334\n",
      "average test accuracy:  0.808\n",
      "clf_ensemble\n",
      "average train accuracy:  0.9746666666666666\n",
      "average test accuracy:  0.796\n"
     ]
    }
   ],
   "source": [
    "X= np.array(book_emotion_DF.iloc[:, :21])\n",
    "y= np.array(book_emotion_DF[\"gender\"])\n",
    "for clf_name, clf in clf_collection.items():\n",
    "    print(clf_name)\n",
    "    train_accuracy_list, test_accuracy_list= cross_val_emotion(X, y, clf)\n",
    "    print(\"average train accuracy: \", np.mean(train_accuracy_list))\n",
    "    print(\"average test accuracy: \", np.mean(test_accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [],
   "source": [
    "A= bookDF_ch[\"30_ch_list\"].iloc[:500]\n",
    "B= bookDF_ch[\"30_ch_list\"].iloc[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbourWords(word,df,windowsize=5):\n",
    "    nb_words = defaultdict(int)\n",
    "    for row in df.values:\n",
    "        if word in row:\n",
    "            idxs = [i for i, x in enumerate(row) if x == word]\n",
    "            for idx in idxs:\n",
    "                #idx = row.index(word)\n",
    "                left = max(idx-windowsize,0)\n",
    "\n",
    "                right = min(idx +windowsize,len(row))\n",
    "                for w in row[left:right]:\n",
    "                    if not word==w:\n",
    "                        nb_words[w]+=1\n",
    "    return sorted(nb_words.items(),key=lambda x:x[1], reverse=True)\n",
    "\n",
    "\n",
    "def getNeighbourInfo(wordlist,sampA=A,sampB=B):\n",
    "    for w in wordlist:\n",
    "        nb_insampA = getNeighbourWords(w, sampA)\n",
    "        nb_insampB = getNeighbourWords(w, sampB)\n",
    "        sampA_neighbour_occurences = 0\n",
    "        sampB_neighbour_occurences = 0\n",
    "        for item in nb_insampA:\n",
    "            sampA_neighbour_occurences+=item[1]\n",
    "        for item in nb_insampB:\n",
    "            sampB_neighbour_occurences+=item[1]\n",
    "        print ('%s \\t 有 \\t %s 邻居(%s 次) \\t in sampA,\\t %s 邻居(%s 次) \\t in sampB' %\\\n",
    "               (w,len(nb_insampA),sampA_neighbour_occurences,len(nb_insampB),sampB_neighbour_occurences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = A\n",
    "windowsize=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_words = defaultdict(int)\n",
    "for row in df.values:\n",
    "    if word in row:\n",
    "        \n",
    "        idx = row.index(word)\n",
    "        left = max(idx-windowsize,0)\n",
    "\n",
    "        right = min(idx +windowsize,len(row))\n",
    "        for w in row[left:right]:\n",
    "            if not word==w:\n",
    "                nb_words[w]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99240"
      ]
     },
     "execution_count": 1186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bookW2V_20.wv.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "他 \t 有 \t 107467 邻居(2197670 次) \t in sampA,\t 83864 邻居(1291770 次) \t in sampB\n",
      "她 \t 有 \t 46236 邻居(434223 次) \t in sampA,\t 109812 邻居(2585742 次) \t in sampB\n"
     ]
    }
   ],
   "source": [
    "getNeighbourInfo(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['宁小闲御神录',\n",
       " '君九龄',\n",
       " '平凡的清穿日子',\n",
       " '慕南枝',\n",
       " '你好，少将大人',\n",
       " '锦桐',\n",
       " '以和为贵',\n",
       " '传说的后来',\n",
       " '凤囚凰',\n",
       " '琅琊榜',\n",
       " '金屋恨',\n",
       " '零陵飘香',\n",
       " '半路情缘',\n",
       " '韶光慢',\n",
       " '乱世红颜梦',\n",
       " '凤回巢',\n",
       " '好事多磨',\n",
       " '剩女不淑',\n",
       " '极品店小二',\n",
       " '在清朝的生活',\n",
       " '红杏泄春光',\n",
       " '覆手繁华',\n",
       " '周小云的幸福生活',\n",
       " '清朝经济适用男',\n",
       " '千面风华',\n",
       " '娱乐圈头条',\n",
       " '狐戏红尘',\n",
       " '娇女',\n",
       " '千金归来',\n",
       " '复贵盈门',\n",
       " '到清当自强',\n",
       " '翠色田园',\n",
       " '喜盈门',\n",
       " '长嫡',\n",
       " '天命为凰',\n",
       " '驱魔人',\n",
       " '十样锦',\n",
       " '八夫临门',\n",
       " '春光里',\n",
       " '美人凶猛',\n",
       " '世婚',\n",
       " '大宅小事',\n",
       " '御夫',\n",
       " '庶难从命',\n",
       " '九重紫',\n",
       " '祖训',\n",
       " '极恶皇后',\n",
       " '重生之珠光宝妻',\n",
       " '替嫁太子妃',\n",
       " '长姐',\n",
       " '俊男坊',\n",
       " '帝后',\n",
       " '阖家欢喜',\n",
       " '金陵春',\n",
       " '帝锦',\n",
       " '名门喜事',\n",
       " '苏菲的异界',\n",
       " '极品女仙',\n",
       " '大当家',\n",
       " '新一品修真',\n",
       " '重生反派女boss',\n",
       " '奉旨休夫',\n",
       " '弃妃俱乐部',\n",
       " '绮梦璇玑',\n",
       " '迷心记——出版名',\n",
       " '雁引春归',\n",
       " '绝色赌妃',\n",
       " '杏林纪事',\n",
       " '珠光宝鉴',\n",
       " '弃妇也逍遥',\n",
       " '庶女攻略',\n",
       " '门楣',\n",
       " '福运来',\n",
       " '剩女的梦幻庄园',\n",
       " '奉子相夫',\n",
       " '奶妈疼你',\n",
       " '嫡谋',\n",
       " '宫斗',\n",
       " '无盐妖娆',\n",
       " '东宫之主',\n",
       " '良婿',\n",
       " '金风玉露',\n",
       " '异世之魔兽庄园',\n",
       " '坤后',\n",
       " '药窕淑女',\n",
       " '富贵逼人',\n",
       " '末世之希望树',\n",
       " '仙风制药',\n",
       " '娇娘医经',\n",
       " '狐狸娇妻',\n",
       " '金瓶莲',\n",
       " '驭夫36计',\n",
       " '古代地主婆',\n",
       " '欢乐颂',\n",
       " '嫁时衣',\n",
       " '国色芳华',\n",
       " '盛世茶香',\n",
       " '锦医',\n",
       " '宫廷营养师',\n",
       " '越姬',\n",
       " '秀色',\n",
       " '极品太子妃',\n",
       " '女帝直播攻略',\n",
       " '名门闺战',\n",
       " '回春坊',\n",
       " '嫁给极品太子',\n",
       " '都市呆萌录',\n",
       " '阿杏',\n",
       " '良陈美锦',\n",
       " '重生超级巨星',\n",
       " '仙有仙归',\n",
       " '末日乐园',\n",
       " '丹凤朝阳',\n",
       " '神仙也有江湖',\n",
       " '名门医女',\n",
       " '丑女如菊',\n",
       " '盛世妖颜',\n",
       " '涩女日记',\n",
       " '锦绣芳华',\n",
       " '平凡的农家女',\n",
       " '闺门春事',\n",
       " '半劫小仙',\n",
       " '妾大不如妻',\n",
       " '嫡长女',\n",
       " '炮灰攻略',\n",
       " '妖媚志',\n",
       " '药医的悠然生活',\n",
       " '龙龙龙',\n",
       " '世家名门',\n",
       " '侯门娇',\n",
       " '魅祸异世',\n",
       " '诱狐',\n",
       " '重生女相士',\n",
       " '遥来归',\n",
       " '旺夫',\n",
       " '谋宫',\n",
       " '千蛊江山',\n",
       " '江山美人谋',\n",
       " '重生夏琉璃',\n",
       " '小富即安',\n",
       " '重生之缘来如此简单',\n",
       " '甜园福地',\n",
       " '市井贵女',\n",
       " '黯乡魂',\n",
       " '重生女配',\n",
       " '不做豪门梦的灰姑娘',\n",
       " '祸乱创世纪',\n",
       " '一品宫女',\n",
       " '晴儿的田园生活',\n",
       " '后命',\n",
       " '喜嫁',\n",
       " '狐狸传奇',\n",
       " '天衣多媚',\n",
       " '妙偶天成',\n",
       " '药结同心',\n",
       " '诛砂',\n",
       " '一品夫人成长记',\n",
       " '鏖仙',\n",
       " '吉时医到',\n",
       " '玩游戏傍大神',\n",
       " '重生之不做皇后',\n",
       " '闺宁',\n",
       " '异世之平淡是福',\n",
       " '福晋吉祥',\n",
       " '傲娇女神，逆袭吧！',\n",
       " '御人',\n",
       " '盛世宫名',\n",
       " '古代剩女的春天',\n",
       " '仙姿物语',\n",
       " '盘丝洞38号',\n",
       " '贵妇',\n",
       " '重生之破茧',\n",
       " '花影重重',\n",
       " '嗨包子他爸',\n",
       " '胭脂大宋',\n",
       " '婚聘',\n",
       " '江湖遍地卖装备',\n",
       " '殿上欢',\n",
       " '清宫升职记',\n",
       " '帝台娇',\n",
       " '喜良缘',\n",
       " '古代育儿宝典',\n",
       " '仙园逸事',\n",
       " '重生宜室宜家',\n",
       " '清朝穿越记',\n",
       " '天字医号',\n",
       " '重生之末世仙途',\n",
       " '十全食美',\n",
       " '妻锦',\n",
       " '闲妻',\n",
       " '阿莞',\n",
       " '异世淘宝女王',\n",
       " '嫡女重生',\n",
       " '海月明珠',\n",
       " '绣外慧中',\n",
       " '九全十美',\n",
       " '清朝求生记',\n",
       " '重生之师傅在外星',\n",
       " '贵女如嫡',\n",
       " '星云海',\n",
       " '大明小官生活',\n",
       " '家业',\n",
       " '皇家幼儿园',\n",
       " '名门闺杀',\n",
       " '重生打造完美家园',\n",
       " '玉氏春秋',\n",
       " '鬼生意之无常快递',\n",
       " '私奔去修仙',\n",
       " '重生之不要爱上我',\n",
       " '名福妻实',\n",
       " '药手回春',\n",
       " '国手棋医',\n",
       " '夺舍在星际',\n",
       " '锦屏记',\n",
       " '上神来了',\n",
       " '田园无小事',\n",
       " '素手遮天',\n",
       " '锦心',\n",
       " '嫌妻',\n",
       " '美人三千笑',\n",
       " '流氓大公',\n",
       " '重生之我的快乐我做主',\n",
       " '终极大神进化论',\n",
       " '嫡策',\n",
       " '重生破茧成蝶',\n",
       " '家有妖夫',\n",
       " '丑仙记',\n",
       " '六零时光俏',\n",
       " '有女不凡',\n",
       " '竞芳菲',\n",
       " '御香记',\n",
       " '荣华归',\n",
       " '魔法养成攻略',\n",
       " '公子别急',\n",
       " '药医的随身空间',\n",
       " '重生之蔷薇花开',\n",
       " '权阀嫡女',\n",
       " '秦画眉',\n",
       " '以嫡为贵',\n",
       " '玉堂娇',\n",
       " '媚骨',\n",
       " '红楼多娇',\n",
       " '与子偕行',\n",
       " '舍我妻谁',\n",
       " '良缘到',\n",
       " '豪门继女的重生日子',\n",
       " '重生换夫记',\n",
       " '谁家天下',\n",
       " '妻高一筹',\n",
       " '无尽相思风',\n",
       " '大妆',\n",
       " '总裁跑错房',\n",
       " '贤妻有毒',\n",
       " '重生带着任意门',\n",
       " '有凤来仪',\n",
       " '重生之宝瞳',\n",
       " '穿越未来之男人不好当',\n",
       " '锦堂春',\n",
       " '佟家小妾',\n",
       " '掌家娘子',\n",
       " '美姬妖且闲',\n",
       " '南宋生活顾问',\n",
       " '朱颜女将',\n",
       " '顾盼生欢',\n",
       " '七零年，有点甜',\n",
       " '金玉满唐',\n",
       " '穿越之茶言观色',\n",
       " '一仙难求',\n",
       " '金枝',\n",
       " '重生之星光大道',\n",
       " '一品休妻',\n",
       " '丑妇',\n",
       " '清贫乐',\n",
       " '极品逃妃',\n",
       " '御佛',\n",
       " '一指成仙',\n",
       " '新唐遗玉',\n",
       " '无忧归田',\n",
       " '隋变',\n",
       " '田园贵女',\n",
       " '重生之意随心动',\n",
       " '星际男神是我爸',\n",
       " '锦绣民国',\n",
       " '重生之人生赢家',\n",
       " '秀色农家',\n",
       " '善终',\n",
       " '庆春归',\n",
       " '一品闺秀',\n",
       " '凤朝江山',\n",
       " '书香世家',\n",
       " '项链里的空间',\n",
       " '大清初年',\n",
       " '重生之阎欢',\n",
       " '雁回',\n",
       " '弃妇再嫁',\n",
       " '斗锦堂',\n",
       " '唐朝笔记',\n",
       " '东宫倾城',\n",
       " '宠宠欲动',\n",
       " '卿本风流',\n",
       " '重生影后小军嫂',\n",
       " '贵妃的现代生活',\n",
       " '春怀缱绻',\n",
       " '重生之再斗极品婆婆',\n",
       " '重生之闲妻',\n",
       " '悠闲在清朝',\n",
       " '末世涅凰',\n",
       " '重生同萌',\n",
       " '平安的重生日子',\n",
       " '嫌妻当家',\n",
       " '田园谷香',\n",
       " '猫游记',\n",
       " '重生之必然幸福',\n",
       " '幸福末世',\n",
       " '贵女种田记',\n",
       " '生活是项技术活',\n",
       " '芸仙',\n",
       " '大汉嫣华',\n",
       " '吾爱倾城：天使之爱',\n",
       " '清朝出阁记',\n",
       " '放下那个汉子',\n",
       " '重生之小资生活',\n",
       " '女配有毒',\n",
       " '古代幸福生活',\n",
       " '玉琢',\n",
       " '烟水寒',\n",
       " '囧囧妖妻',\n",
       " '伪妆记',\n",
       " '欢喜如初',\n",
       " '黄泉旅店',\n",
       " '盛世芳华',\n",
       " '穿越七十年代之军嫂成长记',\n",
       " '重生之晗雅',\n",
       " '仙家有田',\n",
       " '重生之豪门学霸',\n",
       " '重生炮灰大翻身',\n",
       " '古代女军医',\n",
       " '女帝生涯',\n",
       " '六宫',\n",
       " '药师',\n",
       " '大唐明月',\n",
       " '凤月无边',\n",
       " '重生之锦雀成凰',\n",
       " '拯救上神计划',\n",
       " '镇香令',\n",
       " '浮世经',\n",
       " '食味记',\n",
       " '红楼八卦周刊',\n",
       " '点草成妖',\n",
       " '重生之如水人生',\n",
       " '《逍遥游》',\n",
       " '锦绣生香',\n",
       " '春宫缭乱',\n",
       " '大清小事',\n",
       " '春闺记事',\n",
       " '我就是如此娇花',\n",
       " '上善若书',\n",
       " '我家徒弟又挂了',\n",
       " '村花筱叶',\n",
       " '雷影娉婷',\n",
       " '末日随身',\n",
       " '末世重生之炮灰逆袭',\n",
       " '重生之刹那芳华',\n",
       " '田园小当家',\n",
       " '重生之军医',\n",
       " '再世为后',\n",
       " '星际花匠生活',\n",
       " '凰的男臣',\n",
       " '仙株',\n",
       " '锦绣丹华',\n",
       " '清宫——宛妃传',\n",
       " '重生去修真',\n",
       " '女官',\n",
       " '机甲奶爸',\n",
       " '倾世宠妻',\n",
       " '小姬快跑',\n",
       " '大丫鬟',\n",
       " '秀色田园',\n",
       " '重生之花好月圆',\n",
       " '金牌芳香师',\n",
       " '重生之炮灰九福晋',\n",
       " '娇女谋略',\n",
       " '妾上无妻',\n",
       " '吾若为妃',\n",
       " '田园仙事',\n",
       " '宋朝完美生活',\n",
       " '青诡纪事',\n",
       " '娇鸾',\n",
       " '重生小夫妻',\n",
       " '随喜',\n",
       " '凤凰宝藏',\n",
       " '黑萌进化史',\n",
       " '斗翠',\n",
       " '平穿花嫁娘',\n",
       " '古代养儿记',\n",
       " '重生之天运符师',\n",
       " '翡翠明珠',\n",
       " '蕙质兰曦',\n",
       " '一妻当关',\n",
       " '第二春',\n",
       " '生存游戏',\n",
       " '福晋凶猛',\n",
       " '木仙府种田纪事',\n",
       " '富贵不能吟',\n",
       " '末世之医济天下',\n",
       " '朱门恶女',\n",
       " '大帝姬',\n",
       " '红楼遗梦',\n",
       " '不良少夫',\n",
       " '宸宫',\n",
       " '洛临',\n",
       " '娴医',\n",
       " '转世为狐',\n",
       " '弃妇的美好时代',\n",
       " '重生小保姆',\n",
       " '重生之药香',\n",
       " '本宫不在线',\n",
       " '小楼传说',\n",
       " '仙本纯良',\n",
       " '南朝春色',\n",
       " '名门正妻',\n",
       " '重生左唯',\n",
       " '烧火丫鬟喜洋洋',\n",
       " '伯府嫡女',\n",
       " '重华',\n",
       " '穿越安之若素',\n",
       " '庶庶一家亲',\n",
       " '妾生',\n",
       " '伪术士的悠闲生活',\n",
       " '米虫重奏曲',\n",
       " '游医',\n",
       " '极品夫妻',\n",
       " '重生之军营',\n",
       " '网游之乌龙夫妻',\n",
       " '胡笳',\n",
       " '才男财女',\n",
       " '墨镯',\n",
       " '逼入洞房',\n",
       " '军妆',\n",
       " '修女也疯狂',\n",
       " '全职业米虫',\n",
       " '院上坟',\n",
       " '衣香',\n",
       " '万事如易',\n",
       " '清宫熹照',\n",
       " '一品天下',\n",
       " '金枝玉叶',\n",
       " '绾青丝',\n",
       " '北宋生活顾问',\n",
       " '重生之豪门媳妇',\n",
       " '媚公卿',\n",
       " '娥媚',\n",
       " '家有鲜妻',\n",
       " '重修于好',\n",
       " '重生之1976',\n",
       " '衣冠望族',\n",
       " '妻为君纲',\n",
       " '青竹梦',\n",
       " '星际之机甲无敌',\n",
       " '掌事',\n",
       " '重生之再难平凡',\n",
       " '末世好孕',\n",
       " '家事',\n",
       " '宫怀缱绻',\n",
       " '冰肌玉仙',\n",
       " '美人谋律',\n",
       " '娇宠令',\n",
       " '位面跑商',\n",
       " '悠闲小农女',\n",
       " '独步清风',\n",
       " '回到古代当兽医',\n",
       " '网游之神语者',\n",
       " '种田纪事',\n",
       " '喜登枝',\n",
       " '吹灯耕田',\n",
       " '郡主长宁',\n",
       " '御夫手册',\n",
       " '清朝种田记',\n",
       " '知味记',\n",
       " '嫡女纪事',\n",
       " '将门娇',\n",
       " '与君暧昧',\n",
       " '冲囍',\n",
       " '将府小妹',\n",
       " '星际之男色袭人',\n",
       " '请夫入瓮',\n",
       " '末世之人生赢家',\n",
       " '盛世为妖',\n",
       " '重生小地主',\n",
       " '带着吃货闯仙途',\n",
       " '盛唐无妖',\n",
       " '名门贵妻',\n",
       " '重生老俩口悠闲红楼生活',\n",
       " '冠盖满京华',\n",
       " '嫁夫',\n",
       " '以来自远方之名',\n",
       " '多宝佳人',\n",
       " '誓不为庶',\n",
       " '压寨将军',\n",
       " '一见倾心总裁宠妻无上限']"
      ]
     },
     "execution_count": 1192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bookDF_female_tokenized[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
